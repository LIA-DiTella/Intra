{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import raiseExceptions\n",
    "from tokenize import Double\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "from vec3 import Vec3\n",
    "import meshplot as mp\n",
    "import torch\n",
    "torch.manual_seed(125)\n",
    "import random\n",
    "random.seed(125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_fn(f):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        wrapper.count += 1\n",
    "        return f(*args, **kwargs)\n",
    "    wrapper.count = 0\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clase nodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    Class Node\n",
    "    \"\"\"\n",
    "    def __init__(self, value, radius, left = None, right = None, position = None, cl_prob= None, ce = None, mse = None):\n",
    "        self.left = left\n",
    "        self.data = value\n",
    "        self.radius = radius\n",
    "        self.position = position\n",
    "        self.right = right\n",
    "        self.prob = cl_prob\n",
    "        self.mse = mse\n",
    "        self.ce = ce\n",
    "        self.children = [self.left, self.right]\n",
    "    \n",
    "    def agregarHijo(self, children):\n",
    "\n",
    "        if self.right is None:\n",
    "            self.right = children\n",
    "        elif self.left is None:\n",
    "            self.left = children\n",
    "\n",
    "        else:\n",
    "            raise ValueError (\"solo arbol binario \")\n",
    "\n",
    "\n",
    "    def is_leaf(self):\n",
    "        if self.right is None:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def is_two_child(self):\n",
    "        if self.right is not None and self.left is not None:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def is_one_child(self):\n",
    "        if self.is_two_child():\n",
    "            return False\n",
    "        elif self.is_leaf():\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def childs(self):\n",
    "        if self.is_leaf():\n",
    "            return 0\n",
    "        if self.is_one_child():\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "    \n",
    "    \n",
    "    def traverseInorder(self, root):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            self.traverseInorder(root.left)\n",
    "            print (root.data, root.radius)\n",
    "            self.traverseInorder(root.right)\n",
    "\n",
    "    def traverseInorderLoss(self, root, loss):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            self.traverseInorderLoss(root.left, loss)\n",
    "            loss.append(root.prob)\n",
    "            self.traverseInorderLoss(root.right, loss)\n",
    "            return loss\n",
    "\n",
    "    def traverseInorderMSE(self, root, loss):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            self.traverseInorderMSE(root.left, loss)\n",
    "            loss.append(root.mse)\n",
    "            self.traverseInorderMSE(root.right, loss)\n",
    "            return loss\n",
    "\n",
    "    def traverseInorderCE(self, root, loss):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            self.traverseInorderCE(root.left, loss)\n",
    "            loss.append(root.ce)\n",
    "            self.traverseInorderCE(root.right, loss)\n",
    "            return loss\n",
    "\n",
    "    def traverseInorderChilds(self, root, l):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            self.traverseInorderChilds(root.left, l)\n",
    "            l.append(root.childs())\n",
    "            self.traverseInorderChilds(root.right, l)\n",
    "            return l\n",
    "\n",
    "    def preorder(self, root):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            print (root.data, root.radius)\n",
    "            self.preorder(root.left)\n",
    "            self.preorder(root.right)\n",
    "\n",
    "    def cloneBinaryTree(self, root):\n",
    "     \n",
    "        # base case\n",
    "        if root is None:\n",
    "            return None\n",
    "    \n",
    "        # create a new node with the same data as the root node\n",
    "        root_copy = Node(root.data, root.radius)\n",
    "    \n",
    "        # clone the left and right subtree\n",
    "        root_copy.left = self.cloneBinaryTree(root.left)\n",
    "        root_copy.right = self.cloneBinaryTree(root.right)\n",
    "    \n",
    "        # return cloned root node\n",
    "        return root_copy\n",
    "\n",
    "    def height(self, root):\n",
    "    # Check if the binary tree is empty\n",
    "        if root is None:\n",
    "            return 0 \n",
    "        # Recursively call height of each node\n",
    "        leftAns = self.height(root.left)\n",
    "        rightAns = self.height(root.right)\n",
    "    \n",
    "        # Return max(leftHeight, rightHeight) at each iteration\n",
    "        return max(leftAns, rightAns) + 1\n",
    "\n",
    "    # Print nodes at a current level\n",
    "    def printCurrentLevel(self, root, level):\n",
    "        if root is None:\n",
    "            return\n",
    "        if level == 1:\n",
    "            print(root.data, end=\" \")\n",
    "        elif level > 1:\n",
    "            self.printCurrentLevel(root.left, level-1)\n",
    "            self.printCurrentLevel(root.right, level-1)\n",
    "\n",
    "    def printLevelOrder(self, root):\n",
    "        h = self.height(root)\n",
    "        for i in range(1, h+1):\n",
    "            self.printCurrentLevel(root, i)\n",
    "\n",
    "\n",
    "    \n",
    "    def count_nodes(self, root, counter):\n",
    "        if   root is not None:\n",
    "            self.count_nodes(root.left, counter)\n",
    "            counter.append(root.data)\n",
    "            self.count_nodes(root.right, counter)\n",
    "            return counter\n",
    "\n",
    "    \n",
    "    def serialize(self, root):\n",
    "        def post_order(root):\n",
    "            if root:\n",
    "                post_order(root.left)\n",
    "                post_order(root.right)\n",
    "                ret[0] += str(root.data)+'_'+ str(root.radius) +';'\n",
    "                \n",
    "            else:\n",
    "                ret[0] += '#;'           \n",
    "\n",
    "        ret = ['']\n",
    "        post_order(root)\n",
    "        return ret[0][:-1]  # remove last ,\n",
    "\n",
    "    def toGraph( self, graph, index, dec, proc=True):\n",
    "        \n",
    "        \n",
    "        radius = self.radius.cpu().detach().numpy()\n",
    "        if dec:\n",
    "            radius= radius[0]\n",
    "        #print(\"posicion\", self.data, radius)\n",
    "        #print(\"right\", self.right)\n",
    "        \n",
    "        #graph.add_nodes_from( [ (index, {'posicion': radius[0:3], 'radio': radius[3] } ) ])\n",
    "        graph.add_nodes_from( [ (self.data, {'posicion': radius[0:3], 'radio': radius[3] } ) ])\n",
    "        \n",
    "\n",
    "        if self.right is not None:\n",
    "            #leftIndex = self.right.toGraph( graph, index + 1, dec)#\n",
    "            self.right.toGraph( graph, index + 1, dec)#\n",
    "            \n",
    "            #graph.add_edge( index, index + 1 )\n",
    "            graph.add_edge( self.data, self.right.data )\n",
    "            #if proc:\n",
    "            #    nx.set_edge_attributes( graph, {(index, index+1) : {'procesada':False}})\n",
    "        \n",
    "            if self.left is not None:\n",
    "                #retIndex = self.left.toGraph( graph, leftIndex, dec )#\n",
    "                self.left.toGraph( graph, 0, dec )#\n",
    "\n",
    "                #graph.add_edge( index, leftIndex)\n",
    "                graph.add_edge( self.data, self.left.data)\n",
    "                #if proc:\n",
    "                #    nx.set_edge_attributes( graph, {(index, leftIndex) : {'procesada':False}})\n",
    "            \n",
    "            else:\n",
    "                #return leftIndex\n",
    "                return\n",
    "\n",
    "        else:\n",
    "            #return index + 1\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTree( root, dec ):\n",
    "    graph = nx.Graph()\n",
    "    root.toGraph( graph, 0, dec)\n",
    "    edges=nx.get_edge_attributes(graph,'procesada')\n",
    "\n",
    "    p = mp.plot( np.array([ graph.nodes[v]['posicion'] for v in graph.nodes]), shading={'point_size':0.1}, return_plot=True)\n",
    "\n",
    "    for arista in graph.edges:\n",
    "        p.add_lines( graph.nodes[arista[0]]['posicion'], graph.nodes[arista[1]]['posicion'])\n",
    "\n",
    "    return \n",
    "\n",
    "def traverse(root, tree):\n",
    "       \n",
    "        if root is not None:\n",
    "            traverse(root.left, tree)\n",
    "            tree.append((root.radius, root.data))\n",
    "            traverse(root.right, tree)\n",
    "            return tree\n",
    "\n",
    "def traverse_2(tree1, tree2, t_l):\n",
    "       \n",
    "        if tree1 is not None:\n",
    "            traverse_2(tree1.left, tree2.left, t_l)\n",
    "            if tree2:\n",
    "                t_l.append((tree1.radius, tree2.radius))\n",
    "                print((tree1.radius, tree2.radius))\n",
    "            else:\n",
    "                t_l.append(tree1.radius)\n",
    "                print((tree1.radius))\n",
    "            traverse_2(tree1.right, tree2, t_l)\n",
    "            return t_l\n",
    "            \n",
    "\n",
    "def traverse_conexiones(root, tree):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            traverse_conexiones(root.left, tree)\n",
    "            if root.right is not None:\n",
    "                tree.append((root.data, root.right.data))\n",
    "            if root.left is not None:\n",
    "                tree.append((root.data, root.left.data))\n",
    "            traverse_conexiones(root.right, tree)\n",
    "            return tree\n",
    "\n",
    "def arbolAGrafo (nodoRaiz):\n",
    "    \n",
    "    conexiones = []\n",
    "    lineas = traverse_conexiones(nodoRaiz, conexiones)\n",
    "    tree = []\n",
    "    tree = traverse(nodoRaiz, tree)\n",
    "\n",
    "    vertices = []\n",
    "    verticesCrudos = []\n",
    "    for node in tree:\n",
    "        vertice = node[0][0][:3]\n",
    "        rad = node[0][0][-1]\n",
    "        num = node[1]\n",
    "        \n",
    "        #vertices.append((num, {'posicion': Vec3( vertice[0], vertice[1], vertice[2]), 'radio': rad} ))\n",
    "        vertices.append((len(verticesCrudos),{'posicion': Vec3( vertice[0], vertice[1], vertice[2]), 'radio': rad}))\n",
    "        verticesCrudos.append(vertice)\n",
    "\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from( vertices )\n",
    "    G.add_edges_from( lineas )\n",
    "    \n",
    "    return G\n",
    "\n",
    "@count_fn\n",
    "def createNode(data, radius, position = None, left = None, right = None, cl_prob = None, ce = None, mse=None):\n",
    "        \"\"\"\n",
    "        Utility function to create a node.\n",
    "        \"\"\"\n",
    "        return Node(data, radius, position, left, right, cl_prob, ce, mse)\n",
    " \n",
    "def deserialize(data):\n",
    "    if  not data:\n",
    "        return \n",
    "    nodes = data.split(';')  \n",
    "    #print(\"node\",nodes[3])\n",
    "    def post_order(nodes):\n",
    "                \n",
    "        if nodes[-1] == '#':\n",
    "            nodes.pop()\n",
    "            return None\n",
    "        node = nodes.pop().split('_')\n",
    "        data = int(node[0])\n",
    "        #radius = float(node[1])\n",
    "        #print(\"node\", node)\n",
    "        #breakpoint()\n",
    "        radius = node[1]\n",
    "        #print(\"radius\", radius)\n",
    "        rad = radius.split(\",\")\n",
    "        rad [0] = rad[0].replace('[','')\n",
    "        rad [3] = rad[3].replace(']','')\n",
    "        r = []\n",
    "        for value in rad:\n",
    "            r.append(float(value))\n",
    "        #r =[float(num) for num in radius if num.isdigit()]\n",
    "        r = torch.tensor(r, device=device)\n",
    "        #breakpoint()\n",
    "        root = createNode(data, r)\n",
    "        root.right = post_order(nodes)\n",
    "        root.left = post_order(nodes)\n",
    "        \n",
    "        return root    \n",
    "    return post_order(nodes)    \n",
    "\n",
    "\n",
    "def read_tree(filename):\n",
    "    with open('./trees/' +filename, \"r\") as f:\n",
    "        byte = f.read() \n",
    "        return byte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeafEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size: int, feature_size: int, hidden_size: int):\n",
    "        super(LeafEncoder, self).__init__()\n",
    "        #self.l1 = nn.Linear(4, hidden_size)\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size, feature_size)\n",
    "        self.l3 = nn.Linear(feature_size, feature_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, input):\n",
    "        #print(\"leaf encoder\")\n",
    "        #print(\"input\", input)\n",
    "        #print(\"input\", input.shape)\n",
    "        \n",
    "        input = input.reshape(-1,4)\n",
    "        #rad = torch.tensor(input.radius)\n",
    "        #rad = torch.reshape(rad, (1,4)).to(device)\n",
    "        #radius = self.l1(rad)\n",
    "        #input = torch.tensor(input).to(device)\n",
    "        radius = self.l1(input)\n",
    "        radius = self.tanh(radius)\n",
    "        radius = self.l2(radius)\n",
    "        radius = self.tanh(radius)\n",
    "        radius = self.l3(radius)\n",
    "        radius = self.tanh(radius)\n",
    "        #print(\"otput\", radius.shape)\n",
    "        return radius\n",
    "\n",
    "class InternalEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size: int, feature_size: int, hidden_size: int):\n",
    "        super(InternalEncoder, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size,hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size,feature_size)\n",
    "\n",
    "        self.left = nn.Linear(feature_size,feature_size)\n",
    "        self.right = nn.Linear(feature_size,feature_size)\n",
    "        \n",
    "        self.encoder = nn.Linear(2*feature_size, feature_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, input, left_input, right_input):\n",
    "        #print(\"internal encoder\")\n",
    "        #radius = self.l1(torch.tensor(input.radius).reshape(1,4).to(device))\n",
    "        #print(\"input\", input.shape)\n",
    "        radius = self.l1(input)\n",
    "        radius = self.tanh(radius)\n",
    "        radius = self.l2(radius)\n",
    "        radius = self.tanh(radius)\n",
    "        \n",
    "        context = self.right(right_input)\n",
    "        if left_input is not None:\n",
    "            context += self.left(left_input)\n",
    "        context = self.tanh(context)\n",
    "        #print(\"radius\", radius.shape)\n",
    "        #print(\"context\", context.shape)\n",
    "        feature = torch.cat((radius,context), 1)\n",
    "        #print(\"feature\", feature.shape)\n",
    "        feature = self.encoder(feature)\n",
    "        feature = self.tanh(feature)\n",
    "\n",
    "        #print(\"otput\", feature.shape)\n",
    "\n",
    "        return feature\n",
    "\n",
    "class RightEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size: int, feature_size: int, hidden_size: int):\n",
    "        super(RightEncoder, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size,hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size,feature_size)\n",
    "\n",
    "       \n",
    "        self.right = nn.Linear(feature_size,feature_size)\n",
    "        \n",
    "        self.encoder = nn.Linear(2*feature_size, feature_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, input, right_input):\n",
    "        #print(\"right encoder\")\n",
    "        #radius = self.l1(torch.tensor(input.radius).reshape(1,4).to(device))\n",
    "        #print(\"input\", input.shape)\n",
    "        #print(\"r input\", right_input.shape)\n",
    "        #print(\"input\", input)\n",
    "        #print(\"input\", right_input)\n",
    "        #input = torch.cat(input, 1)\n",
    "\n",
    "        #radius = self.l1(torch.tensor(input).reshape(-1,4).to(device))\n",
    "        radius = self.l1(input)\n",
    "        radius = self.tanh(radius)\n",
    "        radius = self.l2(radius)\n",
    "        radius = self.tanh(radius)\n",
    "        context = self.right(right_input)\n",
    "        context = self.tanh(context)\n",
    "        #print(\"rad shape\", radius.shape)\n",
    "        #print(\"context shape\", context.shape)\n",
    "\n",
    "        feature = torch.cat((radius,context), 1)\n",
    "        \n",
    "        feature = self.encoder(feature)\n",
    "        feature = self.tanh(feature)\n",
    "\n",
    "        #print(\"otput\", feature.shape)\n",
    "        return feature\n",
    "\n",
    "class GRASSEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size: int, feature_size : int, hidden_size: int):\n",
    "        super(GRASSEncoder, self).__init__()\n",
    "        self.leaf_encoder = LeafEncoder(input_size, feature_size, hidden_size )\n",
    "        self.internal_encoder = InternalEncoder(input_size,feature_size, hidden_size)\n",
    "        self.right_encoder = RightEncoder(input_size,feature_size, hidden_size)\n",
    "        \n",
    "\n",
    "    def leafEncoder(self, node):\n",
    "        return self.leaf_encoder(node)\n",
    "\n",
    "    def internalEncoder(self, node, left, right):\n",
    "        return self.internal_encoder(node, left, right)\n",
    "\n",
    "    def rightEncoder(self, node, right):\n",
    "        return self.right_encoder(node, right)\n",
    "\n",
    "gencoder = GRASSEncoder(input_size = 4, feature_size=128, hidden_size=32)\n",
    "gencoder = gencoder.to(device)\n",
    "\n",
    "\n",
    "def encode_structure_fold(fold, root):\n",
    "    \n",
    "    \n",
    "    def encode_node(node):\n",
    "        \n",
    "        if node is None:\n",
    "            return\n",
    "        if node.is_leaf():\n",
    "            #print('entra hoja')\n",
    "            return fold.add('leafEncoder', node.radius)\n",
    "            #return gencoder.leafEncoder(node)\n",
    "        elif node.is_two_child():\n",
    "\n",
    "\n",
    "            left = encode_node(node.left)\n",
    "            right = encode_node(node.right)\n",
    "            #print('entra 2 hijos')\n",
    "           \n",
    "            return fold.add('internalEncoder', node.radius, left, right)\n",
    "            #return gencoder.nonleafEncoder(node, left, right)\n",
    "        else:\n",
    "\n",
    "            right = encode_node(node.right)\n",
    "            #print('entra 1 hijo')\n",
    "            \n",
    "            return fold.add('rightEncoder', node.radius, right)\n",
    "        \n",
    "\n",
    "    encoding = encode_node(root)\n",
    "    #return fold.add('sampleEncoder', encoding)\n",
    "    return encoding\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerar_nodos(root, count):\n",
    "    if root is not None:\n",
    "        numerar_nodos(root.left, count)\n",
    "        root.data = len(count)\n",
    "        count.append(1)\n",
    "        numerar_nodos(root.right, count)\n",
    "        return \n",
    "\n",
    "\n",
    "def traversefeatures(root, features):\n",
    "       \n",
    "    if root is not None:\n",
    "        traversefeatures(root.left, features)\n",
    "        features.append(root.radius)\n",
    "        traversefeatures(root.right, features)\n",
    "        return features\n",
    "\n",
    "def norm(root, minx, miny, minz, minr, maxx, maxy, maxz, maxr):\n",
    "    \n",
    "    if root is not None:\n",
    "        mx = minx.clone().detach()\n",
    "        my = miny.clone().detach()\n",
    "        mz = minz.clone().detach()\n",
    "        mr = minr.clone().detach()\n",
    "        Mx = maxx.clone().detach()\n",
    "        My = maxy.clone().detach()\n",
    "        Mz = maxz.clone().detach()\n",
    "        Mr = maxr.clone().detach()\n",
    "\n",
    "        root.radius[0] = (root.radius[0] - minx)/(maxx - minx)\n",
    "        root.radius[1] = (root.radius[1] - miny)/(maxy - miny)\n",
    "        root.radius[2] = (root.radius[2] - minz)/(maxz - minz)\n",
    "        root.radius[3] = (root.radius[3] - minr)/(maxr - minr)\n",
    "        \n",
    "        norm(root.left, mx, my, mz, mr, Mx, My, Mz, Mr)\n",
    "        norm(root.right, mx, my, mz, mr, Mx, My, Mz, Mr)\n",
    "        return \n",
    "\n",
    "def normalize_features(root):\n",
    "    features = []\n",
    "    features = traversefeatures(root, features)\n",
    "    \n",
    "    x = [tensor[0] for tensor in features]\n",
    "    y = [tensor[1] for tensor in features]\n",
    "    z = [tensor[2] for tensor in features]\n",
    "    r = [tensor[3] for tensor in features]\n",
    " \n",
    "    norm(root, min(x), min(y), min(z), min(r), max(x), max(y), max(z), max(r))\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ArteryObjAN1-7.dat', 'ArteryObjAN1-7.dat', 'ArteryObjAN1-7.dat', 'ArteryObjAN1-7.dat', 'ArteryObjAN1-7.dat', 'ArteryObjAN1-7.dat', 'ArteryObjAN1-7.dat', 'ArteryObjAN1-7.dat']\n"
     ]
    }
   ],
   "source": [
    "def my_collate(batch):\n",
    "    return batch\n",
    "\n",
    "#t_list = ['ArteryObjAN1-7.dat','ArteryObjAN1-0.dat', 'ArteryObjAN1-17.dat',  'ArteryObjAN1-11.dat']\n",
    "\n",
    "t_list = ['ArteryObjAN1-0.dat','ArteryObjAN1-7.dat', 'ArteryObjAN1-17.dat',  'ArteryObjAN1-11.dat', 'ArteryObjAN1-19.dat', 'ArteryObjAN2-4.dat', 'ArteryObjAN2-6.dat', \n",
    "           'ArteryObjAN25-18.dat']\n",
    "t_list = ['ArteryObjAN1-7.dat','ArteryObjAN1-7.dat','ArteryObjAN1-7.dat','ArteryObjAN1-7.dat','ArteryObjAN1-7.dat','ArteryObjAN1-7.dat','ArteryObjAN1-7.dat', 'ArteryObjAN1-7.dat']\n",
    "#t_list = os.listdir(\"./trees\")[:20]\n",
    "print(t_list)\n",
    "class tDataset(Dataset):\n",
    "    def __init__(self, dir, transform=None):\n",
    "        self.names = dir\n",
    "        self.transform = transform\n",
    "        self.data = [] #lista con las strings de todos los arboles\n",
    "        for file in self.names:\n",
    "            self.data.append(read_tree(file))\n",
    "        self.trees = []\n",
    "        for tree in self.data:\n",
    "            deserial = deserialize(tree)\n",
    "            normalize_features(deserial)\n",
    "            self.trees.append(deserial)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #file = self.names[idx]\n",
    "        #string = read_tree(file)\n",
    "        tree = self.trees[idx]\n",
    "        return tree\n",
    "\n",
    "batch_size = 8\n",
    "dataset = tDataset(t_list)\n",
    "data_loader = DataLoader(dataset, batch_size = batch_size, shuffle=True, collate_fn=my_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[61, 61, 61, 61, 61, 61, 61, 61]\n",
      "61.0\n",
      "3.0\n",
      "56.0\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "n_no = []\n",
    "qzero = 0\n",
    "qOne = 0\n",
    "qtwo = 0\n",
    "\n",
    "for batch in data_loader:\n",
    "    for tree in batch:\n",
    "        count = []\n",
    "        n = tree.count_nodes(tree, count)\n",
    "        n_no.append(len(n))\n",
    "        li = []\n",
    "        tree.traverseInorderChilds(tree, li)\n",
    "        zero = [a for a in li if a == 0]\n",
    "        one = [a for a in li if a == 1]\n",
    "        two = [a for a in li if a == 2]\n",
    "        qzero += len(zero)\n",
    "        qOne += len(one)\n",
    "        qtwo += len(two)\n",
    "\n",
    "print(len(data_loader)*batch_size)\n",
    "print(n_no)\n",
    "nprom = np.mean(n_no)\n",
    "print(nprom)\n",
    "qzero /= len(data_loader)*batch_size\n",
    "qOne /= len(data_loader)*batch_size\n",
    "qtwo /= len(data_loader)*batch_size\n",
    "\n",
    "print(qzero)\n",
    "print(qOne)\n",
    "print(qtwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODED [tensor([[-0.0026,  0.1752, -0.0285,  ...,  0.0370, -0.1349,  0.0015],\n",
      "        [-0.0026,  0.1752, -0.0285,  ...,  0.0370, -0.1349,  0.0015],\n",
      "        [-0.0026,  0.1752, -0.0285,  ...,  0.0370, -0.1349,  0.0015],\n",
      "        ...,\n",
      "        [-0.0026,  0.1752, -0.0285,  ...,  0.0370, -0.1349,  0.0015],\n",
      "        [-0.0026,  0.1752, -0.0285,  ...,  0.0370, -0.1349,  0.0015],\n",
      "        [-0.0026,  0.1752, -0.0285,  ...,  0.0370, -0.1349,  0.0015]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "import torch_f\n",
    "enc_fold = torch_f.Fold(device)\n",
    "enc_fold_nodes = []     # list of fold nodes for encoding, lista con la \"hoja de ruta\" de los dos arboles\n",
    "batch = iter(data_loader).next()\n",
    "for example in batch:\n",
    "        #enc_fold.add('leafEncoder', example.radius)\n",
    "        #enc_fold_nodes.append(enc_fold.add('leafEncoder', example.radius))\n",
    "        enc_fold_nodes.append(encode_structure_fold(enc_fold, example))\n",
    "\n",
    "        #print(\"enc fold nodes\", enc_fold)\n",
    "enc_fold_nodes = enc_fold.apply(gencoder, [enc_fold_nodes])\n",
    "print(\"ENCODED\",enc_fold_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODED torch.Size([8, 128])\n"
     ]
    }
   ],
   "source": [
    "print(\"ENCODED\",enc_fold_nodes[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_structure( root):\n",
    "    \n",
    "    \n",
    "    def encode_node(node):\n",
    "        if node is None:\n",
    "            return\n",
    "        if node.is_leaf():\n",
    "            return gencoder.leafEncoder(node.radius.reshape(-1,4))\n",
    "        elif node.is_two_child():\n",
    "            \n",
    "\n",
    "            left = encode_node(node.left)\n",
    "            right = encode_node(node.right)\n",
    "            print(\"right\", right)\n",
    "            print(\"left\", left)\n",
    "            return gencoder.internalEncoder(node.radius.reshape(-1,4), left, right)\n",
    "        else:\n",
    "            right = encode_node(node.right)\n",
    "            return gencoder.rightEncoder(node.radius.reshape(-1,4), right)\n",
    "        \n",
    "\n",
    "    encoding = encode_node(root)\n",
    "    #return fold.add('sampleEncoder', encoding)\n",
    "    return encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data [<__main__.Node object at 0x000001826FA83730>, <__main__.Node object at 0x000001826FAE4EB0>, <__main__.Node object at 0x000001826FA83010>, <__main__.Node object at 0x000001826FAE48B0>, <__main__.Node object at 0x000001826FAE6800>, <__main__.Node object at 0x000001826FAE7D30>, <__main__.Node object at 0x000001826FB06B00>, <__main__.Node object at 0x000001826FB07BE0>]\n",
      "data <__main__.Node object at 0x000001826FA83730>\n",
      "right tensor([[-8.0241e-02, -1.3209e-01, -1.1694e-02,  6.4178e-02, -1.0668e-01,\n",
      "          9.3040e-02, -1.7474e-02, -1.1865e-01, -1.0348e-01,  6.1720e-02,\n",
      "         -9.9721e-02,  1.6098e-01, -2.0763e-01,  1.3070e-01,  4.3113e-03,\n",
      "         -1.2500e-01, -7.5596e-02,  7.9006e-02, -6.5657e-02,  4.4135e-02,\n",
      "         -4.2779e-02, -3.4956e-04, -1.1364e-01, -6.3175e-02, -1.8682e-02,\n",
      "          4.8230e-02, -4.2590e-02, -2.1231e-02, -1.2573e-01, -9.6575e-02,\n",
      "          1.0605e-01, -1.4574e-01, -7.6381e-02, -1.1214e-01,  6.6220e-02,\n",
      "          9.6129e-02,  1.9026e-03,  3.9336e-03,  1.0526e-01,  4.6488e-02,\n",
      "         -1.1953e-01, -1.9290e-02, -8.2107e-02, -2.4176e-01,  3.2674e-02,\n",
      "         -1.0093e-01, -7.7589e-02,  3.1573e-02,  6.0425e-02,  6.8984e-02,\n",
      "         -4.4520e-02,  2.4181e-02, -2.1203e-01, -9.6355e-02,  1.7732e-01,\n",
      "          1.0107e-01,  1.1121e-01, -4.4913e-02,  1.0157e-04, -1.2941e-02,\n",
      "          1.8293e-01, -6.2244e-03, -5.8242e-02, -4.1364e-03,  6.9701e-02,\n",
      "         -1.1208e-01,  1.0454e-01, -7.7758e-02,  2.1076e-02, -1.2975e-03,\n",
      "         -6.6641e-02,  3.9715e-02,  3.1470e-02, -7.9474e-03,  5.6430e-02,\n",
      "          1.8546e-03,  9.1323e-03,  2.6157e-02,  1.1329e-01,  1.5994e-02,\n",
      "          2.3211e-02,  4.0163e-02,  1.9093e-01,  7.9024e-02,  1.5514e-02,\n",
      "          1.0399e-01,  4.8905e-02, -2.1836e-02,  1.6442e-03,  1.6819e-01,\n",
      "          1.6686e-01, -4.1036e-02, -7.7224e-02, -1.0482e-01, -1.0496e-01,\n",
      "          1.6825e-01, -1.8333e-01,  2.9692e-03, -5.5822e-02,  3.9190e-02,\n",
      "         -5.3507e-03, -1.9589e-02, -1.1794e-02, -1.5919e-02, -5.5275e-02,\n",
      "         -1.0174e-01,  7.1504e-02,  1.8057e-01, -1.3702e-01, -1.6384e-02,\n",
      "          7.7142e-02, -7.5003e-02,  9.0023e-02,  4.1485e-02, -8.5944e-02,\n",
      "         -2.3026e-01, -3.4326e-02, -2.3177e-02,  1.4573e-01, -6.0074e-02,\n",
      "          3.9978e-02,  1.5279e-01,  5.5326e-02,  5.9247e-02, -1.7722e-03,\n",
      "          1.1089e-01,  2.7630e-02, -6.1363e-02]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "left tensor([[-0.0802, -0.1055,  0.0538,  0.1312, -0.0657,  0.0953, -0.0445, -0.1496,\n",
      "         -0.1415,  0.0690, -0.1343,  0.1900, -0.2260,  0.0941, -0.0179, -0.1218,\n",
      "         -0.0982,  0.0278, -0.0565,  0.0566, -0.0933,  0.0147, -0.0945,  0.0161,\n",
      "         -0.0362,  0.0480, -0.0027, -0.0359, -0.1263, -0.1004,  0.0513, -0.1402,\n",
      "         -0.0946, -0.1105,  0.0817,  0.1065,  0.0419, -0.0060,  0.0791,  0.0370,\n",
      "         -0.1254, -0.0715, -0.1211, -0.2217,  0.0334,  0.0346, -0.0961, -0.1058,\n",
      "          0.0296,  0.1528, -0.0803,  0.0221, -0.2229, -0.1282,  0.1130,  0.0275,\n",
      "          0.0674, -0.0297,  0.0708, -0.0606,  0.0607, -0.0894, -0.0547, -0.0262,\n",
      "          0.0816, -0.0955,  0.1451, -0.1115,  0.0469,  0.0342, -0.0924,  0.0123,\n",
      "          0.0473, -0.0607,  0.0945, -0.0030,  0.0253, -0.0514,  0.1171,  0.0114,\n",
      "          0.0021,  0.0258,  0.1678,  0.0049,  0.0782,  0.0451,  0.0417, -0.0226,\n",
      "         -0.0436,  0.1146,  0.1485, -0.1011, -0.1155, -0.0912, -0.0995,  0.1438,\n",
      "         -0.1710, -0.0251, -0.0535,  0.1071, -0.0056, -0.0042, -0.0231,  0.0084,\n",
      "         -0.0622, -0.1182,  0.0307,  0.0998, -0.1213, -0.0215, -0.0339, -0.0381,\n",
      "          0.1513,  0.0670, -0.1414, -0.1992,  0.0149, -0.0326,  0.1781,  0.0004,\n",
      "         -0.0231,  0.1204,  0.0477,  0.0225, -0.0191,  0.1140,  0.0399, -0.0191]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "right tensor([[-0.0842, -0.0917,  0.0868,  0.1503, -0.0558,  0.1026, -0.0414, -0.1515,\n",
      "         -0.1542,  0.0560, -0.1344,  0.1820, -0.2397,  0.0867, -0.0331, -0.1334,\n",
      "         -0.1003,  0.0093, -0.0494,  0.0370, -0.1103,  0.0177, -0.1002,  0.0582,\n",
      "         -0.0327,  0.0521,  0.0070, -0.0391, -0.1054, -0.0975,  0.0397, -0.1273,\n",
      "         -0.0716, -0.1138,  0.0904,  0.1007,  0.0513, -0.0203,  0.0814,  0.0284,\n",
      "         -0.1201, -0.0943, -0.1314, -0.2246,  0.0289,  0.0575, -0.1038, -0.1386,\n",
      "          0.0488,  0.1650, -0.1079,  0.0155, -0.2313, -0.1491,  0.0848,  0.0173,\n",
      "          0.0563, -0.0145,  0.0746, -0.0619,  0.0220, -0.0985, -0.0353, -0.0442,\n",
      "          0.0898, -0.0867,  0.1647, -0.1085,  0.0595,  0.0462, -0.1175,  0.0015,\n",
      "          0.0640, -0.0628,  0.1080, -0.0116,  0.0357, -0.0690,  0.1291,  0.0071,\n",
      "          0.0059,  0.0409,  0.1561, -0.0236,  0.0925,  0.0390,  0.0352, -0.0171,\n",
      "         -0.0326,  0.0955,  0.1561, -0.1145, -0.1151, -0.0737, -0.0905,  0.1235,\n",
      "         -0.1503, -0.0301, -0.0465,  0.1155, -0.0025,  0.0046, -0.0214,  0.0235,\n",
      "         -0.0703, -0.1240,  0.0049,  0.0875, -0.1190, -0.0337, -0.0554, -0.0169,\n",
      "          0.1708,  0.0907, -0.1650, -0.1819,  0.0331, -0.0435,  0.1728,  0.0122,\n",
      "         -0.0534,  0.1157,  0.0425, -0.0053, -0.0281,  0.1122,  0.0360, -0.0032]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "left tensor([[-0.0924, -0.0579,  0.0752,  0.1879,  0.0318,  0.0918, -0.0678, -0.1687,\n",
      "         -0.1547,  0.0955, -0.1125,  0.2252, -0.2633,  0.0550, -0.0317, -0.1170,\n",
      "         -0.1357,  0.0308, -0.0530,  0.0562, -0.0305,  0.0684, -0.0982,  0.0516,\n",
      "         -0.0580,  0.0741,  0.0017,  0.0283, -0.0889, -0.1381,  0.0169, -0.0871,\n",
      "         -0.0440, -0.1465,  0.0915,  0.1234,  0.1066, -0.0413,  0.1028,  0.0207,\n",
      "         -0.0768, -0.1130, -0.1434, -0.2562,  0.0316,  0.0851, -0.0110, -0.1748,\n",
      "          0.0256,  0.2154, -0.1045,  0.0655, -0.2530, -0.1454,  0.1036, -0.0299,\n",
      "          0.0297, -0.0042,  0.0220, -0.0828,  0.0808, -0.0665, -0.0368, -0.0241,\n",
      "          0.1318, -0.0867,  0.1582, -0.0612,  0.0801,  0.0571, -0.1145,  0.0238,\n",
      "          0.0771, -0.0823,  0.1031,  0.0199,  0.0549, -0.0511,  0.1640, -0.0117,\n",
      "          0.0715,  0.0338,  0.1254, -0.0172,  0.0915,  0.0307,  0.0536, -0.0417,\n",
      "         -0.0440,  0.1029,  0.1061, -0.0900, -0.1779, -0.0911, -0.0816,  0.1440,\n",
      "         -0.0780, -0.0841, -0.0147,  0.1475,  0.0318, -0.0596,  0.0188,  0.0490,\n",
      "         -0.1191, -0.1106,  0.0160,  0.0813, -0.1146,  0.0398, -0.0410,  0.0114,\n",
      "          0.1378,  0.1519, -0.1626, -0.1962,  0.0771,  0.0057,  0.1518,  0.0494,\n",
      "         -0.0327,  0.1117,  0.0531, -0.0364, -0.0877,  0.0642,  0.0394, -0.0156]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for data in data_loader:\n",
    "    print(\"data\",data)\n",
    "    data = data[0]\n",
    "    print(\"data\",data)\n",
    "\n",
    "    enc_f = encode_structure(data).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encodeado sin batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0027,  0.1752, -0.0285, -0.0784,  0.0358,  0.0278, -0.0273,  0.0520,\n",
       "          0.0496, -0.0078,  0.0383, -0.0248,  0.0149,  0.1616, -0.1669, -0.1386,\n",
       "         -0.0058,  0.0681, -0.1032,  0.0032,  0.0566, -0.0406, -0.0838,  0.0198,\n",
       "          0.2157,  0.0758,  0.1168,  0.0395,  0.1142,  0.1369, -0.1324, -0.0146,\n",
       "          0.1393, -0.2041,  0.0408,  0.2378, -0.1168,  0.0736, -0.2224, -0.1507,\n",
       "          0.0105, -0.0405,  0.0673,  0.0202, -0.0572, -0.1223,  0.0023,  0.0892,\n",
       "         -0.1261,  0.0985,  0.0343, -0.0242,  0.0502, -0.0218, -0.0792, -0.1821,\n",
       "         -0.1557, -0.1379, -0.0173,  0.1947,  0.0029,  0.0020, -0.0598,  0.0483,\n",
       "         -0.1256,  0.1992, -0.0305,  0.1387,  0.0676, -0.0245, -0.1319, -0.0415,\n",
       "          0.0783,  0.1869, -0.0664, -0.0418, -0.0693, -0.1703,  0.1616, -0.0100,\n",
       "         -0.1639, -0.0472,  0.0638,  0.1809,  0.0242,  0.1264, -0.0915, -0.0213,\n",
       "          0.0523, -0.0926,  0.0883, -0.0089,  0.1756,  0.1143, -0.1364,  0.1158,\n",
       "         -0.0533,  0.0091, -0.0531,  0.1421, -0.0779,  0.2023, -0.0915,  0.0827,\n",
       "         -0.2424, -0.0505, -0.0888, -0.0651, -0.0627, -0.1581, -0.0202,  0.0586,\n",
       "         -0.2123,  0.1266, -0.0529,  0.1121, -0.0926,  0.0484,  0.1872,  0.0469,\n",
       "          0.0177,  0.0215, -0.2356,  0.1667,  0.0023,  0.0370, -0.1349,  0.0015]],\n",
       "       device='cuda:0', grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encodeado con batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0026,  0.1752, -0.0285,  ...,  0.0370, -0.1349,  0.0015],\n",
       "        [-0.0026,  0.1752, -0.0285,  ...,  0.0370, -0.1349,  0.0015],\n",
       "        [-0.0026,  0.1752, -0.0285,  ...,  0.0370, -0.1349,  0.0015],\n",
       "        ...,\n",
       "        [-0.0026,  0.1752, -0.0285,  ...,  0.0370, -0.1349,  0.0015],\n",
       "        [-0.0026,  0.1752, -0.0285,  ...,  0.0370, -0.1349,  0.0015],\n",
       "        [-0.0026,  0.1752, -0.0285,  ...,  0.0370, -0.1349,  0.0015]],\n",
       "       device='cuda:0', grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_fold_nodes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en el loop creo un fold, mando este fold con cada uno de los arboles del batch a encode_structure_fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, latent_size : int, hidden_size : int):\n",
    "        super(NodeClassifier, self).__init__()\n",
    "        self.mlp1 = nn.Linear(latent_size, hidden_size*2)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.mlp2 = nn.Linear(hidden_size*2, hidden_size)\n",
    "\n",
    "        self.tanh2 = nn.Tanh()\n",
    "        self.mlp3 = nn.Linear(hidden_size, 3)\n",
    "\n",
    "    def forward(self, input_feature):\n",
    "        #print(\"classifier input\", input_feature.shape)\n",
    "\n",
    "        output = self.mlp1(input_feature)\n",
    "        output = self.tanh(output)\n",
    "        output = self.mlp2(output)\n",
    "\n",
    "        output = self.tanh2(output)\n",
    "        output = self.mlp3(output)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InternalDecoder(nn.Module):\n",
    "    \n",
    "    \"\"\" Decode an input (parent) feature into a left-child and a right-child feature \"\"\"\n",
    "    def __init__(self, latent_size : int, hidden_size: int):\n",
    "        super(InternalDecoder, self).__init__()\n",
    "        self.mlp = nn.Linear(latent_size,hidden_size)\n",
    "        self.lp2 = nn.Linear(hidden_size, latent_size)\n",
    "        self.mlp_right = nn.Linear(latent_size, latent_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.mlp2 = nn.Linear(latent_size,4)\n",
    "\n",
    "    def forward(self, parent_feature):\n",
    "        #print(\"internal decoder\")\n",
    "        #print(\"input\", parent_feature.shape)\n",
    "        vector = self.mlp(parent_feature)\n",
    "        vector = self.tanh(vector)\n",
    "        vector = self.lp2(vector)\n",
    "        vector = self.tanh(vector)\n",
    "        right_feature = self.mlp_right(vector)\n",
    "        right_feature = self.tanh(right_feature)\n",
    "        rad_feature = self.mlp2(vector)\n",
    "\n",
    "        return right_feature, rad_feature\n",
    "\n",
    "class BifurcationDecoder(nn.Module):\n",
    "    \n",
    "    \"\"\" Decode an input (parent) feature into a left-child and a right-child feature \"\"\"\n",
    "    def __init__(self, latent_size : int, hidden_size : int):\n",
    "        super(BifurcationDecoder, self).__init__()\n",
    "        #self.mlp = nn.Linear(latent_size,hidden_size)\n",
    "        self.mlp = nn.Linear(latent_size,hidden_size)\n",
    "        self.lp2 = nn.Linear(hidden_size, latent_size)\n",
    "        self.mlp_left = nn.Linear(latent_size, latent_size)\n",
    "        self.mlp_right = nn.Linear(latent_size, latent_size)\n",
    "        self.mlp2 = nn.Linear(latent_size,4)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, parent_feature):\n",
    "        #print(\"bifurcation decoder input\", parent_feature.shape)\n",
    "        parent_feature = parent_feature.reshape(-1,128)\n",
    "        #print(\"bifurcation decoder input\", parent_feature.shape)\n",
    "        vector = self.mlp(parent_feature)\n",
    "        #print(\"v1\", vector.shape)\n",
    "        vector = self.tanh(vector)\n",
    "        #print(\"v2\", vector.shape)\n",
    "        vector = self.lp2(vector)\n",
    "        #print(\"v3\", vector.shape)\n",
    "        vector = self.tanh(vector)\n",
    "        left_feature = self.mlp_left(vector)\n",
    "        left_feature = self.tanh(left_feature)\n",
    "        right_feature = self.mlp_right(vector)\n",
    "        right_feature = self.tanh(right_feature)\n",
    "        rad_feature = self.mlp2(vector)\n",
    "        #print(\"exiting bif dec\")\n",
    "        return left_feature, right_feature, rad_feature\n",
    "\n",
    "\n",
    "\n",
    "class featureDecoder(nn.Module):\n",
    "    \n",
    "    \"\"\" Decode an input (parent) feature into a left-child and a right-child feature \"\"\"\n",
    "    def __init__(self, latent_size : int, hidden_size: int):\n",
    "        super(featureDecoder, self).__init__()\n",
    "        self.mlp = nn.Linear(latent_size,hidden_size)\n",
    "        self.mlp2 = nn.Linear(hidden_size, latent_size)\n",
    "        self.mlp3 = nn.Linear(latent_size, latent_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.mlp4 = nn.Linear(latent_size,4)\n",
    "\n",
    "    def forward(self, parent_feature):\n",
    "        #print(\"feature decoder input\", parent_feature.shape)\n",
    "\n",
    "        vector = self.mlp(parent_feature)\n",
    "        vector = self.tanh(vector)\n",
    "        vector = self.mlp2(vector)\n",
    "        vector = self.tanh(vector)\n",
    "        vector = self.mlp3(vector)\n",
    "        vector = self.tanh(vector)\n",
    "        vector = self.mlp4(vector)\n",
    "       \n",
    "        return vector\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GRASSDecoder(nn.Module):\n",
    "    def __init__(self, latent_size : int, hidden_size: int, mult: torch.Tensor):\n",
    "        super(GRASSDecoder, self).__init__()\n",
    "        self.feature_decoder = featureDecoder(latent_size, hidden_size)\n",
    "        self.internal_decoder = InternalDecoder(latent_size, hidden_size)\n",
    "        self.bifurcation_decoder = BifurcationDecoder(latent_size, hidden_size)\n",
    "        self.node_classifier = NodeClassifier(latent_size, hidden_size)\n",
    "        self.mseLoss = nn.MSELoss()  # pytorch's mean squared error loss\n",
    "        self.ceLoss = nn.CrossEntropyLoss(weight = mult)  # pytorch's cross entropy loss (NOTE: no softmax is needed before)\n",
    "\n",
    "    def featureDecoder(self, feature):\n",
    "        return self.feature_decoder(feature)\n",
    "\n",
    "    def internalDecoder(self, feature):\n",
    "        return self.internal_decoder(feature)\n",
    "\n",
    "    def bifurcationDecoder(self, feature):\n",
    "        return self.bifurcation_decoder(feature)\n",
    "\n",
    "    def nodeClassifier(self, feature):\n",
    "        return self.node_classifier(feature)\n",
    "\n",
    "    def calcularLossAtributo(self, nodo, radio):\n",
    "        if nodo is None:\n",
    "            return\n",
    "        else:\n",
    "            #print(\"radio\", radio)\n",
    "            #print(\"nodo\", nodo)\n",
    "            nodo = torch.stack(nodo)\n",
    "            #print(\"nodo stack\", nodo)\n",
    "            #radio = radio.reshape(-1,4)\n",
    "        \n",
    "            #return mse\n",
    "            #return torch.cat([self.mseLoss(b, gt) for b, gt in zip(radio, nodo)], 0)\n",
    "            z = zip(radio.reshape(-1,4), nodo.reshape(-1,4))\n",
    "            \n",
    "            #for b, gt in z:\n",
    "            #    print(\"bgt\", b, gt)\n",
    "                \n",
    "            \n",
    "            l = [self.mseLoss(b.reshape(1,4), gt.reshape(1,4)) for b, gt in zip(radio.reshape(-1,4), nodo.reshape(-1,4))]\n",
    "            #print(\"loss\", l)\n",
    "            return l\n",
    "\n",
    "\n",
    "    def classifyLossEstimator(self, label_vector, original):\n",
    "        if original is None:\n",
    "            return\n",
    "        else:\n",
    "           \n",
    "            v = []\n",
    "            for o in original:\n",
    "                if o == 0:\n",
    "                    vector = torch.tensor([1, 0, 0], device=device, dtype = torch.float)\n",
    "                if o == 1:\n",
    "                    vector = torch.tensor([0, 1, 0], device=device, dtype = torch.float)\n",
    "                if o == 2:\n",
    "                    vector = torch.tensor([0, 0, 1], device=device, dtype = torch.float)\n",
    "                v.append(vector)\n",
    "\n",
    "            v = torch.stack(v)\n",
    "            z = zip(label_vector.reshape(-1,3), v.reshape(-1,3))   \n",
    "            l = [self.ceLoss(b.reshape(1,3), gt.reshape(1,3)).mul(0.6) for b, gt in zip(label_vector.reshape(-1,3), v.reshape(-1,3))]\n",
    "            \n",
    "            return l\n",
    "            #return c\n",
    "       # return torch.cat([self.creLoss(l.unsqueeze(0), gt).mul(0.2) for l, gt in zip(label_vector, gt_label_vector)], 0)\n",
    "\n",
    "    def vectorAdder(self, v1, v2, v3 = None, v4 = None):\n",
    "        \n",
    "        v = v1.add_(v2)\n",
    "        #print(\"v0\", v)\n",
    "        if v3 is not None:\n",
    "            v = v.add_(v3)\n",
    "        #print(\"v0\", v)\n",
    "        if v4 is not None:\n",
    "            v = v.add_(v4)\n",
    "       \n",
    "        return v\n",
    "\n",
    "mult = torch.tensor([1/round(qzero),1/round(qOne),1/round(qtwo)], device = device)\n",
    "Grassdecoder = GRASSDecoder(latent_size=128, hidden_size=256, mult = mult)\n",
    "Grassdecoder = Grassdecoder.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decode structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcularLossEstructura(cl_p, original):\n",
    "    \n",
    "    mult = torch.tensor([1/3.,1/66,1/2.], device = device)\n",
    "    ce = nn.CrossEntropyLoss(weight=mult)\n",
    "    if original.childs() == 0:\n",
    "        vector = [1, 0, 0] \n",
    "    if original.childs() == 1:\n",
    "        vector = [0, 1, 0]\n",
    "    if original.childs() == 2:\n",
    "        vector = [0, 0, 1] \n",
    "\n",
    "    c = ce(cl_p, torch.tensor(vector, device=device, dtype = torch.float).reshape(1, 3))\n",
    "    return c\n",
    "\n",
    "\n",
    "def calcularLossAtributo(nodo, radio):\n",
    "    \n",
    "    radio = radio.reshape(-1,4)\n",
    "    nodo = nodo.reshape(-1,4)\n",
    "    l2    = nn.MSELoss()\n",
    "   \n",
    "    mse = l2(radio, nodo.radius)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_structure_fold_grass(fold, v, root):\n",
    "    \n",
    "    def decode_node(fold, v, node):\n",
    "        \n",
    "        \n",
    "        if node.childs() == 0 : ##output del classifier\n",
    "            radio = fold.add('featureDecoder', v)\n",
    "            lossAtributo = fold.add('calcularLossAtributo', node, radio)\n",
    "            #lossAtributo = calcularLossAtributo( node, radio)\n",
    "            label = fold.add('nodeClassifier', v)\n",
    "            #lossEstructura = calcularLossEstructura()\n",
    "            lossEstructura = fold.add('classifyLossEstimator', label, node)  \n",
    "            #nd = createNode(1,radio, ce = lossEstructura,  mse = lossAtributo)          \n",
    "            return fold.add('vectorAdder', lossEstructura, lossAtributo)\n",
    "\n",
    "            \n",
    "            \n",
    "        elif node.childs() == 1 :\n",
    "            \n",
    "            right, radius = fold.add('internalDecoder', v).split(2)\n",
    "            label = fold.add('nodeClassifier', v)\n",
    "            nodoSiguiente = node.right\n",
    "            if nodoSiguiente is not None:\n",
    "                right_loss = decode_node(fold, right, nodoSiguiente)\n",
    "\n",
    "            lossEstructura = fold.add('classifyLossEstimator', label, node)\n",
    "            lossAtributo = fold.add('calcularLossAtributo', node, radius)\n",
    "\n",
    "        \n",
    "            return fold.add('vectorAdder', lossEstructura, right_loss, lossAtributo)\n",
    "            \n",
    "            \n",
    "\n",
    "        elif node.childs() == 2 :\n",
    "            left, right, radius = fold.add('bifurcationDecoder', v).split(3)\n",
    "            label = fold.add('nodeClassifier', v)\n",
    "            \n",
    "            \n",
    "            nodoSiguienteRight = node.right\n",
    "            nodoSiguienteLeft = node.left\n",
    "            if nodoSiguienteRight is not None:\n",
    "                right_loss = decode_node(fold, right, nodoSiguienteRight)\n",
    "             \n",
    "            if nodoSiguienteLeft is not None:\n",
    "                left_loss  = decode_node(fold, left, nodoSiguienteLeft)\n",
    "            lossEstructura = fold.add('classifyLossEstimator', label, node)\n",
    "            lossAtributo = fold.add('calcularLossAtributo', node, radius)\n",
    "            \n",
    "            return fold.add('vectorAdder', lossEstructura, right_loss, left_loss, lossAtributo)\n",
    "            \n",
    "\n",
    "    dec = decode_node (fold, v, root)\n",
    "    return dec\n",
    "\n",
    "def decode_structure(v, root):\n",
    "    \n",
    "    def decode_node(v, node):\n",
    "        \n",
    "        \n",
    "        if node.childs() == 0 : ##output del classifier\n",
    "            radio = Grassdecoder.featureDecoder(v)\n",
    "            lossAtributo = Grassdecoder.calcularLossAtributo(node, radio)\n",
    "            #lossAtributo = calcularLossAtributo( node, radio)\n",
    "            label = Grassdecoder.nodeClassifier(v)\n",
    "            lossEstructura = Grassdecoder.classifyLossEstimator(label, node)  \n",
    "              \n",
    "            return Grassdecoder.vectorAdder(lossEstructura, lossAtributo)\n",
    "\n",
    "            \n",
    "        elif node.childs() == 1 :\n",
    "            right, radius = Grassdecoder.internalDecoder(v)#.split(2)\n",
    "            label = Grassdecoder.nodeClassifier(v)\n",
    "            nodoSiguiente = node.right\n",
    "            if nodoSiguiente is not None:\n",
    "                right_loss = decode_node(right, nodoSiguiente)\n",
    "            lossEstructura =Grassdecoder.classifyLossEstimator(label, node)\n",
    "            lossAtributo = Grassdecoder.calcularLossAtributo( node, radius)\n",
    "\n",
    "        \n",
    "            return Grassdecoder.vectorAdder(lossEstructura, right_loss, lossAtributo)\n",
    "            \n",
    "            \n",
    "\n",
    "        elif node.childs() == 2 :\n",
    "            left, right, radius = Grassdecoder.bifurcationDecoder(v)#.split(3)\n",
    "            label = Grassdecoder.nodeClassifier(v)\n",
    "            nodoSiguienteRight = node.right\n",
    "            nodoSiguienteLeft = node.left\n",
    "            if nodoSiguienteRight is not None:\n",
    "                right_loss = decode_node(right, nodoSiguienteRight)\n",
    "             \n",
    "            if nodoSiguienteLeft is not None:\n",
    "                left_loss  = decode_node(left, nodoSiguienteLeft)\n",
    "            lossEstructura =Grassdecoder.classifyLossEstimator(label, node)\n",
    "            lossAtributo = Grassdecoder.calcularLossAtributo(node, radius)\n",
    "            \n",
    "            return Grassdecoder.vectorAdder(lossEstructura, right_loss, left_loss, lossAtributo)\n",
    "            \n",
    "\n",
    "    dec = decode_node (v, root)\n",
    "    return dec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decode testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_testing_grass(v, root, max):\n",
    "    def decode_node(v, node, max):\n",
    "        cl = Grassdecoder.nodeClassifier(v)\n",
    "        _, label = torch.max(cl, 1)\n",
    "        label = label.data\n",
    "        print\n",
    "        \n",
    "        if label == 0 and createNode.count <= max: ##output del classifier\n",
    "           \n",
    "            #lossEstructura = Grassdecoder.classifyLossEstimator(cl, node)\n",
    "            radio = Grassdecoder.featureDecoder(v)\n",
    "            #print(\"radius\", radio)\n",
    "            #lossAtrs = Grassdecoder.calcularLossAtributo( node, radio )\n",
    "           \n",
    "            return createNode(1,radio)\n",
    "\n",
    "        elif label == 1 and createNode.count <= max:\n",
    "       \n",
    "            right, radius = Grassdecoder.internalDecoder(v)\n",
    "            #print(\"radius\", radius)\n",
    "            \n",
    "            d = createNode(1, radius) \n",
    "            #print(\"d\", d.radius)\n",
    "             \n",
    "            if not node is None:\n",
    "                if not node.right is None:\n",
    "                    nodoSiguiente = node.right\n",
    "                else:\n",
    "                    nodoSiguiente = None\n",
    "            else:\n",
    "                nodoSiguiente = None\n",
    "            \n",
    "            d.right = decode_node(right, nodoSiguiente, max)\n",
    "            \n",
    "\n",
    "            return d\n",
    "       \n",
    "        elif label == 2 and createNode.count <= max:\n",
    "            left, right, radius = Grassdecoder.bifurcationDecoder(v)\n",
    "            #print(\"radius\", radius)\n",
    "            \n",
    "            d = createNode(1, radius )\n",
    "  \n",
    "            if not node is None: #el nodo existe, me fijo si tiene hijo der/izq\n",
    "                if not node.right is None:\n",
    "                    nodoSiguienteRight = node.right\n",
    "                else:\n",
    "                    nodoSiguienteRight = None\n",
    "                if not node.left is None:\n",
    "                    nodoSiguienteLeft = node.left\n",
    "                else:\n",
    "                    nodoSiguienteLeft = None\n",
    "            else: #el nodo no existe\n",
    "                nodoSiguienteRight = None\n",
    "                nodoSiguienteLeft = None\n",
    "            \n",
    "            d.right = decode_node(right, nodoSiguienteRight, max)\n",
    "            d.left = decode_node(left, nodoSiguienteLeft, max)\n",
    "            \n",
    "           \n",
    "            return d\n",
    "            \n",
    "    createNode.count = 0\n",
    "    dec = decode_node (v, root, max)\n",
    "    return dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveBestModel:\n",
    "    \"\"\"\n",
    "    Class to save the best model while training. If the current epoch's \n",
    "    validation loss is less than the previous least less, then save the\n",
    "    model state.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, best_valid_loss=float('inf')\n",
    "    ):\n",
    "        self.best_valid_loss = best_valid_loss\n",
    "        \n",
    "    def __call__(\n",
    "        self, current_valid_loss, \n",
    "        epoch, encoder, decoder, optimizer\n",
    "    ):\n",
    "        if current_valid_loss < self.best_valid_loss:\n",
    "            self.best_valid_loss = current_valid_loss\n",
    "            #print(f\"\\nBest validation loss: {self.best_valid_loss}\")\n",
    "            #print(f\"\\nSaving best model for epoch: {epoch+1}\\n\")\n",
    "            #'classifier_state_dict': classifier.state_dict(),\n",
    "            torch.save({\n",
    "                'epoch': epoch+1,\n",
    "                'encoder_state_dict': encoder.state_dict(),\n",
    "                'decoder_state_dict': decoder.state_dict(),\n",
    "                \n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, 'outputs/best_model.pth')\n",
    "\n",
    "save_best_model = SaveBestModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 10000] average reconstruction error: 0.303813 \n",
      "Epoch [11 / 10000] average reconstruction error: 0.247892 \n",
      "Epoch [21 / 10000] average reconstruction error: 0.193058 \n",
      "Epoch [31 / 10000] average reconstruction error: 0.130594 \n",
      "Epoch [41 / 10000] average reconstruction error: 0.090713 \n",
      "Epoch [51 / 10000] average reconstruction error: 0.082077 \n",
      "Epoch [61 / 10000] average reconstruction error: 0.078756 \n",
      "Epoch [71 / 10000] average reconstruction error: 0.074781 \n",
      "Epoch [81 / 10000] average reconstruction error: 0.073681 \n",
      "Epoch [91 / 10000] average reconstruction error: 0.072962 \n",
      "Epoch [101 / 10000] average reconstruction error: 0.072330 \n",
      "Epoch [111 / 10000] average reconstruction error: 0.071772 \n",
      "Epoch [121 / 10000] average reconstruction error: 0.071280 \n",
      "Epoch [131 / 10000] average reconstruction error: 0.070828 \n",
      "Epoch [141 / 10000] average reconstruction error: 0.070366 \n",
      "Epoch [151 / 10000] average reconstruction error: 0.069831 \n",
      "Epoch [161 / 10000] average reconstruction error: 0.069172 \n",
      "Epoch [171 / 10000] average reconstruction error: 0.068310 \n",
      "Epoch [181 / 10000] average reconstruction error: 0.067069 \n",
      "Epoch [191 / 10000] average reconstruction error: 0.064843 \n",
      "Epoch [201 / 10000] average reconstruction error: 0.056827 \n",
      "Epoch [211 / 10000] average reconstruction error: 0.041098 \n",
      "Epoch [221 / 10000] average reconstruction error: 0.032917 \n",
      "Epoch [231 / 10000] average reconstruction error: 0.025536 \n",
      "Epoch [241 / 10000] average reconstruction error: 0.021432 \n",
      "Epoch [251 / 10000] average reconstruction error: 0.020314 \n",
      "Epoch [261 / 10000] average reconstruction error: 0.018835 \n",
      "Epoch [271 / 10000] average reconstruction error: 0.016793 \n",
      "Epoch [281 / 10000] average reconstruction error: 0.013672 \n",
      "Epoch [291 / 10000] average reconstruction error: 0.010901 \n",
      "Epoch [301 / 10000] average reconstruction error: 0.023285 \n",
      "Epoch [311 / 10000] average reconstruction error: 0.017931 \n",
      "Epoch [321 / 10000] average reconstruction error: 0.013288 \n",
      "Epoch [331 / 10000] average reconstruction error: 0.010282 \n",
      "Epoch [341 / 10000] average reconstruction error: 0.008738 \n",
      "Epoch [351 / 10000] average reconstruction error: 0.007831 \n",
      "Epoch [361 / 10000] average reconstruction error: 0.007075 \n",
      "Epoch [371 / 10000] average reconstruction error: 0.006596 \n",
      "Epoch [381 / 10000] average reconstruction error: 0.006281 \n",
      "Epoch [391 / 10000] average reconstruction error: 0.018045 \n",
      "Epoch [401 / 10000] average reconstruction error: 0.011304 \n",
      "Epoch [411 / 10000] average reconstruction error: 0.009732 \n",
      "Epoch [421 / 10000] average reconstruction error: 0.007804 \n",
      "Epoch [431 / 10000] average reconstruction error: 0.006974 \n",
      "Epoch [441 / 10000] average reconstruction error: 0.006322 \n",
      "Epoch [451 / 10000] average reconstruction error: 0.005865 \n",
      "Epoch [461 / 10000] average reconstruction error: 0.005573 \n",
      "Epoch [471 / 10000] average reconstruction error: 0.005327 \n",
      "Epoch [481 / 10000] average reconstruction error: 0.005149 \n",
      "Epoch [491 / 10000] average reconstruction error: 0.007674 \n",
      "Epoch [501 / 10000] average reconstruction error: 0.015442 \n",
      "Epoch [511 / 10000] average reconstruction error: 0.012246 \n",
      "Epoch [521 / 10000] average reconstruction error: 0.010010 \n",
      "Epoch [531 / 10000] average reconstruction error: 0.007794 \n",
      "Epoch [541 / 10000] average reconstruction error: 0.006495 \n",
      "Epoch [551 / 10000] average reconstruction error: 0.005802 \n",
      "Epoch [561 / 10000] average reconstruction error: 0.005310 \n",
      "Epoch [571 / 10000] average reconstruction error: 0.004988 \n",
      "Epoch [581 / 10000] average reconstruction error: 0.004738 \n",
      "Epoch [591 / 10000] average reconstruction error: 0.004534 \n",
      "Epoch [601 / 10000] average reconstruction error: 0.004359 \n",
      "Epoch [611 / 10000] average reconstruction error: 0.004198 \n",
      "Epoch [621 / 10000] average reconstruction error: 0.004050 \n",
      "Epoch [631 / 10000] average reconstruction error: 0.018423 \n",
      "Epoch [641 / 10000] average reconstruction error: 0.026551 \n",
      "Epoch [651 / 10000] average reconstruction error: 0.012408 \n",
      "Epoch [661 / 10000] average reconstruction error: 0.009476 \n",
      "Epoch [671 / 10000] average reconstruction error: 0.007672 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Documents\\repo\\Intra\\autoencoder\\autoencoder_fold.ipynb Celda 35\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X46sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     dec_fold_nodes\u001b[39m.\u001b[39mappend(decode_structure_fold_grass(dec_fold, fnode, example))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X46sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# Apply the computations on the decoder model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X46sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m#print(\"dec fold nodes\", dec_fold_nodes)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X46sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m total_loss \u001b[39m=\u001b[39m dec_fold\u001b[39m.\u001b[39;49mapply(Grassdecoder, [dec_fold_nodes])\u001b[39m#[0]\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X46sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m#print(\"total_loss\", total_loss)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X46sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     \u001b[39m# the first dim of total_loss is for reconstruction and the second for KL divergence\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X46sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39m# Do parameter optimization\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X46sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39m#print(\"total_loss\", total_loss)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X46sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m n_nodes \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(n_nodes, device \u001b[39m=\u001b[39m device)\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\repo\\Intra\\autoencoder\\torch_f.py:124\u001b[0m, in \u001b[0;36mFold.apply\u001b[1;34m(self, nn, nodes)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mError while executing node \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m[\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m] with args: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (op, step, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step][op]))\n\u001b[0;32m    122\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49mbatched_args)\n\u001b[0;32m    126\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m)):\n\u001b[0;32m    127\u001b[0m     values[step][op] \u001b[39m=\u001b[39m []\n",
      "\u001b[1;32mc:\\Users\\User\\Documents\\repo\\Intra\\autoencoder\\autoencoder_fold.ipynb Celda 35\u001b[0m in \u001b[0;36mGRASSDecoder.classifyLossEstimator\u001b[1;34m(self, label_vector, original)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X46sZmlsZQ%3D%3D?line=138'>139</a>\u001b[0m     vector \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m], device\u001b[39m=\u001b[39mdevice, dtype \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfloat)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X46sZmlsZQ%3D%3D?line=139'>140</a>\u001b[0m \u001b[39mif\u001b[39;00m o \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X46sZmlsZQ%3D%3D?line=140'>141</a>\u001b[0m     vector \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor([\u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m0\u001b[39;49m], device\u001b[39m=\u001b[39;49mdevice, dtype \u001b[39m=\u001b[39;49m torch\u001b[39m.\u001b[39;49mfloat)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X46sZmlsZQ%3D%3D?line=141'>142</a>\u001b[0m \u001b[39mif\u001b[39;00m o \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X46sZmlsZQ%3D%3D?line=142'>143</a>\u001b[0m     vector \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m], device\u001b[39m=\u001b[39mdevice, dtype \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfloat)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "learning_rate = 1e-4\n",
    "\n",
    "\n",
    "params = list(gencoder.parameters()) + list(Grassdecoder.parameters()) \n",
    "\n",
    "opt = torch.optim.Adam(params, lr=learning_rate) \n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.MultiStepLR(opt, milestones=[200], gamma=0.1)\n",
    "    \n",
    "train_loss_avg = []\n",
    "#train_loss_avg.append(0)\n",
    "ce_avg = []\n",
    "mse_avg = []\n",
    "lr_list = []\n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    train_loss_avg.append(0)\n",
    "   #batch es cada arbol del dataloader\n",
    "    for batch_idx, batch in enumerate(data_loader):\n",
    "        # Initialize torchfold for *encoding*\n",
    "        enc_fold = torch_f.Fold(device)\n",
    "        enc_fold_nodes = []     # list of fold nodes for encoding, lista con la \"hoja de ruta\" de los dos arboles\n",
    "        # Collect computation nodes recursively from encoding process\n",
    "        n_nodes = []\n",
    "        for example in batch: #example es un arbolito\n",
    "            c = []\n",
    "            n = example.count_nodes(example, c)\n",
    "            n_nodes.append(len(n))\n",
    "            encode_structure_fold(enc_fold, example)\n",
    "            enc_fold_nodes.append(encode_structure_fold(enc_fold, example))\n",
    "       \n",
    "        # Apply the computations on the encoder model\n",
    "       \n",
    "        enc_fold_nodes = enc_fold.apply(gencoder, [enc_fold_nodes])\n",
    "        # Split into a list of fold nodes per example\n",
    "        #enc_fold_nodes = torch.split(enc_fold_nodes[0], 1, 0) #divide ele ncodeado en vectores de un elemento\n",
    "        #print(\"enc_fold_nodes\", enc_fold_nodes)\n",
    "        # Initialize torchfold for *decoding*\n",
    "        dec_fold = torch_f.Fold(device)\n",
    "        # Collect computation nodes recursively from decoding process\n",
    "        dec_fold_nodes = []\n",
    "        kld_fold_nodes = []\n",
    "\n",
    "        t_l = []\n",
    "        for f in enc_fold_nodes:\n",
    "            for t in f:\n",
    "                t_l.append(t)\n",
    "        for example, fnode in zip(batch, t_l): #example es el arbol y fnode el encodeado\n",
    "            #print(\"example\", example)\n",
    "            #print(\"fnode\", fnode) \n",
    "            #root_code, kl_div = torch.chunk(fnode, 2, 0)\n",
    "            dec_fold_nodes.append(decode_structure_fold_grass(dec_fold, fnode, example))\n",
    "        # Apply the computations on the decoder model\n",
    "        #print(\"dec fold nodes\", dec_fold_nodes)\n",
    "           \n",
    "                       \n",
    "        total_loss = dec_fold.apply(Grassdecoder, [dec_fold_nodes])#[0]\n",
    "        #print(\"total_loss\", total_loss)\n",
    "            # the first dim of total_loss is for reconstruction and the second for KL divergence\n",
    "        # Do parameter optimization\n",
    "        #print(\"total_loss\", total_loss)\n",
    "        n_nodes = torch.tensor(n_nodes, device = device)\n",
    "        #print(\"n\", n_nodes)\n",
    "        total_loss = torch.div(total_loss[0], n_nodes)\n",
    "        #print(\"div\", total_loss)\n",
    "        total_loss = total_loss.sum() / len(batch)  #n_nodes[0] #modificar y dividir por el promedio?\n",
    "        #print(\"total_loss\", total_loss)\n",
    "        opt.zero_grad()\n",
    "        #decoder_opt.zero_grad()\n",
    "        total_loss.backward()\n",
    "        opt.step()\n",
    "        #scheduler.step()\n",
    "        #decoder_opt.step()\n",
    "        train_loss_avg[-1] += (total_loss.item())\n",
    "        \n",
    "\n",
    "        \n",
    "    save_best_model(\n",
    "        total_loss, epoch, gencoder, Grassdecoder, opt)\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch [%d / %d] average reconstruction error: %f ' % (epoch+1, epochs, total_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = iter(data_loader).next()[0]\n",
    "enc_fold = torch_f.Fold(device)\n",
    "enc_fold_nodes = []\n",
    "enc_fold_nodes.append(encode_structure_fold(enc_fold, input))\n",
    "enc_fold_nodes = enc_fold.apply(gencoder, [enc_fold_nodes])\n",
    "encoded = enc_fold_nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 628\n"
     ]
    }
   ],
   "source": [
    "encoder = GRASSEncoder(input_size = 4, feature_size=128, hidden_size=32).to(device)\n",
    "decoder = GRASSDecoder(latent_size=128, hidden_size=256, mult = mult).to(device)\n",
    "\n",
    "checkpoint = torch.load(\"outputs/best_model.pth\")\n",
    "encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "print(\"epoch\", epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([[0.0545, 0.7690, 0.2951, 0.0048]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "1 tensor([[0.1672, 0.6812, 0.3740, 0.1865]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "2 tensor([[0.2238, 0.6524, 0.3636, 0.2762]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "3 tensor([[0.2537, 0.6889, 0.3452, 0.3039]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "4 tensor([[0.3010, 0.7223, 0.3396, 0.3087]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "5 tensor([[0.3457, 0.7462, 0.3302, 0.3048]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "6 tensor([[0.3904, 0.7662, 0.3184, 0.2979]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "7 tensor([[0.4358, 0.7832, 0.3054, 0.2898]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "8 tensor([[0.4819, 0.7976, 0.2921, 0.2821]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "9 tensor([[0.5283, 0.8093, 0.2794, 0.2756]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "10 tensor([[0.5740, 0.8179, 0.2685, 0.2712]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "11 tensor([[0.6182, 0.8233, 0.2605, 0.2699]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "12 tensor([[0.6595, 0.8254, 0.2562, 0.2721]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "13 tensor([[0.6971, 0.8240, 0.2563, 0.2780]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "14 tensor([[0.7301, 0.8196, 0.2612, 0.2879]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "15 tensor([[0.8356, 0.9899, 0.0931, 0.4794]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "16 tensor([[-0.1951,  0.3795, -0.2444,  0.3406]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "17 tensor([[-0.0286,  0.6962,  0.4351,  0.8968]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "18 tensor([[-0.0164,  0.6241,  0.6040,  0.6810]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "19 tensor([[-0.0184,  0.5387,  0.6168,  0.6013]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "20 tensor([[-0.0152,  0.4873,  0.6122,  0.5777]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "21 tensor([[-0.0067,  0.4587,  0.6222,  0.5816]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "22 tensor([[0.0037, 0.4377, 0.6415, 0.5972]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "23 tensor([[0.0141, 0.4160, 0.6659, 0.6180]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "24 tensor([[0.0237, 0.3903, 0.6931, 0.6406]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "25 tensor([[0.0330, 0.3595, 0.7208, 0.6622]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "26 tensor([[0.0423, 0.3245, 0.7470, 0.6812]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "27 tensor([[0.0526, 0.2875, 0.7696, 0.6959]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "28 tensor([[0.0640, 0.2513, 0.7871, 0.7058]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "29 tensor([[0.0766, 0.2187, 0.7996, 0.7115]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "30 tensor([[0.0901, 0.1918, 0.8077, 0.7140]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "31 tensor([[0.1038, 0.1713, 0.8124, 0.7145]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "32 tensor([[ 0.2364, -0.0518,  1.0033,  0.5261]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "33 tensor([[ 0.0675,  0.7473,  0.3092, -0.0136]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "34 tensor([[0.0386, 0.7773, 0.3224, 0.0659]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "35 tensor([[0.0609, 0.7064, 0.2067, 0.1370]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "36 tensor([[0.1100, 0.6793, 0.1960, 0.1327]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "37 tensor([[0.1667, 0.6909, 0.1827, 0.1274]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "38 tensor([[0.2233, 0.7139, 0.1729, 0.1242]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "39 tensor([[0.2775, 0.7375, 0.1633, 0.1214]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "40 tensor([[0.3297, 0.7588, 0.1535, 0.1184]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "41 tensor([[0.3797, 0.7772, 0.1441, 0.1161]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "42 tensor([[0.4279, 0.7925, 0.1356, 0.1149]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "43 tensor([[0.4740, 0.8049, 0.1289, 0.1156]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "44 tensor([[0.5181, 0.8148, 0.1246, 0.1187]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "45 tensor([[0.5601, 0.8225, 0.1231, 0.1244]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "46 tensor([[0.5996, 0.8280, 0.1246, 0.1328]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "47 tensor([[0.6365, 0.8316, 0.1292, 0.1437]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "48 tensor([[0.6704, 0.8333, 0.1366, 0.1571]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "49 tensor([[0.7012, 0.8332, 0.1471, 0.1727]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "50 tensor([[0.7287, 0.8315, 0.1603, 0.1902]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "51 tensor([[0.7530, 0.8280, 0.1761, 0.2096]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "52 tensor([[ 0.8430,  1.0415, -0.0175,  0.4298]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = iter(data_loader).next()[1]\n",
    "enc_fold = torch_f.Fold(device)\n",
    "enc_fold_nodes = []\n",
    "enc_fold_nodes.append(encode_structure_fold(enc_fold, input))\n",
    "enc_fold_nodes = enc_fold.apply(gencoder, [enc_fold_nodes])\n",
    "encoded = enc_fold_nodes[0]\n",
    "decoded = decode_testing_grass(encoded, input, 200)\n",
    "count = []\n",
    "numerar_nodos(decoded, count)\n",
    "decoded.traverseInorder(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a08c5c9848e043449255cc39254e33b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(0.5, 0.5,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotTree(input, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47684518490c45759c5c3b426ee22d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(0.3239407…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotTree(decoded, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = []\n",
    "n_nodes = input.count_nodes(input,c)\n",
    "len(n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = []\n",
    "n_nodes = decoded.count_nodes(decoded,c)\n",
    "len(n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 26 2\n"
     ]
    }
   ],
   "source": [
    "li = []\n",
    "decoded.traverseInorderChilds(decoded, li)\n",
    "zero = [a for a in li if a == 0]\n",
    "one = [a for a in li if a == 1]\n",
    "two = [a for a in li if a == 2]\n",
    "qzero = len(zero)\n",
    "qOne = len(one)\n",
    "qtwo = len(two)\n",
    "print(qzero, qOne, qtwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 56 2\n"
     ]
    }
   ],
   "source": [
    "li = []\n",
    "input.traverseInorderChilds(input, li)\n",
    "zero = [a for a in li if a == 0]\n",
    "one = [a for a in li if a == 1]\n",
    "two = [a for a in li if a == 2]\n",
    "qzero = len(zero)\n",
    "qOne = len(one)\n",
    "qtwo = len(two)\n",
    "print(qzero, qOne, qtwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (20,10))\n",
    "plt.plot(train_loss_avg) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py_torc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f3e717cd274da89498094fde320e6eab1bf0f52911d27cf47473187acb3fe8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
