{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import raiseExceptions\n",
    "from tokenize import Double\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "from vec3 import Vec3\n",
    "import meshplot as mp\n",
    "import torch\n",
    "torch.manual_seed(125)\n",
    "import random\n",
    "random.seed(125)\n",
    "import torch_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_fn(f):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        wrapper.count += 1\n",
    "        return f(*args, **kwargs)\n",
    "    wrapper.count = 0\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clase nodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    Class Node\n",
    "    \"\"\"\n",
    "    def __init__(self, value, radius, left = None, right = None, position = None, cl_prob= None, ce = None, mse = None):\n",
    "        self.left = left\n",
    "        self.data = value\n",
    "        self.radius = radius\n",
    "        self.position = position\n",
    "        self.right = right\n",
    "        self.prob = cl_prob\n",
    "        self.mse = mse\n",
    "        self.ce = ce\n",
    "        self.children = [self.left, self.right]\n",
    "    \n",
    "    def agregarHijo(self, children):\n",
    "\n",
    "        if self.right is None:\n",
    "            self.right = children\n",
    "        elif self.left is None:\n",
    "            self.left = children\n",
    "\n",
    "        else:\n",
    "            raise ValueError (\"solo arbol binario \")\n",
    "\n",
    "\n",
    "    def is_leaf(self):\n",
    "        if self.right is None:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def is_two_child(self):\n",
    "        if self.right is not None and self.left is not None:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def is_one_child(self):\n",
    "        if self.is_two_child():\n",
    "            return False\n",
    "        elif self.is_leaf():\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def childs(self):\n",
    "        if self.is_leaf():\n",
    "            return 0\n",
    "        if self.is_one_child():\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "    \n",
    "    \n",
    "    def traverseInorder(self, root):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            self.traverseInorder(root.left)\n",
    "            print (root.data, root.radius)\n",
    "            self.traverseInorder(root.right)\n",
    "\n",
    "    def traverseInorderLoss(self, root, loss):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            self.traverseInorderLoss(root.left, loss)\n",
    "            loss.append(root.prob)\n",
    "            self.traverseInorderLoss(root.right, loss)\n",
    "            return loss\n",
    "\n",
    "    def traverseInorderMSE(self, root, loss):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            self.traverseInorderMSE(root.left, loss)\n",
    "            loss.append(root.mse)\n",
    "            self.traverseInorderMSE(root.right, loss)\n",
    "            return loss\n",
    "\n",
    "    def traverseInorderCE(self, root, loss):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            self.traverseInorderCE(root.left, loss)\n",
    "            loss.append(root.ce)\n",
    "            self.traverseInorderCE(root.right, loss)\n",
    "            return loss\n",
    "\n",
    "    def traverseInorderChilds(self, root, l):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            self.traverseInorderChilds(root.left, l)\n",
    "            l.append(root.childs())\n",
    "            self.traverseInorderChilds(root.right, l)\n",
    "            return l\n",
    "\n",
    "    def preorder(self, root):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            print (root.data, root.radius)\n",
    "            self.preorder(root.left)\n",
    "            self.preorder(root.right)\n",
    "\n",
    "    def cloneBinaryTree(self, root):\n",
    "     \n",
    "        # base case\n",
    "        if root is None:\n",
    "            return None\n",
    "    \n",
    "        # create a new node with the same data as the root node\n",
    "        root_copy = Node(root.data, root.radius)\n",
    "    \n",
    "        # clone the left and right subtree\n",
    "        root_copy.left = self.cloneBinaryTree(root.left)\n",
    "        root_copy.right = self.cloneBinaryTree(root.right)\n",
    "    \n",
    "        # return cloned root node\n",
    "        return root_copy\n",
    "\n",
    "    def height(self, root):\n",
    "    # Check if the binary tree is empty\n",
    "        if root is None:\n",
    "            return 0 \n",
    "        # Recursively call height of each node\n",
    "        leftAns = self.height(root.left)\n",
    "        rightAns = self.height(root.right)\n",
    "    \n",
    "        # Return max(leftHeight, rightHeight) at each iteration\n",
    "        return max(leftAns, rightAns) + 1\n",
    "\n",
    "    # Print nodes at a current level\n",
    "    def printCurrentLevel(self, root, level):\n",
    "        if root is None:\n",
    "            return\n",
    "        if level == 1:\n",
    "            print(root.data, end=\" \")\n",
    "        elif level > 1:\n",
    "            self.printCurrentLevel(root.left, level-1)\n",
    "            self.printCurrentLevel(root.right, level-1)\n",
    "\n",
    "    def printLevelOrder(self, root):\n",
    "        h = self.height(root)\n",
    "        for i in range(1, h+1):\n",
    "            self.printCurrentLevel(root, i)\n",
    "\n",
    "\n",
    "    \n",
    "    def count_nodes(self, root, counter):\n",
    "        if   root is not None:\n",
    "            self.count_nodes(root.left, counter)\n",
    "            counter.append(root.data)\n",
    "            self.count_nodes(root.right, counter)\n",
    "            return counter\n",
    "\n",
    "    \n",
    "    def serialize(self, root):\n",
    "        def post_order(root):\n",
    "            if root:\n",
    "                post_order(root.left)\n",
    "                post_order(root.right)\n",
    "                ret[0] += str(root.data)+'_'+ str(root.radius) +';'\n",
    "                \n",
    "            else:\n",
    "                ret[0] += '#;'           \n",
    "\n",
    "        ret = ['']\n",
    "        post_order(root)\n",
    "        return ret[0][:-1]  # remove last ,\n",
    "\n",
    "    def toGraph( self, graph, index, dec, proc=True):\n",
    "        \n",
    "        \n",
    "        radius = self.radius.cpu().detach().numpy()\n",
    "        if dec:\n",
    "            radius= radius[0]\n",
    "        #print(\"posicion\", self.data, radius)\n",
    "        #print(\"right\", self.right)\n",
    "        \n",
    "        #graph.add_nodes_from( [ (index, {'posicion': radius[0:3], 'radio': radius[3] } ) ])\n",
    "        graph.add_nodes_from( [ (self.data, {'posicion': radius[0:3], 'radio': radius[3] } ) ])\n",
    "        \n",
    "\n",
    "        if self.right is not None:\n",
    "            #leftIndex = self.right.toGraph( graph, index + 1, dec)#\n",
    "            self.right.toGraph( graph, index + 1, dec)#\n",
    "            \n",
    "            #graph.add_edge( index, index + 1 )\n",
    "            graph.add_edge( self.data, self.right.data )\n",
    "            #if proc:\n",
    "            #    nx.set_edge_attributes( graph, {(index, index+1) : {'procesada':False}})\n",
    "        \n",
    "            if self.left is not None:\n",
    "                #retIndex = self.left.toGraph( graph, leftIndex, dec )#\n",
    "                self.left.toGraph( graph, 0, dec )#\n",
    "\n",
    "                #graph.add_edge( index, leftIndex)\n",
    "                graph.add_edge( self.data, self.left.data)\n",
    "                #if proc:\n",
    "                #    nx.set_edge_attributes( graph, {(index, leftIndex) : {'procesada':False}})\n",
    "            \n",
    "            else:\n",
    "                #return leftIndex\n",
    "                return\n",
    "\n",
    "        else:\n",
    "            #return index + 1\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTree( root, dec ):\n",
    "    graph = nx.Graph()\n",
    "    root.toGraph( graph, 0, dec)\n",
    "    edges=nx.get_edge_attributes(graph,'procesada')\n",
    "\n",
    "    p = mp.plot( np.array([ graph.nodes[v]['posicion'] for v in graph.nodes]), shading={'point_size':0.1}, return_plot=True)\n",
    "\n",
    "    for arista in graph.edges:\n",
    "        p.add_lines( graph.nodes[arista[0]]['posicion'], graph.nodes[arista[1]]['posicion'])\n",
    "\n",
    "    return \n",
    "\n",
    "def traverse(root, tree):\n",
    "       \n",
    "        if root is not None:\n",
    "            traverse(root.left, tree)\n",
    "            tree.append((root.radius, root.data))\n",
    "            traverse(root.right, tree)\n",
    "            return tree\n",
    "\n",
    "            \n",
    "def traverse_conexiones(root, tree):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            traverse_conexiones(root.left, tree)\n",
    "            if root.right is not None:\n",
    "                tree.append((root.data, root.right.data))\n",
    "            if root.left is not None:\n",
    "                tree.append((root.data, root.left.data))\n",
    "            traverse_conexiones(root.right, tree)\n",
    "            return tree\n",
    "\n",
    "def arbolAGrafo (nodoRaiz):\n",
    "    \n",
    "    conexiones = []\n",
    "    lineas = traverse_conexiones(nodoRaiz, conexiones)\n",
    "    tree = []\n",
    "    tree = traverse(nodoRaiz, tree)\n",
    "\n",
    "    vertices = []\n",
    "    verticesCrudos = []\n",
    "    for node in tree:\n",
    "        vertice = node[0][0][:3]\n",
    "        rad = node[0][0][-1]\n",
    "        num = node[1]\n",
    "        \n",
    "        #vertices.append((num, {'posicion': Vec3( vertice[0], vertice[1], vertice[2]), 'radio': rad} ))\n",
    "        vertices.append((len(verticesCrudos),{'posicion': Vec3( vertice[0], vertice[1], vertice[2]), 'radio': rad}))\n",
    "        verticesCrudos.append(vertice)\n",
    "\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from( vertices )\n",
    "    G.add_edges_from( lineas )\n",
    "    \n",
    "    return G\n",
    "\n",
    "@count_fn\n",
    "def createNode(data, radius, position = None, left = None, right = None, cl_prob = None, ce = None, mse=None):\n",
    "        \"\"\"\n",
    "        Utility function to create a node.\n",
    "        \"\"\"\n",
    "        return Node(data, radius, position, left, right, cl_prob, ce, mse)\n",
    " \n",
    "def deserialize(data):\n",
    "    if  not data:\n",
    "        return \n",
    "    nodes = data.split(';')  \n",
    "    #print(\"node\",nodes[3])\n",
    "    def post_order(nodes):\n",
    "                \n",
    "        if nodes[-1] == '#':\n",
    "            nodes.pop()\n",
    "            return None\n",
    "        node = nodes.pop().split('_')\n",
    "        data = int(node[0])\n",
    "        #radius = float(node[1])\n",
    "        #print(\"node\", node)\n",
    "        #breakpoint()\n",
    "        radius = node[1]\n",
    "        #print(\"radius\", radius)\n",
    "        rad = radius.split(\",\")\n",
    "        rad [0] = rad[0].replace('[','')\n",
    "        rad [3] = rad[3].replace(']','')\n",
    "        r = []\n",
    "        for value in rad:\n",
    "            r.append(float(value))\n",
    "        #r =[float(num) for num in radius if num.isdigit()]\n",
    "        r = torch.tensor(r, device=device)\n",
    "        #breakpoint()\n",
    "        root = createNode(data, r)\n",
    "        root.right = post_order(nodes)\n",
    "        root.left = post_order(nodes)\n",
    "        \n",
    "        return root    \n",
    "    return post_order(nodes)    \n",
    "\n",
    "\n",
    "def read_tree(filename):\n",
    "    with open('./trees/' +filename, \"r\") as f:\n",
    "        byte = f.read() \n",
    "        return byte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class LeafEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size: int, feature_size: int, hidden_size: int):\n",
    "        super(LeafEncoder, self).__init__()\n",
    "        #self.l1 = nn.Linear(4, hidden_size)\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size, feature_size)\n",
    "        self.l3 = nn.Linear(feature_size, feature_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.reshape(-1,4)\n",
    "        #rad = torch.tensor(input.radius)\n",
    "        #rad = torch.reshape(rad, (1,4)).to(device)\n",
    "        #radius = self.l1(rad)\n",
    "        #input = torch.tensor(input).to(device)\n",
    "        radius = self.l1(input)\n",
    "        radius = self.tanh(radius)\n",
    "        radius = self.l2(radius)\n",
    "        radius = self.tanh(radius)\n",
    "        radius = self.l3(radius)\n",
    "        radius = self.tanh(radius)\n",
    "        #print(\"otput\", radius.shape)\n",
    "        return radius\n",
    "'''\n",
    "class InternalEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size: int, feature_size: int, hidden_size: int):\n",
    "        super(InternalEncoder, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size,hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size,feature_size)\n",
    "        self.l3 = nn.Linear(feature_size,feature_size)\n",
    "\n",
    "        self.left = nn.Linear(feature_size,feature_size)\n",
    "        self.right = nn.Linear(feature_size,feature_size)\n",
    "        \n",
    "        self.leafencoder = nn.Linear(feature_size, feature_size)\n",
    "        self.encoder = nn.Linear(2*feature_size, feature_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, input, right_input, left_input):\n",
    "        radius = self.l1(input)\n",
    "        radius = self.tanh(radius)\n",
    "        radius = self.l2(radius)\n",
    "        radius = self.tanh(radius)\n",
    "        #print(\"radius\", radius.shape)\n",
    "        if right_input is not None:\n",
    "            context = self.right(right_input)\n",
    "            #print(\"context\", context.shape)\n",
    "            if left_input is not None:\n",
    "                context += self.left(left_input)\n",
    "                #print(\"context2\", context.shape)\n",
    "            context = self.tanh(context)\n",
    "            #print(\"context3\", context.shape)\n",
    "            feature = torch.cat((radius,context), 1)\n",
    "            #print(\"feature\", feature.shape)\n",
    "            feature = self.encoder(feature)\n",
    "        else:\n",
    "            feature = self.l3(radius)\n",
    "            feature = self.tanh(feature)\n",
    "            feature = self.leafencoder(radius)\n",
    "            #print(\"feature\", feature.shape)\n",
    "\n",
    "        feature = self.tanh(feature)\n",
    "        return feature\n",
    "\n",
    "'''\n",
    "class RightEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size: int, feature_size: int, hidden_size: int):\n",
    "        super(RightEncoder, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size,hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size,feature_size)\n",
    "\n",
    "       \n",
    "        self.right = nn.Linear(feature_size,feature_size)\n",
    "        \n",
    "        self.encoder = nn.Linear(2*feature_size, feature_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, input, right_input):\n",
    "        radius = self.l1(input)\n",
    "        radius = self.tanh(radius)\n",
    "        radius = self.l2(radius)\n",
    "        radius = self.tanh(radius)\n",
    "        context = self.right(right_input)\n",
    "        context = self.tanh(context)\n",
    "        #print(\"rad shape\", radius.shape)\n",
    "        #print(\"context shape\", context.shape)\n",
    "\n",
    "        feature = torch.cat((radius,context), 1)\n",
    "        \n",
    "        feature = self.encoder(feature)\n",
    "        feature = self.tanh(feature)\n",
    "\n",
    "        #print(\"otput\", feature.shape)\n",
    "        return feature\n",
    "'''\n",
    "class GRASSEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size: int, feature_size : int, hidden_size: int):\n",
    "        super(GRASSEncoder, self).__init__()\n",
    "        #self.leaf_encoder = LeafEncoder(input_size, feature_size, hidden_size )\n",
    "        self.internal_encoder = InternalEncoder(input_size,feature_size, hidden_size)\n",
    "        #self.right_encoder = RightEncoder(input_size,feature_size, hidden_size)\n",
    "        \n",
    "\n",
    "    #def leafEncoder(self, node):\n",
    "    #    return self.leaf_encoder(node)\n",
    "\n",
    "    def internalEncoder(self, node, right=None, left = None):\n",
    "        return self.internal_encoder(node, right, left)\n",
    "\n",
    "    #def rightEncoder(self, node, right):\n",
    "     #   return self.right_encoder(node, right)\n",
    "\n",
    "encoder = GRASSEncoder(input_size = 4, feature_size=128, hidden_size=32)\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "\n",
    "def encode_structure_fold(fold, root):\n",
    "    \n",
    "    \n",
    "    def encode_node(node):\n",
    "        \n",
    "        if node is None:\n",
    "            return\n",
    "        #if node.is_leaf():\n",
    "        #    return fold.add('leafEncoder', node.radius)\n",
    "        else:\n",
    "            if node.is_leaf():\n",
    "                return fold.add('internalEncoder', node.radius)\n",
    "            else:\n",
    "                left = encode_node(node.left)\n",
    "                right = encode_node(node.right)\n",
    "                if left is not None:\n",
    "                    return fold.add('internalEncoder', node.radius, right, left)\n",
    "                else:\n",
    "                    return fold.add('internalEncoder', node.radius, right)\n",
    "        '''\n",
    "        elif node.is_two_child():\n",
    "            left = encode_node(node.left)\n",
    "            right = encode_node(node.right)\n",
    "            return fold.add('internalEncoder', node.radius, left, right)\n",
    "        else:\n",
    "            right = encode_node(node.right)\n",
    "            return fold.add('rightEncoder', node.radius, right)\n",
    "        '''\n",
    "        \n",
    "\n",
    "    encoding = encode_node(root)\n",
    "    #return fold.add('sampleEncoder', encoding)\n",
    "    return encoding\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerar_nodos(root, count):\n",
    "    if root is not None:\n",
    "        numerar_nodos(root.left, count)\n",
    "        root.data = len(count)\n",
    "        count.append(1)\n",
    "        numerar_nodos(root.right, count)\n",
    "        return \n",
    "\n",
    "\n",
    "def traversefeatures(root, features):\n",
    "       \n",
    "    if root is not None:\n",
    "        traversefeatures(root.left, features)\n",
    "        features.append(root.radius)\n",
    "        traversefeatures(root.right, features)\n",
    "        return features\n",
    "\n",
    "def norm(root, minx, miny, minz, minr, maxx, maxy, maxz, maxr):\n",
    "    \n",
    "    if root is not None:\n",
    "        mx = minx.clone().detach()\n",
    "        my = miny.clone().detach()\n",
    "        mz = minz.clone().detach()\n",
    "        mr = minr.clone().detach()\n",
    "        Mx = maxx.clone().detach()\n",
    "        My = maxy.clone().detach()\n",
    "        Mz = maxz.clone().detach()\n",
    "        Mr = maxr.clone().detach()\n",
    "\n",
    "        root.radius[0] = (root.radius[0] - minx)/(maxx - minx)\n",
    "        root.radius[1] = (root.radius[1] - miny)/(maxy - miny)\n",
    "        root.radius[2] = (root.radius[2] - minz)/(maxz - minz)\n",
    "        root.radius[3] = (root.radius[3] - minr)/(maxr - minr)\n",
    "        \n",
    "        norm(root.left, mx, my, mz, mr, Mx, My, Mz, Mr)\n",
    "        norm(root.right, mx, my, mz, mr, Mx, My, Mz, Mr)\n",
    "        return \n",
    "\n",
    "def normalize_features(root):\n",
    "    features = []\n",
    "    features = traversefeatures(root, features)\n",
    "    \n",
    "    x = [tensor[0] for tensor in features]\n",
    "    y = [tensor[1] for tensor in features]\n",
    "    z = [tensor[2] for tensor in features]\n",
    "    r = [tensor[3] for tensor in features]\n",
    " \n",
    "    norm(root, min(x), min(y), min(z), min(r), max(x), max(y), max(z), max(r))\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ArteryObjAN1-0.dat']\n"
     ]
    }
   ],
   "source": [
    "def my_collate(batch):\n",
    "    return batch\n",
    "\n",
    "#t_list = ['ArteryObjAN1-7.dat','ArteryObjAN1-0.dat', 'ArteryObjAN1-17.dat',  'ArteryObjAN1-11.dat']\n",
    "\n",
    "t_list = ['ArteryObjAN1-0.dat','ArteryObjAN1-7.dat', 'ArteryObjAN1-17.dat',  'ArteryObjAN1-11.dat', 'ArteryObjAN1-19.dat', 'ArteryObjAN2-4.dat', 'ArteryObjAN2-6.dat', \n",
    "           'ArteryObjAN25-18.dat', 'ArteryObjAN1-0.dat','ArteryObjAN1-7.dat', 'ArteryObjAN1-17.dat',  'ArteryObjAN1-11.dat', 'ArteryObjAN1-19.dat', 'ArteryObjAN2-4.dat', 'ArteryObjAN2-6.dat', \n",
    "           'ArteryObjAN25-18.dat', 'ArteryObjAN1-0.dat','ArteryObjAN1-7.dat', 'ArteryObjAN1-17.dat',  'ArteryObjAN1-11.dat', 'ArteryObjAN1-19.dat', 'ArteryObjAN2-4.dat', 'ArteryObjAN2-6.dat', \n",
    "           'ArteryObjAN25-18.dat', 'ArteryObjAN1-0.dat','ArteryObjAN1-7.dat', 'ArteryObjAN1-17.dat',  'ArteryObjAN1-11.dat', 'ArteryObjAN1-19.dat', 'ArteryObjAN2-4.dat', 'ArteryObjAN2-6.dat', \n",
    "           'ArteryObjAN25-18.dat']\n",
    "#t_list = ['ArteryObjAN1-11.dat','ArteryObjAN1-11.dat','ArteryObjAN1-11.dat','ArteryObjAN1-11.dat','ArteryObjAN1-11.dat','ArteryObjAN1-11.dat','ArteryObjAN1-11.dat','ArteryObjAN1-11.dat','ArteryObjAN1-11.dat','ArteryObjAN1-11.dat','ArteryObjAN1-11.dat','ArteryObjAN1-11.dat','ArteryObjAN1-11.dat','ArteryObjAN1-11.dat','ArteryObjAN1-11.dat','ArteryObjAN1-11.dat']\n",
    "t_list = ['ArteryObjAN1-7.dat','ArteryObjAN1-7.dat','ArteryObjAN1-7.dat','ArteryObjAN1-7.dat','ArteryObjAN1-7.dat','ArteryObjAN1-7.dat','ArteryObjAN1-7.dat','ArteryObjAN1-7.dat','ArteryObjAN1-7.dat','ArteryObjAN1-7.dat','ArteryObjAN1-7.dat','ArteryObjAN1-7.dat','ArteryObjAN1-7.dat','ArteryObjAN1-7.dat','ArteryObjAN1-7.dat','ArteryObjAN1-7.dat']\n",
    "t_list = ['ArteryObjAN1-2.dat', 'ArteryObjAN1-2.dat', 'ArteryObjAN1-2.dat', 'ArteryObjAN1-2.dat', 'ArteryObjAN1-2.dat', 'ArteryObjAN1-2.dat', 'ArteryObjAN1-2.dat', 'ArteryObjAN1-2.dat', 'ArteryObjAN1-2.dat', 'ArteryObjAN1-2.dat', 'ArteryObjAN1-2.dat', 'ArteryObjAN1-2.dat', 'ArteryObjAN1-2.dat', 'ArteryObjAN1-2.dat', 'ArteryObjAN1-2.dat', 'ArteryObjAN1-2.dat']\n",
    "t_list = ['ArteryObjAN1-0.dat']\n",
    "\n",
    "\n",
    "#t_list = os.listdir(\"./trees\")[:20]\n",
    "print(t_list)\n",
    "class tDataset(Dataset):\n",
    "    def __init__(self, dir, transform=None):\n",
    "        self.names = dir\n",
    "        self.transform = transform\n",
    "        self.data = [] #lista con las strings de todos los arboles\n",
    "        for file in self.names:\n",
    "            self.data.append(read_tree(file))\n",
    "        self.trees = []\n",
    "        for tree in self.data:\n",
    "            deserial = deserialize(tree)\n",
    "            normalize_features(deserial)\n",
    "            self.trees.append(deserial)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #file = self.names[idx]\n",
    "        #string = read_tree(file)\n",
    "        tree = self.trees[idx]\n",
    "        return tree\n",
    "\n",
    "batch_size = 1\n",
    "dataset = tDataset(t_list)\n",
    "data_loader = DataLoader(dataset, batch_size = batch_size, shuffle=True, collate_fn=my_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[63]\n",
      "63.0\n",
      "3.0\n",
      "58.0\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "n_no = []\n",
    "qzero = 0\n",
    "qOne = 0\n",
    "qtwo = 0\n",
    "\n",
    "for batch in data_loader:\n",
    "    for tree in batch:\n",
    "        count = []\n",
    "        n = tree.count_nodes(tree, count)\n",
    "        n_no.append(len(n))\n",
    "        li = []\n",
    "        tree.traverseInorderChilds(tree, li)\n",
    "        zero = [a for a in li if a == 0]\n",
    "        one = [a for a in li if a == 1]\n",
    "        two = [a for a in li if a == 2]\n",
    "        qzero += len(zero)\n",
    "        qOne += len(one)\n",
    "        qtwo += len(two)\n",
    "\n",
    "print(len(data_loader)*batch_size)\n",
    "print(n_no)\n",
    "nprom = np.mean(n_no)\n",
    "print(nprom)\n",
    "qzero /= len(data_loader)*batch_size\n",
    "qOne /= len(data_loader)*batch_size\n",
    "qtwo /= len(data_loader)*batch_size\n",
    "\n",
    "print(qzero)\n",
    "print(qOne)\n",
    "print(qtwo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en el loop creo un fold, mando este fold con cada uno de los arboles del batch a encode_structure_fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, latent_size : int, hidden_size : int):\n",
    "        super(NodeClassifier, self).__init__()\n",
    "        self.mlp1 = nn.Linear(latent_size, hidden_size*2)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.mlp2 = nn.Linear(hidden_size*2, hidden_size)\n",
    "\n",
    "        self.tanh2 = nn.Tanh()\n",
    "        self.mlp3 = nn.Linear(hidden_size, 3)\n",
    "\n",
    "    def forward(self, input_feature):\n",
    "        output = self.mlp1(input_feature)\n",
    "        output = self.tanh(output)\n",
    "        output = self.mlp2(output)\n",
    "\n",
    "        output = self.tanh2(output)\n",
    "        output = self.mlp3(output)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InternalDecoder(nn.Module):\n",
    "    \n",
    "    \"\"\" Decode an input (parent) feature into a left-child and a right-child feature \"\"\"\n",
    "    def __init__(self, latent_size : int, hidden_size: int):\n",
    "        super(InternalDecoder, self).__init__()\n",
    "        self.mlp = nn.Linear(latent_size,hidden_size)\n",
    "        self.lp2 = nn.Linear(hidden_size, latent_size)\n",
    "        self.mlp_right = nn.Linear(latent_size, latent_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.mlp2 = nn.Linear(latent_size,4)\n",
    "\n",
    "\n",
    "    def forward(self, parent_feature):\n",
    "        vector = self.mlp(parent_feature)\n",
    "        vector = self.tanh(vector)\n",
    "        vector = self.lp2(vector)\n",
    "        vector = self.tanh(vector)\n",
    "        right_feature = self.mlp_right(vector)\n",
    "        right_feature = self.tanh(right_feature)\n",
    "        rad_feature = self.mlp2(vector)\n",
    "\n",
    "        return right_feature, rad_feature\n",
    "\n",
    "class BifurcationDecoder(nn.Module):\n",
    "    \n",
    "    \"\"\" Decode an input (parent) feature into a left-child and a right-child feature \"\"\"\n",
    "    def __init__(self, latent_size : int, hidden_size : int):\n",
    "        super(BifurcationDecoder, self).__init__()\n",
    "        self.mlp = nn.Linear(latent_size,hidden_size)\n",
    "        self.lp2 = nn.Linear(hidden_size, latent_size)\n",
    "        self.mlp_left = nn.Linear(latent_size, latent_size)\n",
    "        self.mlp_right = nn.Linear(latent_size, latent_size)\n",
    "        self.mlp2 = nn.Linear(latent_size,4)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, parent_feature):\n",
    "        #print(\"pf\", parent_feature.shape)\n",
    "        vector = self.mlp(parent_feature)\n",
    "        vector = self.tanh(vector)\n",
    "        vector = self.lp2(vector)\n",
    "        vector = self.tanh(vector)\n",
    "        left_feature = self.mlp_left(vector)\n",
    "        left_feature = self.tanh(left_feature)\n",
    "        right_feature = self.mlp_right(vector)\n",
    "        right_feature = self.tanh(right_feature)\n",
    "        rad_feature = self.mlp2(vector)\n",
    "        return left_feature, right_feature, rad_feature\n",
    "\n",
    "class featureDecoder(nn.Module):\n",
    "    \n",
    "    \"\"\" Decode an input (parent) feature into a left-child and a right-child feature \"\"\"\n",
    "    def __init__(self, latent_size : int, hidden_size: int):\n",
    "        super(featureDecoder, self).__init__()\n",
    "        self.mlp = nn.Linear(latent_size,hidden_size)\n",
    "        self.mlp2 = nn.Linear(hidden_size, latent_size)\n",
    "        self.mlp3 = nn.Linear(latent_size, latent_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.mlp4 = nn.Linear(latent_size,4)\n",
    "       \n",
    "    def forward(self, parent_feature):\n",
    "        vector = self.mlp(parent_feature)\n",
    "        vector = self.tanh(vector)\n",
    "        vector = self.mlp2(vector)\n",
    "        vector = self.tanh(vector)\n",
    "        vector = self.mlp3(vector)\n",
    "        vector = self.tanh(vector)\n",
    "        vector = self.mlp4(vector)\n",
    "       \n",
    "        return vector\n",
    "\n",
    "\n",
    "class GRASSDecoder(nn.Module):\n",
    "    def __init__(self, latent_size : int, hidden_size: int, mult: torch.Tensor):\n",
    "        super(GRASSDecoder, self).__init__()\n",
    "        self.feature_decoder = featureDecoder(latent_size, hidden_size)\n",
    "        self.internal_decoder = InternalDecoder(latent_size, hidden_size)\n",
    "        self.bifurcation_decoder = BifurcationDecoder(latent_size, hidden_size)\n",
    "        self.node_classifier = NodeClassifier(latent_size, hidden_size)\n",
    "        self.mseLoss = nn.MSELoss()  # pytorch's mean squared error loss\n",
    "        self.ceLoss = nn.CrossEntropyLoss(weight = mult)  #\n",
    "\n",
    "    def featureDecoder(self, feature):\n",
    "        return self.feature_decoder(feature)\n",
    "\n",
    "    def internalDecoder(self, feature):\n",
    "        return self.internal_decoder(feature)\n",
    "\n",
    "    def bifurcationDecoder(self, feature):\n",
    "        return self.bifurcation_decoder(feature)\n",
    "\n",
    "    def nodeClassifier(self, feature):\n",
    "        return self.node_classifier(feature)\n",
    "\n",
    "    def calcularLossAtributo(self, nodo, radio):\n",
    "        mult = torch.tensor([1/round(qzero),1/round(qOne),1/round(qtwo)], device = device)\n",
    "        a, b = list(zip(*nodo))# a son los atributos, b los pesos\n",
    "        \n",
    "        if nodo is None:\n",
    "            return\n",
    "        else:\n",
    "            nodo = torch.stack(list(a))\n",
    "            #print(\"nodo stack\", nodo)\n",
    "            z = zip(radio.reshape(-1,4), nodo.reshape(-1,4))\n",
    "            \n",
    "            lis = zip(radio.reshape(-1,4), nodo.reshape(-1,4), b)\n",
    "            l = []\n",
    "            for d, gt, c in lis:\n",
    "                #print(\"d\", d)\n",
    "                #print(\"gt\", gt)\n",
    "                if c == 0:\n",
    "                    #print(\"mult\",mult[0])\n",
    "                    #print(\"n\", self.mseLoss(d.reshape(1,4), gt.reshape(1,4)).mul(mult[0]))\n",
    "                    l.append(self.mseLoss(d.reshape(1,4), gt.reshape(1,4)).mul(100*mult[0]))\n",
    "                elif c == 1:\n",
    "                    #print(\"mult\",mult[1])\n",
    "                    #print(\"n1\", self.mseLoss(d.reshape(1,4), gt.reshape(1,4)).mul(mult[1]))\n",
    "                    l.append(self.mseLoss(d.reshape(1,4), gt.reshape(1,4)).mul(10*mult[1]))\n",
    "                elif c == 2:\n",
    "                    print(\"nodo\", nodo)\n",
    "                    print(\"radio\", radio)\n",
    "                    #print(\"mult\",mult[2])\n",
    "                    #print(\"n2\", self.mseLoss(d.reshape(1,4), gt.reshape(1,4)).mul(mult[2]))\n",
    "                    #print(\"d, gt\", d, gt)\n",
    "                    l.append(self.mseLoss(d.reshape(1,4), gt.reshape(1,4)).mul(100*mult[2]))\n",
    "            \n",
    "            \n",
    "            l = [self.mseLoss(d.reshape(1,4), gt.reshape(1,4)) for d, gt in zip(radio.reshape(-1,4), nodo.reshape(-1,4)) ] \n",
    "            print(\"l\", l)\n",
    "            return l\n",
    "\n",
    "\n",
    "    def classifyLossEstimator(self, label_vector, original):\n",
    "        if original is None:\n",
    "            return\n",
    "        else:\n",
    "           \n",
    "            v = []\n",
    "            for o in original:\n",
    "                if o == 0:\n",
    "                    vector = torch.tensor([1, 0, 0], device=device, dtype = torch.float)\n",
    "                if o == 1:\n",
    "                    vector = torch.tensor([0, 1, 0], device=device, dtype = torch.float)\n",
    "                if o == 2:\n",
    "                    vector = torch.tensor([0, 0, 1], device=device, dtype = torch.float)\n",
    "                v.append(vector)\n",
    "\n",
    "            v = torch.stack(v)\n",
    "            z = zip(label_vector.reshape(-1,3), v.reshape(-1,3))   \n",
    "            l = [self.ceLoss(b.reshape(1,3), gt.reshape(1,3)).mul(0.5) for b, gt in zip(label_vector.reshape(-1,3), v.reshape(-1,3))]\n",
    "            \n",
    "            return l\n",
    "            #return c\n",
    "       # return torch.cat([self.creLoss(l.unsqueeze(0), gt).mul(0.2) for l, gt in zip(label_vector, gt_label_vector)], 0)\n",
    "\n",
    "    def vectorAdder(self, v1, v2, v3 = None, v4 = None):\n",
    "        #print(\"v1\", v1)\n",
    "        #print(\"v2\", v2)\n",
    "        v = v1.add(v2)\n",
    "        #print(\"v\", v)\n",
    "        if v3 is not None:   \n",
    "            v = v.add(v3)\n",
    "           \n",
    "        if v4 is not None: \n",
    "            #print(\"loss e\", v1)\n",
    "            #print(\"loss a\", v2)\n",
    "            v = v.add(v4)\n",
    "         \n",
    "        return v\n",
    "\n",
    "if qzero == 0:\n",
    "    qzero = 1\n",
    "if qOne == 0:\n",
    "    qOne = 1\n",
    "if qtwo == 0:\n",
    "    qtwo = 1\n",
    "\n",
    "mult = torch.tensor([1/round(qzero),1/round(qOne),1/round(qtwo)], device = device)\n",
    "Grassdecoder = GRASSDecoder(latent_size=128, hidden_size=256, mult = mult)\n",
    "Grassdecoder = Grassdecoder.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decode structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyLossEstimator(cl_p, original):\n",
    "    \n",
    "    mult = torch.tensor([1/3.,1/66,1/2.], device = device)\n",
    "    ce = nn.CrossEntropyLoss(weight=mult)\n",
    "    if original.childs() == 0:\n",
    "        vector = [1, 0, 0] \n",
    "    if original.childs() == 1:\n",
    "        vector = [0, 1, 0]\n",
    "    if original.childs() == 2:\n",
    "        vector = [0, 0, 1] \n",
    "\n",
    "    c = ce(cl_p, torch.tensor(vector, device=device, dtype = torch.float).reshape(1, 3))\n",
    "    return c\n",
    "\n",
    "\n",
    "def calcularLossAtributo(nodo, radio):\n",
    "    \n",
    "    if nodo is None:\n",
    "        return\n",
    "    \n",
    "    radio = radio.reshape(4)\n",
    "    l2    = nn.MSELoss()\n",
    "   \n",
    "    mse = l2(radio, nodo.radius)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_structure_fold_grass(fold, v, root):\n",
    "    \n",
    "    def decode_node(fold, v, node):\n",
    "        \n",
    "        \n",
    "        if node.childs() == 0 : ##output del classifier\n",
    "            \n",
    "            radio = fold.add('featureDecoder', v)\n",
    "            lossAtributo = fold.add('calcularLossAtributo', node, radio)\n",
    "            label = fold.add('nodeClassifier', v)\n",
    "            lossEstructura = fold.add('classifyLossEstimator', label, node)           \n",
    "            return fold.add('vectorAdder', lossEstructura, lossAtributo)\n",
    "\n",
    "            \n",
    "        elif node.childs() == 1 :\n",
    "            \n",
    "            right, radius = fold.add('internalDecoder', v).split(2)\n",
    "            label = fold.add('nodeClassifier', v)\n",
    "            nodoSiguiente = node.right\n",
    "            if nodoSiguiente is not None:\n",
    "                right_loss = decode_node(fold, right, nodoSiguiente)\n",
    "            lossEstructura = fold.add('classifyLossEstimator', label, node)\n",
    "            lossAtributo = fold.add('calcularLossAtributo', node, radius)\n",
    "\n",
    "            return fold.add('vectorAdder', lossEstructura, right_loss, lossAtributo)\n",
    "            \n",
    "            \n",
    "\n",
    "        elif node.childs() == 2 :\n",
    "            \n",
    "            left, right, radius = fold.add('bifurcationDecoder', v).split(3)\n",
    "            #print(\"left\", left)\n",
    "            #print(\"right\", right)\n",
    "            #print(\"radius\", radius)\n",
    "            label = fold.add('nodeClassifier', v)\n",
    "            \n",
    "            nodoSiguienteRight = node.right\n",
    "            nodoSiguienteLeft = node.left\n",
    "\n",
    "            if nodoSiguienteRight is not None:\n",
    "                right_loss = decode_node(fold, right, nodoSiguienteRight)\n",
    "            if nodoSiguienteLeft is not None:\n",
    "                left_loss  = decode_node(fold, left, nodoSiguienteLeft)\n",
    "                \n",
    "            lossEstructura = fold.add('classifyLossEstimator', label, node)\n",
    "            lossAtributo = fold.add('calcularLossAtributo', node, radius)\n",
    "            #print (\"2\")\n",
    "            #print(\"loss e\", lossEstructura)\n",
    "            #print(\"loss a\", lossAtributo)\n",
    "            #print(\"r\", right_loss)\n",
    "            #print(\"l\", left_loss)\n",
    "            return fold.add('vectorAdder', lossEstructura, lossAtributo, right_loss, left_loss)\n",
    "            \n",
    "\n",
    "    dec = decode_node (fold, v, root)\n",
    "    return dec\n",
    "\n",
    "def decode_structure(v, root):\n",
    "    \n",
    "    def decode_node(v, node):\n",
    "        \n",
    "        \n",
    "        if node.childs() == 0 : ##output del classifier\n",
    "            radio = Grassdecoder.featureDecoder(v)\n",
    "            lossAtributo = Grassdecoder.calcularLossAtributo(node, radio)\n",
    "            #lossAtributo = calcularLossAtributo( node, radio)\n",
    "            label = Grassdecoder.nodeClassifier(v)\n",
    "            lossEstructura = Grassdecoder.classifyLossEstimator(label, node)  \n",
    "              \n",
    "            return Grassdecoder.vectorAdder(lossEstructura, lossAtributo)\n",
    "\n",
    "            \n",
    "        elif node.childs() == 1 :\n",
    "            right, radius = Grassdecoder.internalDecoder(v)#.split(2)\n",
    "            label = Grassdecoder.nodeClassifier(v)\n",
    "            nodoSiguiente = node.right\n",
    "            if nodoSiguiente is not None:\n",
    "                right_loss = decode_node(right, nodoSiguiente)\n",
    "            lossEstructura =Grassdecoder.classifyLossEstimator(label, node)\n",
    "            lossAtributo = Grassdecoder.calcularLossAtributo( node, radius)\n",
    "\n",
    "        \n",
    "            return Grassdecoder.vectorAdder(lossEstructura, right_loss, lossAtributo)\n",
    "            \n",
    "            \n",
    "\n",
    "        elif node.childs() == 2 :\n",
    "            left, right, radius = Grassdecoder.bifurcationDecoder(v)#.split(3)\n",
    "            label = Grassdecoder.nodeClassifier(v)\n",
    "            nodoSiguienteRight = node.right\n",
    "            nodoSiguienteLeft = node.left\n",
    "            if nodoSiguienteRight is not None:\n",
    "                right_loss = decode_node(right, nodoSiguienteRight)\n",
    "             \n",
    "            if nodoSiguienteLeft is not None:\n",
    "                left_loss  = decode_node(left, nodoSiguienteLeft)\n",
    "            lossEstructura =Grassdecoder.classifyLossEstimator(label, node)\n",
    "            lossAtributo = Grassdecoder.calcularLossAtributo(node, radius)\n",
    "            \n",
    "            return Grassdecoder.vectorAdder(lossEstructura, right_loss, left_loss, lossAtributo)\n",
    "            \n",
    "\n",
    "    dec = decode_node (v, root)\n",
    "    return dec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_structure_fold_(v, root):\n",
    "    \n",
    "    def decode_node(v, node):\n",
    "        cl = Grassdecoder.nodeClassifier(v)\n",
    "        _, label = torch.max(cl, 1)\n",
    "        label = label.data\n",
    "\n",
    "        \n",
    "        if node.childs() == 0 : ##output del classifier\n",
    "            lossEstructura = classifyLossEstimator(cl, node)\n",
    "            radio = Grassdecoder.featureDecoder(v)\n",
    "            lossAtrs = calcularLossAtributo( node, radio )\n",
    "            nd = createNode(1,radio, ce = lossEstructura,  mse = lossAtrs)\n",
    "            return nd\n",
    "\n",
    "        elif node.childs() == 1 :\n",
    "        \n",
    "            right, radius = Grassdecoder.internalDecoder(v)\n",
    "            lossEstructura = classifyLossEstimator(cl, node)\n",
    "            lossAtrs = calcularLossAtributo( node, radius )\n",
    "            nd = createNode(1, radius, cl_prob = lossAtrs , ce = lossEstructura, mse = lossAtrs) \n",
    "            \n",
    "            nodoSiguiente = node.right\n",
    "           \n",
    "            if nodoSiguiente is not None:\n",
    "                nd.right = decode_node(right, nodoSiguiente)\n",
    "               \n",
    "            return nd\n",
    "\n",
    "        elif node.childs() == 2 :\n",
    "            left, right, radius = Grassdecoder.bifurcationDecoder(v)\n",
    "            #print(\"left\", left)\n",
    "            #print(\"right\", right)\n",
    "            #print(\"radius\", radius)\n",
    "            lossEstructura = classifyLossEstimator(cl, node)\n",
    "            lossAtrs = calcularLossAtributo( node, radius )\n",
    "            #print(\"loss e\", lossEstructura)\n",
    "            #print(\"loss a\", lossAtrs)\n",
    "            nd = createNode(1, radius, cl_prob = lossAtrs, ce = lossEstructura, mse = lossAtrs)\n",
    "            \n",
    "            nodoSiguienteRight = node.right\n",
    "            nodoSiguienteLeft = node.left\n",
    "            if nodoSiguienteRight is not None:\n",
    "                nd.right = decode_node(right, nodoSiguienteRight)\n",
    "             \n",
    "            if nodoSiguienteLeft is not None:\n",
    "                nd.left  = decode_node(left, nodoSiguienteLeft)\n",
    "            \n",
    "            return nd\n",
    "            \n",
    "    createNode.count = 0\n",
    "    dec = decode_node (v, root)\n",
    "    return dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decode testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_testing_grass(v, root, max, decoder):\n",
    "    def decode_node(v, node, max):\n",
    "        cl = decoder.nodeClassifier(v)\n",
    "        _, label = torch.max(cl, 1)\n",
    "        label = label.data\n",
    "        \n",
    "        if label == 0 and createNode.count <= max: ##output del classifier\n",
    "           \n",
    "            #lossEstructura = Grassdecoder.classifyLossEstimator(cl, node)\n",
    "           \n",
    "            radio = decoder.featureDecoder(v)\n",
    "          \n",
    "            #lossAtrs = Grassdecoder.calcularLossAtributo( node, radio )\n",
    "           \n",
    "            return createNode(1,radio)\n",
    "\n",
    "        elif label == 1 and createNode.count <= max:\n",
    "       \n",
    "            right, radius = decoder.internalDecoder(v)\n",
    "            \n",
    "            d = createNode(1, radius) \n",
    "             \n",
    "            if not node is None:\n",
    "                if not node.right is None:\n",
    "                    nodoSiguiente = node.right\n",
    "                else:\n",
    "                    nodoSiguiente = None\n",
    "            else:\n",
    "                nodoSiguiente = None\n",
    "            \n",
    "            d.right = decode_node(right, nodoSiguiente, max)\n",
    "            \n",
    "\n",
    "            return d\n",
    "       \n",
    "        elif label == 2 and createNode.count <= max:\n",
    "            left, right, radius = decoder.bifurcationDecoder(v)\n",
    "          \n",
    "            \n",
    "            d = createNode(1, radius )\n",
    "  \n",
    "            if not node is None: #el nodo existe, me fijo si tiene hijo der/izq\n",
    "                if not node.right is None:\n",
    "                    nodoSiguienteRight = node.right\n",
    "                else:\n",
    "                    nodoSiguienteRight = None\n",
    "                if not node.left is None:\n",
    "                    nodoSiguienteLeft = node.left\n",
    "                else:\n",
    "                    nodoSiguienteLeft = None\n",
    "            else: #el nodo no existe\n",
    "                nodoSiguienteRight = None\n",
    "                nodoSiguienteLeft = None\n",
    "            \n",
    "            d.right = decode_node(right, nodoSiguienteRight, max)\n",
    "            d.left = decode_node(left, nodoSiguienteLeft, max)\n",
    "            \n",
    "            return d\n",
    "            \n",
    "    createNode.count = 0\n",
    "    dec = decode_node (v, root, max)\n",
    "    return dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveBestModel:\n",
    "    \"\"\"\n",
    "    Class to save the best model while training. If the current epoch's \n",
    "    validation loss is less than the previous least less, then save the\n",
    "    model state.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, best_valid_loss=float('inf')\n",
    "    ):\n",
    "        self.best_valid_loss = best_valid_loss\n",
    "        \n",
    "    def __call__(\n",
    "        self, current_valid_loss, \n",
    "        epoch, encoder, decoder, optimizer\n",
    "    ):\n",
    "        if current_valid_loss < self.best_valid_loss:\n",
    "            self.best_valid_loss = current_valid_loss\n",
    "            #print(f\"\\nBest validation loss: {self.best_valid_loss}\")\n",
    "            #print(f\"\\nSaving best model for epoch: {epoch+1}\\n\")\n",
    "            #'classifier_state_dict': classifier.state_dict(),\n",
    "            torch.save({\n",
    "                'epoch': epoch+1,\n",
    "                'encoder_state_dict': encoder.state_dict(),\n",
    "                'decoder_state_dict': decoder.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, 'outputs/best_model.pth')\n",
    "\n",
    "save_best_model = SaveBestModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 5000] average reconstruction error: 0.37515879 \n",
      "Epoch [11 / 5000] average reconstruction error: 0.30621642 \n",
      "Epoch [21 / 5000] average reconstruction error: 0.23733729 \n",
      "Epoch [31 / 5000] average reconstruction error: 0.15457235 \n",
      "Epoch [41 / 5000] average reconstruction error: 0.07940166 \n",
      "Epoch [51 / 5000] average reconstruction error: 0.07360681 \n",
      "Epoch [61 / 5000] average reconstruction error: 0.07326046 \n",
      "Epoch [71 / 5000] average reconstruction error: 0.07063048 \n",
      "Epoch [81 / 5000] average reconstruction error: 0.07022715 \n",
      "Epoch [91 / 5000] average reconstruction error: 0.07005106 \n",
      "Epoch [101 / 5000] average reconstruction error: 0.06981432 \n",
      "Epoch [111 / 5000] average reconstruction error: 0.06968877 \n",
      "Epoch [121 / 5000] average reconstruction error: 0.06959068 \n",
      "Epoch [131 / 5000] average reconstruction error: 0.06950370 \n",
      "Epoch [141 / 5000] average reconstruction error: 0.06942429 \n",
      "Epoch [151 / 5000] average reconstruction error: 0.06934392 \n",
      "Epoch [161 / 5000] average reconstruction error: 0.06926543 \n",
      "Epoch [171 / 5000] average reconstruction error: 0.06918663 \n",
      "Epoch [181 / 5000] average reconstruction error: 0.06910017 \n",
      "Epoch [191 / 5000] average reconstruction error: 0.06900855 \n",
      "Epoch [201 / 5000] average reconstruction error: 0.06891114 \n",
      "Epoch [211 / 5000] average reconstruction error: 0.06879930 \n",
      "Epoch [221 / 5000] average reconstruction error: 0.06867806 \n",
      "Epoch [231 / 5000] average reconstruction error: 0.06854147 \n",
      "Epoch [241 / 5000] average reconstruction error: 0.06838056 \n",
      "Epoch [251 / 5000] average reconstruction error: 0.06819762 \n",
      "Epoch [261 / 5000] average reconstruction error: 0.06798168 \n",
      "Epoch [271 / 5000] average reconstruction error: 0.06771281 \n",
      "Epoch [281 / 5000] average reconstruction error: 0.06736455 \n",
      "Epoch [291 / 5000] average reconstruction error: 0.06686910 \n",
      "Epoch [301 / 5000] average reconstruction error: 0.06604216 \n",
      "Epoch [311 / 5000] average reconstruction error: 0.06414949 \n",
      "Epoch [321 / 5000] average reconstruction error: 0.05834251 \n",
      "Epoch [331 / 5000] average reconstruction error: 0.05199285 \n",
      "Epoch [341 / 5000] average reconstruction error: 0.04099579 \n",
      "Epoch [351 / 5000] average reconstruction error: 0.03772653 \n",
      "Epoch [361 / 5000] average reconstruction error: 0.03684879 \n",
      "Epoch [371 / 5000] average reconstruction error: 0.03597866 \n",
      "Epoch [381 / 5000] average reconstruction error: 0.03567056 \n",
      "Epoch [391 / 5000] average reconstruction error: 0.03487199 \n",
      "Epoch [401 / 5000] average reconstruction error: 0.03342307 \n",
      "Epoch [411 / 5000] average reconstruction error: 0.03245171 \n",
      "Epoch [421 / 5000] average reconstruction error: 0.03191181 \n",
      "Epoch [431 / 5000] average reconstruction error: 0.03586900 \n",
      "Epoch [441 / 5000] average reconstruction error: 0.03056162 \n",
      "Epoch [451 / 5000] average reconstruction error: 0.02589862 \n",
      "Epoch [461 / 5000] average reconstruction error: 0.02207880 \n",
      "Epoch [471 / 5000] average reconstruction error: 0.01967499 \n",
      "Epoch [481 / 5000] average reconstruction error: 0.01798836 \n",
      "Epoch [491 / 5000] average reconstruction error: 0.01685064 \n",
      "Epoch [501 / 5000] average reconstruction error: 0.01619842 \n",
      "Epoch [511 / 5000] average reconstruction error: 0.01575088 \n",
      "Epoch [521 / 5000] average reconstruction error: 0.01534321 \n",
      "Epoch [531 / 5000] average reconstruction error: 0.01893864 \n",
      "Epoch [541 / 5000] average reconstruction error: 0.01597870 \n",
      "Epoch [551 / 5000] average reconstruction error: 0.01484516 \n",
      "Epoch [561 / 5000] average reconstruction error: 0.01423282 \n",
      "Epoch [571 / 5000] average reconstruction error: 0.01351811 \n",
      "Epoch [581 / 5000] average reconstruction error: 0.01280290 \n",
      "Epoch [591 / 5000] average reconstruction error: 0.01257683 \n",
      "Epoch [601 / 5000] average reconstruction error: 0.01211200 \n",
      "Epoch [611 / 5000] average reconstruction error: 0.01176065 \n",
      "Epoch [621 / 5000] average reconstruction error: 0.01109098 \n",
      "Epoch [631 / 5000] average reconstruction error: 0.01050879 \n",
      "Epoch [641 / 5000] average reconstruction error: 0.01567204 \n",
      "Epoch [651 / 5000] average reconstruction error: 0.01043063 \n",
      "Epoch [661 / 5000] average reconstruction error: 0.00950530 \n",
      "Epoch [671 / 5000] average reconstruction error: 0.00860536 \n",
      "Epoch [681 / 5000] average reconstruction error: 0.00861820 \n",
      "Epoch [691 / 5000] average reconstruction error: 0.00767127 \n",
      "Epoch [701 / 5000] average reconstruction error: 0.00711796 \n",
      "Epoch [711 / 5000] average reconstruction error: 0.00695273 \n",
      "Epoch [721 / 5000] average reconstruction error: 0.01274703 \n",
      "Epoch [731 / 5000] average reconstruction error: 0.01964723 \n",
      "Epoch [741 / 5000] average reconstruction error: 0.01300466 \n",
      "Epoch [751 / 5000] average reconstruction error: 0.00872789 \n",
      "Epoch [761 / 5000] average reconstruction error: 0.00718841 \n",
      "Epoch [771 / 5000] average reconstruction error: 0.00645613 \n",
      "Epoch [781 / 5000] average reconstruction error: 0.01047598 \n",
      "Epoch [791 / 5000] average reconstruction error: 0.00759390 \n",
      "Epoch [801 / 5000] average reconstruction error: 0.00661376 \n",
      "Epoch [811 / 5000] average reconstruction error: 0.00586198 \n",
      "Epoch [821 / 5000] average reconstruction error: 0.00546260 \n",
      "Epoch [831 / 5000] average reconstruction error: 0.00508552 \n",
      "Epoch [841 / 5000] average reconstruction error: 0.00484782 \n",
      "Epoch [851 / 5000] average reconstruction error: 0.00578920 \n",
      "Epoch [861 / 5000] average reconstruction error: 0.02188044 \n",
      "Epoch [871 / 5000] average reconstruction error: 0.01680818 \n",
      "Epoch [881 / 5000] average reconstruction error: 0.01286850 \n",
      "Epoch [891 / 5000] average reconstruction error: 0.00821933 \n",
      "Epoch [901 / 5000] average reconstruction error: 0.00594452 \n",
      "Epoch [911 / 5000] average reconstruction error: 0.00518296 \n",
      "Epoch [921 / 5000] average reconstruction error: 0.01768640 \n",
      "Epoch [931 / 5000] average reconstruction error: 0.01632202 \n",
      "Epoch [941 / 5000] average reconstruction error: 0.00958025 \n",
      "Epoch [951 / 5000] average reconstruction error: 0.00713622 \n",
      "Epoch [961 / 5000] average reconstruction error: 0.00567718 \n",
      "Epoch [971 / 5000] average reconstruction error: 0.00493419 \n",
      "Epoch [981 / 5000] average reconstruction error: 0.00435672 \n",
      "Epoch [991 / 5000] average reconstruction error: 0.00403074 \n",
      "Epoch [1001 / 5000] average reconstruction error: 0.00378623 \n",
      "Epoch [1011 / 5000] average reconstruction error: 0.00361618 \n",
      "Epoch [1021 / 5000] average reconstruction error: 0.00346239 \n",
      "Epoch [1031 / 5000] average reconstruction error: 0.00332803 \n",
      "Epoch [1041 / 5000] average reconstruction error: 0.00320939 \n",
      "Epoch [1051 / 5000] average reconstruction error: 0.00316673 \n",
      "Epoch [1061 / 5000] average reconstruction error: 0.00300172 \n",
      "Epoch [1071 / 5000] average reconstruction error: 0.00295411 \n",
      "Epoch [1081 / 5000] average reconstruction error: 0.00292342 \n",
      "Epoch [1091 / 5000] average reconstruction error: 0.00269182 \n",
      "Epoch [1101 / 5000] average reconstruction error: 0.00260255 \n",
      "Epoch [1111 / 5000] average reconstruction error: 0.00366146 \n",
      "Epoch [1121 / 5000] average reconstruction error: 0.00933746 \n",
      "Epoch [1131 / 5000] average reconstruction error: 0.00537856 \n",
      "Epoch [1141 / 5000] average reconstruction error: 0.00329227 \n",
      "Epoch [1151 / 5000] average reconstruction error: 0.00288996 \n",
      "Epoch [1161 / 5000] average reconstruction error: 0.00260499 \n",
      "Epoch [1171 / 5000] average reconstruction error: 0.00242874 \n",
      "Epoch [1181 / 5000] average reconstruction error: 0.00228604 \n",
      "Epoch [1191 / 5000] average reconstruction error: 0.00220778 \n",
      "Epoch [1201 / 5000] average reconstruction error: 0.00213201 \n",
      "Epoch [1211 / 5000] average reconstruction error: 0.00208376 \n",
      "Epoch [1221 / 5000] average reconstruction error: 0.00202000 \n",
      "Epoch [1231 / 5000] average reconstruction error: 0.00198776 \n",
      "Epoch [1241 / 5000] average reconstruction error: 0.00190213 \n",
      "Epoch [1251 / 5000] average reconstruction error: 0.00185610 \n",
      "Epoch [1261 / 5000] average reconstruction error: 0.00210320 \n",
      "Epoch [1271 / 5000] average reconstruction error: 0.03410375 \n",
      "Epoch [1281 / 5000] average reconstruction error: 0.01993161 \n",
      "Epoch [1291 / 5000] average reconstruction error: 0.01329826 \n",
      "Epoch [1301 / 5000] average reconstruction error: 0.01011736 \n",
      "Epoch [1311 / 5000] average reconstruction error: 0.00848114 \n",
      "Epoch [1321 / 5000] average reconstruction error: 0.00570376 \n",
      "Epoch [1331 / 5000] average reconstruction error: 0.00455965 \n",
      "Epoch [1341 / 5000] average reconstruction error: 0.00338363 \n",
      "Epoch [1351 / 5000] average reconstruction error: 0.00276000 \n",
      "Epoch [1361 / 5000] average reconstruction error: 0.00244712 \n",
      "Epoch [1371 / 5000] average reconstruction error: 0.00226294 \n",
      "Epoch [1381 / 5000] average reconstruction error: 0.00214476 \n",
      "Epoch [1391 / 5000] average reconstruction error: 0.00205385 \n",
      "Epoch [1401 / 5000] average reconstruction error: 0.00197984 \n",
      "Epoch [1411 / 5000] average reconstruction error: 0.00191648 \n",
      "Epoch [1421 / 5000] average reconstruction error: 0.00186057 \n",
      "Epoch [1431 / 5000] average reconstruction error: 0.00181195 \n",
      "Epoch [1441 / 5000] average reconstruction error: 0.00176654 \n",
      "Epoch [1451 / 5000] average reconstruction error: 0.00172525 \n",
      "Epoch [1461 / 5000] average reconstruction error: 0.00168799 \n",
      "Epoch [1471 / 5000] average reconstruction error: 0.00165221 \n",
      "Epoch [1481 / 5000] average reconstruction error: 0.00161724 \n",
      "Epoch [1491 / 5000] average reconstruction error: 0.00158582 \n",
      "Epoch [1501 / 5000] average reconstruction error: 0.00155445 \n",
      "Epoch [1511 / 5000] average reconstruction error: 0.00152403 \n",
      "Epoch [1521 / 5000] average reconstruction error: 0.00150235 \n",
      "Epoch [1531 / 5000] average reconstruction error: 0.00147018 \n",
      "Epoch [1541 / 5000] average reconstruction error: 0.00144846 \n",
      "Epoch [1551 / 5000] average reconstruction error: 0.00141642 \n",
      "Epoch [1561 / 5000] average reconstruction error: 0.00150536 \n",
      "Epoch [1571 / 5000] average reconstruction error: 0.01959672 \n",
      "Epoch [1581 / 5000] average reconstruction error: 0.00715663 \n",
      "Epoch [1591 / 5000] average reconstruction error: 0.01268345 \n",
      "Epoch [1601 / 5000] average reconstruction error: 0.00620046 \n",
      "Epoch [1611 / 5000] average reconstruction error: 0.00393353 \n",
      "Epoch [1621 / 5000] average reconstruction error: 0.00241494 \n",
      "Epoch [1631 / 5000] average reconstruction error: 0.00205670 \n",
      "Epoch [1641 / 5000] average reconstruction error: 0.00188446 \n",
      "Epoch [1651 / 5000] average reconstruction error: 0.00175199 \n",
      "Epoch [1661 / 5000] average reconstruction error: 0.00167586 \n",
      "Epoch [1671 / 5000] average reconstruction error: 0.00161080 \n",
      "Epoch [1681 / 5000] average reconstruction error: 0.00156232 \n",
      "Epoch [1691 / 5000] average reconstruction error: 0.00151956 \n",
      "Epoch [1701 / 5000] average reconstruction error: 0.00148213 \n",
      "Epoch [1711 / 5000] average reconstruction error: 0.00144950 \n",
      "Epoch [1721 / 5000] average reconstruction error: 0.00141881 \n",
      "Epoch [1731 / 5000] average reconstruction error: 0.00138813 \n",
      "Epoch [1741 / 5000] average reconstruction error: 0.00136228 \n",
      "Epoch [1751 / 5000] average reconstruction error: 0.00133643 \n",
      "Epoch [1761 / 5000] average reconstruction error: 0.00131378 \n",
      "Epoch [1771 / 5000] average reconstruction error: 0.00129006 \n",
      "Epoch [1781 / 5000] average reconstruction error: 0.00126842 \n",
      "Epoch [1791 / 5000] average reconstruction error: 0.00124672 \n",
      "Epoch [1801 / 5000] average reconstruction error: 0.00122671 \n",
      "Epoch [1811 / 5000] average reconstruction error: 0.00123621 \n",
      "Epoch [1821 / 5000] average reconstruction error: 0.00132085 \n",
      "Epoch [1831 / 5000] average reconstruction error: 0.00396179 \n",
      "Epoch [1841 / 5000] average reconstruction error: 0.00629410 \n",
      "Epoch [1851 / 5000] average reconstruction error: 0.00373667 \n",
      "Epoch [1861 / 5000] average reconstruction error: 0.00259147 \n",
      "Epoch [1871 / 5000] average reconstruction error: 0.00175572 \n",
      "Epoch [1881 / 5000] average reconstruction error: 0.00145436 \n",
      "Epoch [1891 / 5000] average reconstruction error: 0.00135170 \n",
      "Epoch [1901 / 5000] average reconstruction error: 0.00129558 \n",
      "Epoch [1911 / 5000] average reconstruction error: 0.00124521 \n",
      "Epoch [1921 / 5000] average reconstruction error: 0.00121164 \n",
      "Epoch [1931 / 5000] average reconstruction error: 0.00117818 \n",
      "Epoch [1941 / 5000] average reconstruction error: 0.00115098 \n",
      "Epoch [1951 / 5000] average reconstruction error: 0.00112708 \n",
      "Epoch [1961 / 5000] average reconstruction error: 0.00110410 \n",
      "Epoch [1971 / 5000] average reconstruction error: 0.00108364 \n",
      "Epoch [1981 / 5000] average reconstruction error: 0.00106371 \n",
      "Epoch [1991 / 5000] average reconstruction error: 0.00104520 \n",
      "Epoch [2001 / 5000] average reconstruction error: 0.00102728 \n",
      "Epoch [2011 / 5000] average reconstruction error: 0.00101034 \n",
      "Epoch [2021 / 5000] average reconstruction error: 0.00099374 \n",
      "Epoch [2031 / 5000] average reconstruction error: 0.00097793 \n",
      "Epoch [2041 / 5000] average reconstruction error: 0.00096249 \n",
      "Epoch [2051 / 5000] average reconstruction error: 0.00094717 \n",
      "Epoch [2061 / 5000] average reconstruction error: 0.00093343 \n",
      "Epoch [2071 / 5000] average reconstruction error: 0.00091862 \n",
      "Epoch [2081 / 5000] average reconstruction error: 0.00091545 \n",
      "Epoch [2091 / 5000] average reconstruction error: 0.00102210 \n",
      "Epoch [2101 / 5000] average reconstruction error: 0.02449425 \n",
      "Epoch [2111 / 5000] average reconstruction error: 0.01493574 \n",
      "Epoch [2121 / 5000] average reconstruction error: 0.00955791 \n",
      "Epoch [2131 / 5000] average reconstruction error: 0.00468371 \n",
      "Epoch [2141 / 5000] average reconstruction error: 0.00348916 \n",
      "Epoch [2151 / 5000] average reconstruction error: 0.00253357 \n",
      "Epoch [2161 / 5000] average reconstruction error: 0.00197021 \n",
      "Epoch [2171 / 5000] average reconstruction error: 0.00167523 \n",
      "Epoch [2181 / 5000] average reconstruction error: 0.00149613 \n",
      "Epoch [2191 / 5000] average reconstruction error: 0.00137199 \n",
      "Epoch [2201 / 5000] average reconstruction error: 0.00128737 \n",
      "Epoch [2211 / 5000] average reconstruction error: 0.00122439 \n",
      "Epoch [2221 / 5000] average reconstruction error: 0.00117466 \n",
      "Epoch [2231 / 5000] average reconstruction error: 0.00113299 \n",
      "Epoch [2241 / 5000] average reconstruction error: 0.00109803 \n",
      "Epoch [2251 / 5000] average reconstruction error: 0.00106604 \n",
      "Epoch [2261 / 5000] average reconstruction error: 0.00103948 \n",
      "Epoch [2271 / 5000] average reconstruction error: 0.00101419 \n",
      "Epoch [2281 / 5000] average reconstruction error: 0.00099028 \n",
      "Epoch [2291 / 5000] average reconstruction error: 0.00096885 \n",
      "Epoch [2301 / 5000] average reconstruction error: 0.00094900 \n",
      "Epoch [2311 / 5000] average reconstruction error: 0.00092961 \n",
      "Epoch [2321 / 5000] average reconstruction error: 0.00091206 \n",
      "Epoch [2331 / 5000] average reconstruction error: 0.00089588 \n",
      "Epoch [2341 / 5000] average reconstruction error: 0.00087945 \n",
      "Epoch [2351 / 5000] average reconstruction error: 0.00086493 \n",
      "Epoch [2361 / 5000] average reconstruction error: 0.00085005 \n",
      "Epoch [2371 / 5000] average reconstruction error: 0.00083565 \n",
      "Epoch [2381 / 5000] average reconstruction error: 0.00082327 \n",
      "Epoch [2391 / 5000] average reconstruction error: 0.00080909 \n",
      "Epoch [2401 / 5000] average reconstruction error: 0.00079605 \n",
      "Epoch [2411 / 5000] average reconstruction error: 0.00078677 \n",
      "Epoch [2421 / 5000] average reconstruction error: 0.00080927 \n",
      "Epoch [2431 / 5000] average reconstruction error: 0.00077795 \n",
      "Epoch [2441 / 5000] average reconstruction error: 0.00075214 \n",
      "Epoch [2451 / 5000] average reconstruction error: 0.00074883 \n",
      "Epoch [2461 / 5000] average reconstruction error: 0.00095439 \n",
      "Epoch [2471 / 5000] average reconstruction error: 0.02331441 \n",
      "Epoch [2481 / 5000] average reconstruction error: 0.04013387 \n",
      "Epoch [2491 / 5000] average reconstruction error: 0.01919373 \n",
      "Epoch [2501 / 5000] average reconstruction error: 0.01193457 \n",
      "Epoch [2511 / 5000] average reconstruction error: 0.01109604 \n",
      "Epoch [2521 / 5000] average reconstruction error: 0.00590677 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Documents\\repo\\Intra\\autoencoder\\autoencoder_fold.ipynb Celda 28\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m enc_fold_nodes \u001b[39m=\u001b[39m enc_fold\u001b[39m.\u001b[39mapply(encoder, [enc_fold_nodes])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m#print(enc_fold_nodes)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m decoded \u001b[39m=\u001b[39m decode_structure_fold_(enc_fold_nodes[\u001b[39m0\u001b[39;49m], batch[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m#print(\"decoded\", decoded)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m l \u001b[39m=\u001b[39m []\n",
      "\u001b[1;32mc:\\Users\\User\\Documents\\repo\\Intra\\autoencoder\\autoencoder_fold.ipynb Celda 28\u001b[0m in \u001b[0;36mdecode_structure_fold_\u001b[1;34m(v, root)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m nd\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m createNode\u001b[39m.\u001b[39mcount \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m dec \u001b[39m=\u001b[39m decode_node (v, root)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mreturn\u001b[39;00m dec\n",
      "\u001b[1;32mc:\\Users\\User\\Documents\\repo\\Intra\\autoencoder\\autoencoder_fold.ipynb Celda 28\u001b[0m in \u001b[0;36mdecode_structure_fold_.<locals>.decode_node\u001b[1;34m(v, node)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     nd\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m decode_node(right, nodoSiguienteRight)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39mif\u001b[39;00m nodoSiguienteLeft \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     nd\u001b[39m.\u001b[39mleft  \u001b[39m=\u001b[39m decode_node(left, nodoSiguienteLeft)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mreturn\u001b[39;00m nd\n",
      "\u001b[1;32mc:\\Users\\User\\Documents\\repo\\Intra\\autoencoder\\autoencoder_fold.ipynb Celda 28\u001b[0m in \u001b[0;36mdecode_structure_fold_.<locals>.decode_node\u001b[1;34m(v, node)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     nd\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m decode_node(right, nodoSiguienteRight)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39mif\u001b[39;00m nodoSiguienteLeft \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     nd\u001b[39m.\u001b[39mleft  \u001b[39m=\u001b[39m decode_node(left, nodoSiguienteLeft)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mreturn\u001b[39;00m nd\n",
      "\u001b[1;32mc:\\Users\\User\\Documents\\repo\\Intra\\autoencoder\\autoencoder_fold.ipynb Celda 28\u001b[0m in \u001b[0;36mdecode_structure_fold_.<locals>.decode_node\u001b[1;34m(v, node)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     nodoSiguiente \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mright\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mif\u001b[39;00m nodoSiguiente \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         nd\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m decode_node(right, nodoSiguiente)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m nd\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39melif\u001b[39;00m node\u001b[39m.\u001b[39mchilds() \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m :\n",
      "\u001b[1;32mc:\\Users\\User\\Documents\\repo\\Intra\\autoencoder\\autoencoder_fold.ipynb Celda 28\u001b[0m in \u001b[0;36mdecode_structure_fold_.<locals>.decode_node\u001b[1;34m(v, node)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     nodoSiguiente \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mright\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mif\u001b[39;00m nodoSiguiente \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         nd\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m decode_node(right, nodoSiguiente)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m nd\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39melif\u001b[39;00m node\u001b[39m.\u001b[39mchilds() \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m :\n",
      "    \u001b[1;31m[... skipping similar frames: decode_structure_fold_.<locals>.decode_node at line 26 (2 times)]\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\Documents\\repo\\Intra\\autoencoder\\autoencoder_fold.ipynb Celda 28\u001b[0m in \u001b[0;36mdecode_structure_fold_.<locals>.decode_node\u001b[1;34m(v, node)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     nodoSiguiente \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mright\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mif\u001b[39;00m nodoSiguiente \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         nd\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m decode_node(right, nodoSiguiente)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m nd\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39melif\u001b[39;00m node\u001b[39m.\u001b[39mchilds() \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m :\n",
      "\u001b[1;32mc:\\Users\\User\\Documents\\repo\\Intra\\autoencoder\\autoencoder_fold.ipynb Celda 28\u001b[0m in \u001b[0;36mdecode_structure_fold_.<locals>.decode_node\u001b[1;34m(v, node)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m nd\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39melif\u001b[39;00m node\u001b[39m.\u001b[39mchilds() \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m :\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     right, radius \u001b[39m=\u001b[39m Grassdecoder\u001b[39m.\u001b[39;49minternalDecoder(v)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     lossEstructura \u001b[39m=\u001b[39m classifyLossEstimator(cl, node)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     lossAtrs \u001b[39m=\u001b[39m calcularLossAtributo( node, radius )\n",
      "\u001b[1;32mc:\\Users\\User\\Documents\\repo\\Intra\\autoencoder\\autoencoder_fold.ipynb Celda 28\u001b[0m in \u001b[0;36mGRASSDecoder.internalDecoder\u001b[1;34m(self, feature)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minternalDecoder\u001b[39m(\u001b[39mself\u001b[39m, feature):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minternal_decoder(feature)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\py_torc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\User\\Documents\\repo\\Intra\\autoencoder\\autoencoder_fold.ipynb Celda 28\u001b[0m in \u001b[0;36mInternalDecoder.forward\u001b[1;34m(self, parent_feature)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, parent_feature):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     vector \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp(parent_feature)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     vector \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtanh(vector)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/autoencoder_fold.ipynb#X36sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     vector \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlp2(vector)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\py_torc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\py_torc\\lib\\site-packages\\torch\\nn\\modules\\linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "learning_rate = 1e-4\n",
    "\n",
    "\n",
    "params = list(encoder.parameters()) + list(Grassdecoder.parameters()) \n",
    "\n",
    "opt = torch.optim.Adam(params, lr=learning_rate) \n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.MultiStepLR(opt, milestones=[200], gamma=0.1)\n",
    "    \n",
    "train_loss_avg = []\n",
    "#train_loss_avg.append(0)\n",
    "ce_avg = []\n",
    "mse_avg = []\n",
    "lr_list = []\n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    train_loss_avg.append(0)\n",
    "   #batch es cada arbol del dataloader\n",
    "    for batch_idx, batch in enumerate(data_loader):\n",
    "        # Initialize torchfold for *encoding*\n",
    "        enc_fold = torch_f.Fold(device)\n",
    "        enc_fold_nodes = []     # list of fold nodes for encoding, lista con la \"hoja de ruta\" de los dos arboles\n",
    "        # Collect computation nodes recursively from encoding process\n",
    "        n_nodes = []\n",
    "        for example in batch: #example es un arbolito\n",
    "            c = []\n",
    "            n = example.count_nodes(example, c)\n",
    "            n_nodes.append(len(n))\n",
    "            encode_structure_fold(enc_fold, example)\n",
    "            enc_fold_nodes.append(encode_structure_fold(enc_fold, example))\n",
    "       \n",
    "        # Apply the computations on the encoder model\n",
    "       \n",
    "        enc_fold_nodes = enc_fold.apply(encoder, [enc_fold_nodes])\n",
    "        #print(enc_fold_nodes)\n",
    "\n",
    "        \n",
    "        decoded = decode_structure_fold_(enc_fold_nodes[0], batch[0])\n",
    "        #print(\"decoded\", decoded)\n",
    "        l = []\n",
    "        mse_loss_list = decoded.traverseInorderMSE(decoded, l)\n",
    "        l = []\n",
    "        ce_loss_list = decoded.traverseInorderCE(decoded, l)\n",
    "            \n",
    "        mse_loss = sum(mse_loss_list) / len(mse_loss_list)\n",
    "        ce_loss  = sum(ce_loss_list)  / len(ce_loss_list)\n",
    "        total_loss = (0.5*ce_loss + mse_loss)\n",
    "        \n",
    "        # Initialize torchfold for *decoding*\n",
    "        '''\n",
    "        \n",
    "        dec_fold = torch_f.Fold(device)\n",
    "        # Collect computation nodes recursively from decoding process\n",
    "        dec_fold_nodes = []\n",
    "        kld_fold_nodes = []\n",
    "\n",
    "        t_l = []\n",
    "        for f in enc_fold_nodes:\n",
    "            for t in f:\n",
    "                t_l.append(t)\n",
    "        for example, fnode in zip(batch, t_l): #example es el arbol y fnode el encodeado\n",
    "            dec_fold_nodes.append(decode_structure_fold_grass(dec_fold, fnode, example))\n",
    "        # Apply the computations on the decoder model\n",
    "        #print(\"dec fold nodes\", dec_fold_nodes)\n",
    "           \n",
    "                       \n",
    "        total_loss = dec_fold.apply(Grassdecoder, [dec_fold_nodes])#[0]\n",
    "        print(\"total loss\", total_loss)\n",
    "        n_nodes = torch.tensor(n_nodes, device = device)\n",
    "        total_loss = torch.div(total_loss[0], n_nodes)\n",
    "        total_loss = total_loss.sum() / len(batch)  #n_nodes[0] #modificar y dividir por el promedio?\n",
    "        '''\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        total_loss.backward()\n",
    "        opt.step()\n",
    "        train_loss_avg[-1] += (total_loss.item())\n",
    "        \n",
    "\n",
    "        \n",
    "    save_best_model(\n",
    "        total_loss, epoch, encoder, Grassdecoder, opt)\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch [%d / %d] average reconstruction error: %.8f ' % (epoch+1, epochs, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2458\n"
     ]
    }
   ],
   "source": [
    "encoder = GRASSEncoder(input_size = 4, feature_size=128, hidden_size=32).to(device)\n",
    "decoder = GRASSDecoder(latent_size=128, hidden_size=256, mult = mult).to(device)\n",
    "\n",
    "checkpoint = torch.load(\"outputs/best_model.pth\")\n",
    "encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "print(\"epoch\", epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([[0.2845, 0.5107, 0.6827, 0.8354]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "1 tensor([[0.2411, 0.4905, 0.6356, 0.8620]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "2 tensor([[0.2138, 0.4785, 0.6807, 0.9130]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "3 tensor([[0.1766, 0.4763, 0.6555, 0.9154]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "4 tensor([[0.1400, 0.4734, 0.6099, 0.9063]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "5 tensor([[0.1088, 0.4760, 0.5655, 0.9019]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "6 tensor([[0.0830, 0.4835, 0.5255, 0.9024]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "7 tensor([[0.0620, 0.4936, 0.4889, 0.9070]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "8 tensor([[0.0448, 0.5042, 0.4538, 0.9136]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "9 tensor([[0.0329, 0.5135, 0.4197, 0.9211]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "10 tensor([[0.0265, 0.5209, 0.3862, 0.9284]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "11 tensor([[0.0270, 0.5257, 0.3531, 0.9348]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "12 tensor([[0.0356, 0.5278, 0.3207, 0.9388]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "13 tensor([[0.0533, 0.5273, 0.2895, 0.9397]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "14 tensor([[0.0809, 0.5247, 0.2590, 0.9357]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "15 tensor([[0.1198, 0.5206, 0.2298, 0.9265]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "16 tensor([[0.1705, 0.5156, 0.2019, 0.9101]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "17 tensor([[0.2351, 0.5103, 0.1746, 0.8845]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "18 tensor([[0.3153, 0.5060, 0.1477, 0.8466]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "19 tensor([[0.4143, 0.5044, 0.1201, 0.7920]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "20 tensor([[0.5334, 0.5077, 0.0909, 0.7149]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "21 tensor([[0.6678, 0.5196, 0.0592, 0.6093]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "22 tensor([[0.7922, 0.5424, 0.0254, 0.4771]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "23 tensor([[ 0.8598,  0.5767, -0.0045,  0.3388]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "24 tensor([[1.0002e+00, 5.9223e-01, 8.0261e-04, 6.9129e-04]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "25 tensor([[0.3355, 0.5281, 0.7378, 0.9327]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "26 tensor([[0.3472, 0.4689, 0.7893, 0.7277]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "27 tensor([[0.3578, 0.4725, 0.8127, 0.6812]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "28 tensor([[0.3315, 0.4520, 0.8611, 0.6799]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "29 tensor([[0.3125, 0.4040, 0.8852, 0.7180]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "30 tensor([[0.2903, 0.3490, 0.9046, 0.7567]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "31 tensor([[0.2729, 0.2937, 0.9215, 0.7911]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "32 tensor([[0.2654, 0.2459, 0.9329, 0.8169]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "33 tensor([[0.2669, 0.2114, 0.9347, 0.8321]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "34 tensor([[0.2731, 0.1919, 0.9258, 0.8386]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "35 tensor([[0.2795, 0.1855, 0.9080, 0.8398]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "36 tensor([[ 1.4497e-01, -4.6325e-04,  9.9970e-01,  9.9995e-01]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "37 tensor([[0.4088, 0.6411, 0.7396, 0.4923]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "38 tensor([[0.4097, 0.6395, 0.7445, 0.4757]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "39 tensor([[0.4505, 0.6719, 0.7120, 0.4270]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "40 tensor([[0.4759, 0.7189, 0.7296, 0.4055]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "41 tensor([[0.4871, 0.7409, 0.7302, 0.3977]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "42 tensor([[0.4942, 0.7562, 0.7236, 0.3858]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "43 tensor([[0.5003, 0.7705, 0.7156, 0.3725]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "44 tensor([[0.5058, 0.7851, 0.7071, 0.3596]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "45 tensor([[0.5103, 0.8003, 0.6985, 0.3474]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "46 tensor([[0.5139, 0.8161, 0.6902, 0.3360]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "47 tensor([[0.5156, 0.8325, 0.6822, 0.3256]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "48 tensor([[0.5161, 0.8492, 0.6745, 0.3161]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "49 tensor([[0.5147, 0.8665, 0.6671, 0.3075]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "50 tensor([[0.5115, 0.8843, 0.6598, 0.2998]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "51 tensor([[0.5063, 0.9022, 0.6523, 0.2924]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "52 tensor([[0.4996, 0.9203, 0.6445, 0.2853]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "53 tensor([[0.4916, 0.9382, 0.6361, 0.2785]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "54 tensor([[0.4825, 0.9552, 0.6264, 0.2716]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "55 tensor([[0.4730, 0.9708, 0.6150, 0.2640]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "56 tensor([[0.4640, 0.9847, 0.6012, 0.2562]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "57 tensor([[0.4560, 0.9954, 0.5851, 0.2479]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "58 tensor([[0.4498, 1.0030, 0.5658, 0.2388]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "59 tensor([[0.4460, 1.0064, 0.5433, 0.2293]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "60 tensor([[0.4452, 1.0058, 0.5182, 0.2193]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "61 tensor([[0.4471, 1.0014, 0.4910, 0.2088]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "62 tensor([[0.4503, 1.0014, 0.5082, 0.2766]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = iter(data_loader).next()[0]\n",
    "enc_fold = torch_f.Fold(device)\n",
    "enc_fold_nodes = []\n",
    "enc_fold_nodes.append(encode_structure_fold(enc_fold, input))\n",
    "enc_fold_nodes = enc_fold.apply(encoder, [enc_fold_nodes])\n",
    "encoded = enc_fold_nodes[0]\n",
    "decoded = decode_testing_grass(encoded, input, 200, decoder)\n",
    "count = []\n",
    "numerar_nodos(decoded, count)\n",
    "decoded.traverseInorder(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d88fe74afd4eb6b13226f575b78691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(0.5, 0.5,"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotTree(input, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c187b0645cf74b33ab196c3bf48affbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(0.5133653"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotTree(decoded, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverseleaf(root):\n",
    "    if root is not None:\n",
    "        traverseleaf(root.left)\n",
    "        if root.is_leaf():\n",
    "            print(root.radius)\n",
    "        traverseleaf(root.right)\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9503, 0.9776, 0.3072, 0.6423]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.2194, -0.0301,  0.9954,  0.5094]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.7873,  0.9953, -0.0255,  0.4002]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "traverseleaf(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 0.9987, 0.3278, 0.6864], device='cuda:0')\n",
      "tensor([0.2583, 0.0000, 1.0000, 0.5396], device='cuda:0')\n",
      "tensor([0.8033, 1.0000, 0.0000, 0.4182], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "traverseleaf(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = []\n",
    "n_nodes = input.count_nodes(input,c)\n",
    "len(n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = []\n",
    "n_nodes = decoded.count_nodes(decoded,c)\n",
    "len(n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 16 2\n"
     ]
    }
   ],
   "source": [
    "li = []\n",
    "decoded.traverseInorderChilds(decoded, li)\n",
    "zero = [a for a in li if a == 0]\n",
    "one = [a for a in li if a == 1]\n",
    "two = [a for a in li if a == 2]\n",
    "qzero = len(zero)\n",
    "qOne = len(one)\n",
    "qtwo = len(two)\n",
    "print(qzero, qOne, qtwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 16 2\n"
     ]
    }
   ],
   "source": [
    "li = []\n",
    "input.traverseInorderChilds(input, li)\n",
    "zero = [a for a in li if a == 0]\n",
    "one = [a for a in li if a == 1]\n",
    "two = [a for a in li if a == 2]\n",
    "qzero = len(zero)\n",
    "qOne = len(one)\n",
    "qtwo = len(two)\n",
    "print(qzero, qOne, qtwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (20,10))\n",
    "plt.plot(train_loss_avg) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py_torc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f3e717cd274da89498094fde320e6eab1bf0f52911d27cf47473187acb3fe8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
