{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import raiseExceptions\n",
    "from tokenize import Double\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "from vec3 import Vec3\n",
    "import meshplot as mp\n",
    "import torch\n",
    "torch.manual_seed(125)\n",
    "import random\n",
    "random.seed(125)\n",
    "import torch_f as torch_f\n",
    "from modelo import Node, GRASSEncoder, GRASSDecoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTree( root, dec ):\n",
    "    graph = nx.Graph()\n",
    "    root.toGraph( graph, 0, dec)\n",
    "    edges=nx.get_edge_attributes(graph,'procesada')\n",
    "\n",
    "    p = mp.plot( np.array([ graph.nodes[v]['posicion'] for v in graph.nodes]), shading={'point_size':0.1}, return_plot=True)\n",
    "\n",
    "    for arista in graph.edges:\n",
    "        p.add_lines( graph.nodes[arista[0]]['posicion'], graph.nodes[arista[1]]['posicion'])\n",
    "\n",
    "    return \n",
    "\n",
    "def traverse(root, tree):\n",
    "       \n",
    "        if root is not None:\n",
    "            traverse(root.left, tree)\n",
    "            tree.append((root.radius, root.data))\n",
    "            traverse(root.right, tree)\n",
    "            return tree\n",
    "\n",
    "def traverse_2(tree1, tree2, t_l):\n",
    "       \n",
    "        if tree1 is not None:\n",
    "            traverse_2(tree1.left, tree2.left, t_l)\n",
    "            if tree2:\n",
    "                t_l.append((tree1.radius, tree2.radius))\n",
    "                print((tree1.radius, tree2.radius))\n",
    "            else:\n",
    "                t_l.append(tree1.radius)\n",
    "                print((tree1.radius))\n",
    "            traverse_2(tree1.right, tree2, t_l)\n",
    "            return t_l\n",
    "            \n",
    "\n",
    "def traverse_conexiones(root, tree):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            traverse_conexiones(root.left, tree)\n",
    "            if root.right is not None:\n",
    "                tree.append((root.data, root.right.data))\n",
    "            if root.left is not None:\n",
    "                tree.append((root.data, root.left.data))\n",
    "            traverse_conexiones(root.right, tree)\n",
    "            return tree\n",
    "\n",
    "def arbolAGrafo (nodoRaiz):\n",
    "    \n",
    "    conexiones = []\n",
    "    lineas = traverse_conexiones(nodoRaiz, conexiones)\n",
    "    tree = []\n",
    "    tree = traverse(nodoRaiz, tree)\n",
    "\n",
    "    vertices = []\n",
    "    verticesCrudos = []\n",
    "    for node in tree:\n",
    "        vertice = node[0][0][:3]\n",
    "        rad = node[0][0][-1]\n",
    "        num = node[1]\n",
    "        \n",
    "        #vertices.append((num, {'posicion': Vec3( vertice[0], vertice[1], vertice[2]), 'radio': rad} ))\n",
    "        vertices.append((len(verticesCrudos),{'posicion': Vec3( vertice[0], vertice[1], vertice[2]), 'radio': rad}))\n",
    "        verticesCrudos.append(vertice)\n",
    "\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from( vertices )\n",
    "    G.add_edges_from( lineas )\n",
    "    \n",
    "    return G\n",
    "\n",
    "\n",
    "def createNode(data, radius, position = None, left = None, right = None, cl_prob = None, ce = None, mse=None):\n",
    "        \"\"\"\n",
    "        Utility function to create a node.\n",
    "        \"\"\"\n",
    "        return Node(data, radius, position, left, right, cl_prob, ce, mse)\n",
    " \n",
    "def deserialize(data):\n",
    "    if  not data:\n",
    "        return \n",
    "    nodes = data.split(';')  \n",
    "    #print(\"node\",nodes[3])\n",
    "    def post_order(nodes):\n",
    "                \n",
    "        if nodes[-1] == '#':\n",
    "            nodes.pop()\n",
    "            return None\n",
    "        node = nodes.pop().split('_')\n",
    "        data = int(node[0])\n",
    "        #radius = float(node[1])\n",
    "        #print(\"node\", node)\n",
    "        #breakpoint()\n",
    "        radius = node[1]\n",
    "        #print(\"radius\", radius)\n",
    "        rad = radius.split(\",\")\n",
    "        rad [0] = rad[0].replace('[','')\n",
    "        rad [3] = rad[3].replace(']','')\n",
    "        r = []\n",
    "        for value in rad:\n",
    "            r.append(float(value))\n",
    "        #r =[float(num) for num in radius if num.isdigit()]\n",
    "        r = torch.tensor(r, device=device)\n",
    "        #breakpoint()\n",
    "        root = createNode(data, r)\n",
    "        root.right = post_order(nodes)\n",
    "        root.left = post_order(nodes)\n",
    "        \n",
    "        return root    \n",
    "    return post_order(nodes)    \n",
    "\n",
    "\n",
    "def read_tree(filename):\n",
    "    #with open('./trees/' +'prof3/' +filename, \"r\") as f:\n",
    "    with open('./trees/' +filename, \"r\") as f:\n",
    "        byte = f.read() \n",
    "        return byte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Grassencoder = GRASSEncoder(input_size = 4, feature_size=512, hidden_size=1024)\n",
    "Grassencoder = Grassencoder.to(device)\n",
    "\n",
    "\n",
    "def encode_structure_fold(fold, root):\n",
    "    \n",
    "    \n",
    "    def encode_node(node):\n",
    "        \n",
    "        if node is None:\n",
    "            return\n",
    "        \n",
    "        if node.is_leaf():\n",
    "            return fold.add('leafEncoder', node.radius)\n",
    "        else:\n",
    "            left = encode_node(node.left)\n",
    "            right = encode_node(node.right)\n",
    "            if left is not None:\n",
    "             \n",
    "                return fold.add('bifurcationEncoder', node.radius, right, left)\n",
    "            else:\n",
    "                return fold.add('internalEncoder', node.radius, right)\n",
    "        \n",
    "\n",
    "    encoding = encode_node(root)\n",
    "    \n",
    "    return encoding\n",
    "  \n",
    "def encode_structure(root):\n",
    "    \n",
    "    def encode_node(node):\n",
    "          \n",
    "        if node is None:\n",
    "            return\n",
    "        if node.is_leaf():\n",
    "            return Grassencoder.leafEncoder(node.radius.reshape(-1,4))\n",
    "        else :\n",
    "            left = encode_node(node.left)\n",
    "            right = encode_node(node.right)\n",
    "            if left is not None:\n",
    "                return Grassencoder.bifurcationEncoder(node.radius.reshape(-1,4), right, left)\n",
    "            else:\n",
    "                return Grassencoder.internalEncoder(node.radius.reshape(-1,4), right)\n",
    "        \n",
    "\n",
    "    encoding = encode_node(root)\n",
    "   \n",
    "    return encoding\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerar_nodos(root, count):\n",
    "    if root is not None:\n",
    "        numerar_nodos(root.left, count)\n",
    "        root.data = len(count)\n",
    "        count.append(1)\n",
    "        numerar_nodos(root.right, count)\n",
    "        return \n",
    "\n",
    "\n",
    "def traversefeatures(root, features):\n",
    "       \n",
    "    if root is not None:\n",
    "        traversefeatures(root.left, features)\n",
    "        features.append(root.radius)\n",
    "        traversefeatures(root.right, features)\n",
    "        return features\n",
    "\n",
    "def norm(root, minx, miny, minz, minr, maxx, maxy, maxz, maxr):\n",
    "    \n",
    "    if root is not None:\n",
    "        mx = minx.clone().detach()\n",
    "        my = miny.clone().detach()\n",
    "        mz = minz.clone().detach()\n",
    "        mr = minr.clone().detach()\n",
    "        Mx = maxx.clone().detach()\n",
    "        My = maxy.clone().detach()\n",
    "        Mz = maxz.clone().detach()\n",
    "        Mr = maxr.clone().detach()\n",
    "       \n",
    "        root.radius[0] = (root.radius[0] - minx)/(maxx - minx)\n",
    "        root.radius[1] = (root.radius[1] - miny)/(maxy - miny)\n",
    "        root.radius[2] = (root.radius[2] - minz)/(maxz - minz)\n",
    "        root.radius[3] = (root.radius[3] - minr)/(maxr - minr)\n",
    "        \n",
    "        norm(root.left, mx, my, mz, mr, Mx, My, Mz, Mr)\n",
    "        norm(root.right, mx, my, mz, mr, Mx, My, Mz, Mr)\n",
    "        return \n",
    "\n",
    "def normalize_features(root):\n",
    "    features = []\n",
    "    features = traversefeatures(root, features)\n",
    "    \n",
    "    x = [tensor[0] for tensor in features]\n",
    "    y = [tensor[1] for tensor in features]\n",
    "    z = [tensor[2] for tensor in features]\n",
    "    r = [tensor[3] for tensor in features]\n",
    " \n",
    "    norm(root, min(x), min(y), min(z), min(r), max(x), max(y), max(z), max(r))\n",
    "\n",
    "    return \n",
    "\n",
    "def traversefeatures(root, features):\n",
    "       \n",
    "    if root is not None:\n",
    "        traversefeatures(root.left, features)\n",
    "        features.append(root.radius)\n",
    "        traversefeatures(root.right, features)\n",
    "        return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tree0.dat', 'tree1.dat', 'tree10.dat', 'tree100.dat', 'tree101.dat', 'tree102.dat', 'tree103.dat', 'tree104.dat', 'tree105.dat', 'tree106.dat', 'tree107.dat', 'tree108.dat', 'tree109.dat', 'tree11.dat', 'tree110.dat', 'tree111.dat', 'tree112.dat', 'tree113.dat', 'tree114.dat', 'tree115.dat']\n"
     ]
    }
   ],
   "source": [
    "def my_collate(batch):\n",
    "    return batch\n",
    "\n",
    "#t_list = ['ArteryObjAN1-7.dat','ArteryObjAN1-0.dat', 'ArteryObjAN1-17.dat',  'ArteryObjAN1-11.dat']\n",
    "\n",
    "#t_list = ['ArteryObjAN1-0.dat','ArteryObjAN1-7.dat', 'ArteryObjAN1-17.dat',  'ArteryObjAN1-11.dat', 'ArteryObjAN1-19.dat', 'ArteryObjAN2-4.dat', 'ArteryObjAN2-6.dat', \n",
    "#           'ArteryObjAN25-18.dat']\n",
    "#t_list = ['ArteryObjAN1-17-55.dat', 'ArteryObjAN1-17-22.dat', \"ArteryObjAN1-17-12.dat\", \"ArteryObjAN1-17-9.dat\",'ArteryObjAN1-17-42.dat', 'ArteryObjAN1-17-64.dat', \"ArteryObjAN1-17-70.dat\", \"ArteryObjAN1-17-1.dat\"]\n",
    "#t_list = ['ArteryObjAN1-17.dat']\n",
    "#t_list = ['ArteryObjAN1-11.dat']\n",
    "\n",
    "\n",
    "#t_list = ['test2.dat']\n",
    "\n",
    "#t_list = ['ArteryObjAN31-14.dat']\n",
    "#t_list = os.listdir(\"./trees\")[:20]\n",
    "t_list = os.listdir(\"./trees/prof5\")[:20]\n",
    "print(t_list)\n",
    "class tDataset(Dataset):\n",
    "    def __init__(self, dir, transform=None):\n",
    "        self.names = dir\n",
    "        self.transform = transform\n",
    "        self.data = [] #lista con las strings de todos los arboles\n",
    "        for file in self.names:\n",
    "            self.data.append(read_tree('prof5/'+file))\n",
    "        self.trees = []\n",
    "        for tree in self.data:\n",
    "            deserial = deserialize(tree)\n",
    "            normalize_features(deserial)\n",
    "            self.trees.append(deserial)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #file = self.names[idx]\n",
    "        #string = read_tree(file)\n",
    "        tree = self.trees[idx]\n",
    "        return tree\n",
    "\n",
    "batch_size = 10\n",
    "dataset = tDataset(t_list)\n",
    "data_loader = DataLoader(dataset, batch_size = batch_size, shuffle=True, collate_fn=my_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "[13, 5, 5, 5, 8, 8, 6, 8, 7, 8, 5, 6, 5, 5, 5, 5, 5, 10, 5, 5]\n",
      "6.45\n",
      "3.7\n",
      "2.05\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "n_no = []\n",
    "qzero = 0\n",
    "qOne = 0\n",
    "qtwo = 0\n",
    "\n",
    "for batch in data_loader:\n",
    "    for tree in batch:\n",
    "        count = []\n",
    "        n = tree.count_nodes(tree, count)\n",
    "        n_no.append(len(n))\n",
    "        li = []\n",
    "        tree.traverseInorderChilds(tree, li)\n",
    "        zero = [a for a in li if a == 0]\n",
    "        one = [a for a in li if a == 1]\n",
    "        two = [a for a in li if a == 2]\n",
    "        qzero += len(zero)\n",
    "        qOne += len(one)\n",
    "        qtwo += len(two)\n",
    "\n",
    "print(len(data_loader)*batch_size)\n",
    "print(n_no)\n",
    "nprom = np.mean(n_no)\n",
    "print(nprom)\n",
    "qzero /= len(data_loader)*batch_size\n",
    "qOne /= len(data_loader)*batch_size\n",
    "qtwo /= len(data_loader)*batch_size\n",
    "\n",
    "print(qzero)\n",
    "print(qOne)\n",
    "print(qtwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if round(qzero) == 0:\n",
    "    qzero = 1\n",
    "if round(qOne) == 0:\n",
    "    qOne = 1\n",
    "if round(qtwo) == 0:\n",
    "    qtwo = 1\n",
    "mult = torch.tensor([1/round(qzero),1/round(qOne),1/round(qtwo)], device = device)\n",
    "\n",
    "Grassdecoder = GRASSDecoder(latent_size=512, hidden_size=1024, mult = mult)\n",
    "Grassdecoder = Grassdecoder.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decode structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7\n",
      "2.05\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "print(qzero)\n",
    "print(qOne)\n",
    "print(qtwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2500, 0.5000, 1.0000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(mult)\n",
    "def calcularLossEstructura(cl_p, original):\n",
    "    \n",
    "    if original is None:\n",
    "        return\n",
    "    #mult = torch.tensor([1/round(qzero),1/round(qOne),1/round(qtwo)], device = device)\n",
    "    ce = nn.CrossEntropyLoss(weight = mult)\n",
    "\n",
    "    if original.childs() == 0:\n",
    "        vector = [1, 0, 0] \n",
    "    if original.childs() == 1:\n",
    "        vector = [0, 1, 0]\n",
    "    if original.childs() == 2:\n",
    "        vector = [0, 0, 1] \n",
    "\n",
    "\n",
    "    c = ce(cl_p, torch.tensor(vector, device=device, dtype = torch.float).reshape(1, 3))\n",
    "    #print(\"original\", vector)\n",
    "    #print(\"clasificador\", cl_p)\n",
    "    #print(\"ce\", 0.4*c)\n",
    "    return c\n",
    "\n",
    "\n",
    "def calcularLossAtributo(nodo, radio):\n",
    "    if nodo is None:\n",
    "        return\n",
    "    #print(\"nodo\", nodo)\n",
    "    #print(\"radio\", radio)\n",
    "\n",
    "    radio = radio.reshape(-1,4)\n",
    "    nodo = nodo.radius.reshape(-1,4)\n",
    "    l2    = nn.MSELoss()\n",
    "   \n",
    "    mse = l2(radio, nodo)\n",
    "    #print(\"mse\", mse)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchNode(node, key):\n",
    "     \n",
    "    if (node == None):\n",
    "        return False\n",
    " \n",
    "    if (node.data == key):\n",
    "        return node\n",
    "        \n",
    " \n",
    "    \"\"\" then recur on left subtree \"\"\"\n",
    "    res1 = searchNode(node.left, key)\n",
    "    # node found, no need to look further\n",
    "    if res1:\n",
    "        return res1\n",
    " \n",
    "    \"\"\" node is not found in left,\n",
    "    so recur on right subtree \"\"\"\n",
    "    res2 = searchNode(node.right, key)\n",
    "    return res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLevelUtil(node, data, level):\n",
    "    if (node == None):\n",
    "        return 0\n",
    " \n",
    "    if (node.data == data):\n",
    "        return level\n",
    " \n",
    "    downlevel = getLevelUtil(node.left, data, level + 1)\n",
    "\n",
    "    if (downlevel != 0):\n",
    "        return downlevel\n",
    " \n",
    "    downlevel = getLevelUtil(node.right, data, level + 1)\n",
    "    return downlevel\n",
    " \n",
    "# Returns level of given data value\n",
    " \n",
    " \n",
    "def getLevel(node, data):\n",
    "    return getLevelUtil(node, data, 1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data_loader:\n",
    "    for data in d:\n",
    "        count = []\n",
    "        numerar_nodos(data, count)\n",
    "        c = []\n",
    "        n_nodes = data.count_nodes(data, c)\n",
    "        for x in range(0, len(n_nodes)):\n",
    "            level = getLevel(data, x)\n",
    "            if (level):\n",
    "                #print(\"Level of\", x, \"is\", getLevel(input, x))\n",
    "                node = searchNode(data, x)\n",
    "                node.level = getLevel(data, x)\n",
    "            else:\n",
    "                print(x, \"is not present in tree\")\n",
    "        tree_level = []\n",
    "        data.get_tree_level(data, tree_level)\n",
    "        data.set_tree_level(data, sum(tree_level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_structure_fold_grass(fold, v, root):\n",
    "   \n",
    "    def decode_node(fold, v, node):\n",
    "        \n",
    "        \n",
    "        if node.childs() == 0 : \n",
    "\n",
    "            radio = fold.add('featureDecoder', v)\n",
    "            lossAtributo = fold.add('calcularLossAtributo', node, radio)\n",
    "\n",
    "            label = fold.add('nodeClassifier', v)\n",
    "            \n",
    "            lossEstructura = fold.add('classifyLossEstimator', label, node)  \n",
    "            multipl = node.level/node.treelevel\n",
    "            losse = fold.add('vectorMult', multipl, lossEstructura)\n",
    "            \n",
    "            loss =  fold.add('vectorAdder', losse, lossAtributo)       \n",
    "            return loss\n",
    "\n",
    "            \n",
    "            \n",
    "        elif node.childs() == 1 :\n",
    "            right, radius = fold.add('internalDecoder', v).split(2)\n",
    "            label = fold.add('nodeClassifier', v)\n",
    "            nodoSiguiente = node.right\n",
    "            if nodoSiguiente is not None:\n",
    "                right_loss = decode_node(fold, right, nodoSiguiente)\n",
    "\n",
    "            lossEstructura = fold.add('classifyLossEstimator', label, node)\n",
    "            lossAtributo = fold.add('calcularLossAtributo', node, radius)\n",
    "            multipl = node.level/node.treelevel\n",
    "            losse = fold.add('vectorMult', multipl, lossEstructura)\n",
    "            loss = fold.add('vectorAdder', losse, lossAtributo)\n",
    "            \n",
    "        \n",
    "            loss2 = fold.add('vectorAdder', loss, right_loss)\n",
    "            return loss2\n",
    "            \n",
    "            \n",
    "\n",
    "        elif node.childs() == 2 :\n",
    "            left, right, radius = fold.add('bifurcationDecoder', v).split(3)\n",
    "            \n",
    "            label = fold.add('nodeClassifier', v)            \n",
    "            \n",
    "            nodoSiguienteRight = node.right\n",
    "            nodoSiguienteLeft = node.left\n",
    "\n",
    "\n",
    "            if nodoSiguienteRight is not None:\n",
    "                right_loss = decode_node(fold, right, nodoSiguienteRight)\n",
    "             \n",
    "            if nodoSiguienteLeft is not None:\n",
    "                left_loss  = decode_node(fold, left, nodoSiguienteLeft)\n",
    "\n",
    "            multipl = node.level/node.treelevel\n",
    "            lossEstructura = fold.add('classifyLossEstimator', label, node)\n",
    "            losse = fold.add('vectorMult', multipl, lossEstructura)\n",
    "            lossAtributo   = fold.add('calcularLossAtributo', node, radius)\n",
    "            loss = fold.add('vectorAdder', losse, lossAtributo)\n",
    "            loss2 = fold.add('vectorAdder', loss, right_loss)\n",
    "            loss3 = fold.add('vectorAdder', loss2, left_loss)\n",
    "            \n",
    "            return loss3\n",
    "            \n",
    "\n",
    "    dec = decode_node (fold, v, root)\n",
    "    return dec\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decode testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_testing_grass(v, root, max, decoder):\n",
    "    def decode_node(v, node, max, decoder):\n",
    "        cl = decoder.nodeClassifier(v)\n",
    "        _, label = torch.max(cl, 1)\n",
    "        label = label.data\n",
    "        \n",
    "        #print(\"clasificador: \", label)\n",
    "        #if node is not None:\n",
    "        #    print(\"original:\", node.childs())\n",
    "        #else:\n",
    "        #    print(\"nodo en lugar incorrecto\")\n",
    "        if label == 0 and createNode.count <= max: ##output del classifier\n",
    "           \n",
    "            radio = decoder.featureDecoder(v)\n",
    "            lossEstructura = calcularLossEstructura(cl, node)\n",
    "            lossAtrs = calcularLossAtributo( node, radio )\n",
    "            if lossEstructura is not None:\n",
    "                multipl = node.level/node.treelevel\n",
    "                lossEstructura = multipl*lossEstructura\n",
    "            \n",
    "            return createNode(1,radio, ce = lossEstructura,  mse = lossAtrs)\n",
    "            #return createNode(1,radio)\n",
    "\n",
    "        elif label == 1 and createNode.count <= max:\n",
    "       \n",
    "            right, radius = decoder.internalDecoder(v)\n",
    "            lossEstructura = calcularLossEstructura(cl, node)\n",
    "            lossAtrs = calcularLossAtributo( node, radius )\n",
    "            if lossEstructura is not None:\n",
    "                multipl = node.level/node.treelevel\n",
    "                lossEstructura = multipl*lossEstructura\n",
    "            d = createNode(1, radius, ce = lossEstructura,  mse = lossAtrs) \n",
    "            #d = createNode(1, radius) \n",
    "\n",
    "           \n",
    "            if not node is None:\n",
    "                if not node.right is None:\n",
    "                    nodoSiguiente = node.right\n",
    "                else:\n",
    "                    nodoSiguiente = None\n",
    "            else:\n",
    "                nodoSiguiente = None\n",
    "            \n",
    "            d.right = decode_node(right, nodoSiguiente, max, decoder)\n",
    "            \n",
    "\n",
    "            return d\n",
    "       \n",
    "        elif label == 2 and createNode.count <= max:\n",
    "            left, right, radius = decoder.bifurcationDecoder(v)\n",
    "            lossEstructura = calcularLossEstructura(cl, node)\n",
    "            lossAtrs = calcularLossAtributo( node, radius )\n",
    "            if lossEstructura is not None:\n",
    "                multipl = node.level/node.treelevel\n",
    "                lossEstructura = multipl*lossEstructura\n",
    "            \n",
    "            d = createNode(1, radius, ce = lossEstructura,  mse = lossAtrs )\n",
    "            #d = createNode(1, radius )\n",
    "  \n",
    "            if not node is None: #el nodo existe, me fijo si tiene hijo der/izq\n",
    "                if not node.right is None:\n",
    "                    nodoSiguienteRight = node.right\n",
    "                else:\n",
    "                    nodoSiguienteRight = None\n",
    "                if not node.left is None:\n",
    "                    nodoSiguienteLeft = node.left\n",
    "                else:\n",
    "                    nodoSiguienteLeft = None\n",
    "            else: #el nodo no existe\n",
    "                nodoSiguienteRight = None\n",
    "                nodoSiguienteLeft = None\n",
    "            \n",
    "            d.right = decode_node(right, nodoSiguienteRight, max, decoder)\n",
    "            d.left = decode_node(left, nodoSiguienteLeft, max, decoder)\n",
    "            \n",
    "           \n",
    "            return d\n",
    "            \n",
    "    createNode.count = 0\n",
    "    dec = decode_node (v, root, max, decoder)\n",
    "    return dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveBestModel:\n",
    "    \"\"\"\n",
    "    Class to save the best model while training. If the current epoch's \n",
    "    validation loss is less than the previous least less, then save the\n",
    "    model state.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, best_valid_loss=float('inf')\n",
    "    ):\n",
    "        self.best_valid_loss = best_valid_loss\n",
    "        \n",
    "    def __call__(\n",
    "        self, current_valid_loss, \n",
    "        epoch, encoder, decoder, optimizer\n",
    "    ):\n",
    "        if current_valid_loss < self.best_valid_loss:\n",
    "            self.best_valid_loss = current_valid_loss\n",
    "            #print(f\"\\nBest validation loss: {self.best_valid_loss}\")\n",
    "            #print(f\"\\nSaving best model for epoch: {epoch+1}\\n\")\n",
    "            #'classifier_state_dict': classifier.state_dict(),\n",
    "            torch.save({\n",
    "                'epoch': epoch+1,\n",
    "                'encoder_state_dict': encoder.state_dict(),\n",
    "                'decoder_state_dict': decoder.state_dict(),\n",
    "                \n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, 'outputs/best_model.pth')\n",
    "\n",
    "save_best_model = SaveBestModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder con batch - decoder con batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpaufeldman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Documents\\rpoditela\\Intra\\autoencoder\\wandb\\run-20221205_163156-289pnxg2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/paufeldman/autoencoder4/runs/289pnxg2\" target=\"_blank\">genial-plasma-37</a></strong> to <a href=\"https://wandb.ai/paufeldman/autoencoder4\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/paufeldman/autoencoder4/runs/289pnxg2?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x26c8ccd5c90>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 8000\n",
    "learning_rate = 1e-5\n",
    "params = list(Grassencoder.parameters()) + list(Grassdecoder.parameters()) \n",
    "\n",
    "#opt = torch.optim.Adam(params, lr=learning_rate, weight_decay=0.0001) \n",
    "opt = torch.optim.Adam(params, lr=learning_rate) \n",
    "#opt = torch.optim.SGD(params, lr=learning_rate, momentum = 0.96) \n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.MultiStepLR(opt, milestones=[100], gamma=0.2)\n",
    "import wandb\n",
    "config = {\n",
    "  \"learning_rate\": learning_rate,\n",
    "  \"epochs\": epochs,\n",
    "  \"batch_size\": batch_size,\n",
    "  \"dataset\": t_list,\n",
    "  \"number of trees\": len(data_loader)*batch_size,\n",
    "  \"optim\": opt\n",
    "}\n",
    "wandb.init(project=\"autoencoder4\", entity=\"paufeldman\", config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 8000] average reconstruction error: 0.0709880963 \n",
      "Epoch [11 / 8000] average reconstruction error: 0.0894966200 \n",
      "Epoch [21 / 8000] average reconstruction error: 0.0205484815 \n",
      "Epoch [31 / 8000] average reconstruction error: 0.0422770642 \n",
      "Epoch [41 / 8000] average reconstruction error: 0.0077444292 \n",
      "Epoch [51 / 8000] average reconstruction error: 0.0060902811 \n",
      "Epoch [61 / 8000] average reconstruction error: 0.0054803342 \n",
      "Epoch [71 / 8000] average reconstruction error: 0.0066469866 \n",
      "Epoch [81 / 8000] average reconstruction error: 0.0069245705 \n",
      "Epoch [91 / 8000] average reconstruction error: 0.0078948857 \n",
      "Epoch [101 / 8000] average reconstruction error: 0.0052647465 \n",
      "Epoch [111 / 8000] average reconstruction error: 0.0047962563 \n",
      "Epoch [121 / 8000] average reconstruction error: 0.0056490847 \n",
      "Epoch [131 / 8000] average reconstruction error: 0.0052391207 \n",
      "Epoch [141 / 8000] average reconstruction error: 0.0035783544 \n",
      "Epoch [151 / 8000] average reconstruction error: 0.0064924988 \n",
      "Epoch [161 / 8000] average reconstruction error: 0.0031752035 \n",
      "Epoch [171 / 8000] average reconstruction error: 0.0028496857 \n",
      "Epoch [181 / 8000] average reconstruction error: 0.0057761162 \n",
      "Epoch [191 / 8000] average reconstruction error: 0.0053032488 \n",
      "Epoch [201 / 8000] average reconstruction error: 0.0045257127 \n",
      "Epoch [211 / 8000] average reconstruction error: 0.0035952807 \n",
      "Epoch [221 / 8000] average reconstruction error: 0.0037771766 \n",
      "Epoch [231 / 8000] average reconstruction error: 0.0029559974 \n",
      "Epoch [241 / 8000] average reconstruction error: 0.0011513379 \n",
      "Epoch [251 / 8000] average reconstruction error: 0.0039371322 \n",
      "Epoch [261 / 8000] average reconstruction error: 0.0045192628 \n",
      "Epoch [271 / 8000] average reconstruction error: 0.0057514147 \n",
      "Epoch [281 / 8000] average reconstruction error: 0.0050616381 \n",
      "Epoch [291 / 8000] average reconstruction error: 0.0023240854 \n",
      "Epoch [301 / 8000] average reconstruction error: 0.0017626537 \n",
      "Epoch [311 / 8000] average reconstruction error: 0.0037348995 \n",
      "Epoch [321 / 8000] average reconstruction error: 0.0032541198 \n",
      "Epoch [331 / 8000] average reconstruction error: 0.0037807748 \n",
      "Epoch [341 / 8000] average reconstruction error: 0.0020885945 \n",
      "Epoch [351 / 8000] average reconstruction error: 0.0012122961 \n",
      "Epoch [361 / 8000] average reconstruction error: 0.0006465634 \n",
      "Epoch [371 / 8000] average reconstruction error: 0.0010179338 \n",
      "Epoch [381 / 8000] average reconstruction error: 0.0015872365 \n",
      "Epoch [391 / 8000] average reconstruction error: 0.0008159517 \n",
      "Epoch [401 / 8000] average reconstruction error: 0.0002770461 \n",
      "Epoch [411 / 8000] average reconstruction error: 0.0005605613 \n",
      "Epoch [421 / 8000] average reconstruction error: 0.0004898690 \n",
      "Epoch [431 / 8000] average reconstruction error: 0.0002264203 \n",
      "Epoch [441 / 8000] average reconstruction error: 0.0002070359 \n",
      "Epoch [451 / 8000] average reconstruction error: 0.0003828150 \n",
      "Epoch [461 / 8000] average reconstruction error: 0.0002089357 \n",
      "Epoch [471 / 8000] average reconstruction error: 0.0001301933 \n",
      "Epoch [481 / 8000] average reconstruction error: 0.0001842719 \n",
      "Epoch [491 / 8000] average reconstruction error: 0.0002960268 \n",
      "Epoch [501 / 8000] average reconstruction error: 0.0001940131 \n",
      "Epoch [511 / 8000] average reconstruction error: 0.0001966746 \n",
      "Epoch [521 / 8000] average reconstruction error: 0.0001201190 \n",
      "Epoch [531 / 8000] average reconstruction error: 0.0001994092 \n",
      "Epoch [541 / 8000] average reconstruction error: 0.0001265132 \n",
      "Epoch [551 / 8000] average reconstruction error: 0.0001383623 \n",
      "Epoch [561 / 8000] average reconstruction error: 0.0001499526 \n",
      "Epoch [571 / 8000] average reconstruction error: 0.0001882332 \n",
      "Epoch [581 / 8000] average reconstruction error: 0.0001339734 \n",
      "Epoch [591 / 8000] average reconstruction error: 0.0001469334 \n",
      "Epoch [601 / 8000] average reconstruction error: 0.0003270012 \n",
      "Epoch [611 / 8000] average reconstruction error: 0.0001243649 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Documents\\rpoditela\\Intra\\autoencoder\\autoencoder.ipynb Celda 26\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/rpoditela/Intra/autoencoder/autoencoder.ipynb#X54sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m opt\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/rpoditela/Intra/autoencoder/autoencoder.ipynb#X54sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m total_loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/rpoditela/Intra/autoencoder/autoencoder.ipynb#X54sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m opt\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/rpoditela/Intra/autoencoder/autoencoder.ipynb#X54sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m#scheduler.step()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/rpoditela/Intra/autoencoder/autoencoder.ipynb#X54sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m train_loss_avg[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (total_loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\py_torc\\lib\\site-packages\\torch\\optim\\optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m     87\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\py_torc\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\py_torc\\lib\\site-packages\\torch\\optim\\adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[39m# record the step after step update\u001b[39;00m\n\u001b[0;32m    139\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> 141\u001b[0m     F\u001b[39m.\u001b[39;49madam(params_with_grad,\n\u001b[0;32m    142\u001b[0m            grads,\n\u001b[0;32m    143\u001b[0m            exp_avgs,\n\u001b[0;32m    144\u001b[0m            exp_avg_sqs,\n\u001b[0;32m    145\u001b[0m            max_exp_avg_sqs,\n\u001b[0;32m    146\u001b[0m            state_steps,\n\u001b[0;32m    147\u001b[0m            amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    148\u001b[0m            beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    149\u001b[0m            beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    150\u001b[0m            lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    151\u001b[0m            weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    152\u001b[0m            eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    153\u001b[0m            maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m    154\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\py_torc\\lib\\site-packages\\torch\\optim\\_functional.py:110\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    105\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39msqrt(bias_correction2))\u001b[39m.\u001b[39madd_(eps)\n\u001b[0;32m    109\u001b[0m step_size \u001b[39m=\u001b[39m lr \u001b[39m/\u001b[39m bias_correction1\n\u001b[1;32m--> 110\u001b[0m param\u001b[39m.\u001b[39;49maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49mstep_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "train_loss_avg = []\n",
    "lr_list = []\n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    train_loss_avg.append(0)\n",
    "   #batch es cada arbol del dataloader\n",
    "    for batch_idx, batch in enumerate(data_loader):\n",
    "        # Initialize torchfold for *encoding*\n",
    "\n",
    "        \n",
    "        enc_fold = torch_f.Fold(device)\n",
    "        enc_fold_nodes = []     # list of fold nodes for encoding, lista con la \"hoja de ruta\" de los dos arboles\n",
    "        # Collect computation nodes recursively from encoding process\n",
    "        n_nodes = []\n",
    "        for example in batch: #example es un arbolito\n",
    "            c = []\n",
    "            n = example.count_nodes(example, c)\n",
    "            n_nodes.append(len(n))\n",
    "            encode_structure_fold(enc_fold, example)\n",
    "            enc_fold_nodes.append(encode_structure_fold(enc_fold, example))\n",
    "       \n",
    "        # Apply the computations on the encoder model\n",
    "       \n",
    "        enc_fold_nodes = enc_fold.apply(Grassencoder, [enc_fold_nodes])\n",
    "        \n",
    "        \n",
    "        # Initialize torchfold for *decoding*\n",
    "        dec_fold = torch_f.Fold(device)\n",
    "        # Collect computation nodes recursively from decoding process\n",
    "        dec_fold_nodes = []\n",
    "        kld_fold_nodes = []\n",
    "\n",
    "        t_l = []\n",
    "        for f in enc_fold_nodes:\n",
    "            for t in f:\n",
    "                t_l.append(t)\n",
    "        for example, fnode in zip(batch, t_l): #example es el arbol y fnode el encodeado\n",
    "            #print(\"example\", example)\n",
    "            #print(\"fnode\", fnode) \n",
    "            #root_code, kl_div = torch.chunk(fnode, 2, 0)\n",
    "            dec_fold_nodes.append(decode_structure_fold_grass(dec_fold, fnode, example))\n",
    "        # Apply the computations on the decoder model\n",
    "\n",
    "                       \n",
    "        total_loss = dec_fold.apply(Grassdecoder, [dec_fold_nodes])#[0]\n",
    "        #print(\"total_loss\", total_loss)\n",
    "        n_nodes = torch.tensor(n_nodes, device = device)\n",
    "        #print(\"n\", n_nodes)\n",
    "        total_loss = torch.div(total_loss[0], n_nodes)\n",
    "        #print(\"div\", total_loss)\n",
    "        total_loss = total_loss.sum() / len(batch)  #n_nodes[0] #modificar y dividir por el promedio?\n",
    "        #total_loss = total_loss*10\n",
    "        \n",
    "        #print(\"total_loss\", total_loss)\n",
    "        \n",
    "        \n",
    "        opt.zero_grad()\n",
    "        total_loss.backward()\n",
    "        opt.step()\n",
    "        #scheduler.step()\n",
    "        train_loss_avg[-1] += (total_loss.item())\n",
    "        \n",
    "\n",
    "    wandb.log({'epoch': epoch+1, 'loss': total_loss})\n",
    "    save_best_model(\n",
    "        total_loss, epoch, Grassencoder, Grassdecoder, opt)\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch [%d / %d] average reconstruction error: %.10f ' % (epoch+1, epochs, total_loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5778\n"
     ]
    }
   ],
   "source": [
    "encoder = GRASSEncoder(input_size = 4, feature_size=512, hidden_size=1024).to(device)\n",
    "decoder = GRASSDecoder(latent_size=512, hidden_size=1024, mult = mult).to(device)\n",
    "\n",
    "checkpoint = torch.load(\"outputs/best_model.pth\")\n",
    "encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "print(\"epoch\", epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.5402e-08, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_best_model.best_valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing loss [tensor(4.1618e-08, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.8471e-06, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.2062e-06, device='cuda:0', grad_fn=<DivBackward0>), tensor(5.1889e-08, device='cuda:0', grad_fn=<DivBackward0>), tensor(8.2765e-07, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.2062e-06, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0267e-08, device='cuda:0', grad_fn=<DivBackward0>), tensor(5.1889e-08, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.9761e-07, device='cuda:0', grad_fn=<DivBackward0>), tensor(5.1889e-08, device='cuda:0', grad_fn=<DivBackward0>), tensor(6.4401e-07, device='cuda:0', grad_fn=<DivBackward0>), tensor(5.1889e-08, device='cuda:0', grad_fn=<DivBackward0>), tensor(5.1889e-08, device='cuda:0', grad_fn=<DivBackward0>), tensor(6.4401e-07, device='cuda:0', grad_fn=<DivBackward0>), tensor(5.1889e-08, device='cuda:0', grad_fn=<DivBackward0>), tensor(9.0917e-07, device='cuda:0', grad_fn=<DivBackward0>), tensor(7.1329e-07, device='cuda:0', grad_fn=<DivBackward0>), tensor(6.4401e-07, device='cuda:0', grad_fn=<DivBackward0>), tensor(5.1889e-08, device='cuda:0', grad_fn=<DivBackward0>), tensor(7.4012e-07, device='cuda:0', grad_fn=<DivBackward0>)]\n",
      "avg testing loss tensor(8.6073e-07, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loss_avg.append(0)\n",
    "loss = []\n",
    "for batch_idx, batch in enumerate(data_loader):\n",
    "\n",
    "    enc_fold_nodes = []\n",
    "    n_nodes = []\n",
    "    for example in batch:\n",
    "        c = []\n",
    "        n = example.count_nodes(example, c)\n",
    "        n_nodes.append(len(n))\n",
    "        enc_fold = encode_structure(example).to(device)\n",
    "        enc_fold_nodes.append(enc_fold)\n",
    "  \n",
    "    dec = []\n",
    "    for encoded, example in zip(enc_fold_nodes, batch):\n",
    "       dec.append(decode_testing_grass(encoded, example, 100, decoder))\n",
    "       t_l = []\n",
    "    for decoded in dec:\n",
    "        l = []\n",
    "        mse_loss_list = decoded.traverseInorderMSE(decoded, l)\n",
    "        #print(\"m list\", mse_loss_list)\n",
    "        \n",
    "        l = []\n",
    "        ce_loss_list = decoded.traverseInorderCE(decoded, l)\n",
    "        mse_loss_list = [m for m in mse_loss_list if m is not None]\n",
    "        ce_loss_list = [c for c in ce_loss_list if c is not None]\n",
    "        mse_loss = sum(mse_loss_list) \n",
    "        ce_loss  = sum(ce_loss_list)  \n",
    "        total_loss = (0.4*ce_loss + mse_loss)\n",
    "        #print(\"mse\", mse_loss)\n",
    "        t_l.append(total_loss)\n",
    "    \n",
    "    #print(\"total_loss\", t_l)\n",
    "    #print(len(t_l))\n",
    "    #print(len(n_nodes))\n",
    "    n_nodes = torch.tensor(n_nodes, device = device)\n",
    "    t_l = [torch.div(l, n) for l,  n in zip(t_l, n_nodes)]\n",
    "    #print(\"total_loss\", t_l)\n",
    "    #t_l = sum(t_l)/len(batch)\n",
    "    #print(\"total_loss\", t_l)\n",
    "    #print(\"////\")\n",
    "    loss += t_l\n",
    "print(\"testing loss\", loss)\n",
    "avg_testing_loss = sum(loss)/len(loss)\n",
    "#avg_testing_loss = loss.sum() / len(batch) \n",
    "print(\"avg testing loss\", avg_testing_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([[ 6.2779e-05, -2.5439e-04, -1.6417e-04,  1.4146e-04]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "total testing loss tensor(6.0412e-09, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = iter(data_loader).next()[0]\n",
    "enc_fold = torch_f.Fold(device)\n",
    "enc_fold_nodes = []\n",
    "enc_fold_nodes.append(encode_structure_fold(enc_fold, input))\n",
    "enc_fold_nodes = enc_fold.apply(encoder, [enc_fold_nodes])\n",
    "encoded = enc_fold_nodes[0]\n",
    "decoded = decode_testing_grass(encoded, input, 100, decoder)\n",
    "\n",
    "count = []\n",
    "numerar_nodos(decoded, count)\n",
    "decoded.traverseInorder(decoded)\n",
    "c = []\n",
    "n_nodes = len(input.count_nodes(input,c))\n",
    "\n",
    "l = []\n",
    "mse_loss_list = decoded.traverseInorderMSE(decoded, l)\n",
    "l = []\n",
    "ce_loss_list = decoded.traverseInorderCE(decoded, l)\n",
    "mse_loss_list = [m for m in mse_loss_list if m is not None]\n",
    "ce_loss_list = [c for c in ce_loss_list if c is not None]\n",
    "mse_loss = sum(mse_loss_list) \n",
    "ce_loss  = sum(ce_loss_list)  \n",
    "total_loss = (0.4*ce_loss + mse_loss)/n_nodes\n",
    "print(\"total testing loss\", total_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a974781616c49b0ab58c19a9174f564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(0.5, 0.5,"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotTree(input, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3751b830a0241c99856dd8c3734c9b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(0.2502063"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotTree(decoded, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = []\n",
    "n_nodes = input.count_nodes(input,c)\n",
    "len(n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = []\n",
    "n_nodes = decoded.count_nodes(decoded,c)\n",
    "len(n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0 4\n"
     ]
    }
   ],
   "source": [
    "li = []\n",
    "decoded.traverseInorderChilds(decoded, li)\n",
    "zero = [a for a in li if a == 0]\n",
    "one = [a for a in li if a == 1]\n",
    "two = [a for a in li if a == 2]\n",
    "qzero = len(zero)\n",
    "qOne = len(one)\n",
    "qtwo = len(two)\n",
    "print(qzero, qOne, qtwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0 4\n"
     ]
    }
   ],
   "source": [
    "li = []\n",
    "input.traverseInorderChilds(input, li)\n",
    "zero = [a for a in li if a == 0]\n",
    "one = [a for a in li if a == 1]\n",
    "two = [a for a in li if a == 2]\n",
    "qzero = len(zero)\n",
    "qOne = len(one)\n",
    "qtwo = len(two)\n",
    "print(qzero, qOne, qtwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (20,10))\n",
    "plt.plot(train_loss_avg) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverseleaf(root):\n",
    "    if root is not None:\n",
    "        traverseleaf(root.left)\n",
    "        if root.is_leaf():\n",
    "            print(root.radius)\n",
    "        traverseleaf(root.right)\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traversebif(root):\n",
    "    if root is not None:\n",
    "        traversebif(root.left)\n",
    "        if root.is_two_child():\n",
    "            print(root.radius)\n",
    "        traversebif(root.right)\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3076, 0.0895, 0.1057, 0.3334]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 2.1714e-04,  1.0490e-05, -2.0231e-05, -4.4443e-05]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.7619, 0.7292, 0.7403, 0.6714]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.3850, 0.3609, 0.3718, 0.3348]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "////\n",
      "tensor([0.3077, 0.0909, 0.1053, 0.3333], device='cuda:0')\n",
      "tensor([0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.7692, 0.7273, 0.7368, 0.6667], device='cuda:0')\n",
      "tensor([0.3846, 0.3636, 0.3684, 0.3333], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "traversebif(decoded)\n",
    "print(\"////\")\n",
    "traversebif(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6155, 0.1789, 0.2109, 0.6657]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.6909, 0.4516, 0.4784, 0.6652]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.9243, 0.2678, 0.3202, 1.0016]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.9976, 0.5389, 0.5869, 1.0000]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.8381, 0.9955, 1.0046, 0.6704]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "traverseleaf(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6154, 0.1818, 0.2105, 0.6667], device='cuda:0')\n",
      "tensor([0.6923, 0.4545, 0.4737, 0.6667], device='cuda:0')\n",
      "tensor([0.9231, 0.2727, 0.3158, 1.0000], device='cuda:0')\n",
      "tensor([1.0000, 0.5455, 0.5789, 1.0000], device='cuda:0')\n",
      "tensor([0.8462, 1.0000, 1.0000, 0.6667], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "traverseleaf(input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py_torc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f3e717cd274da89498094fde320e6eab1bf0f52911d27cf47473187acb3fe8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
