{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nTE9Wj7efv74"
   },
   "outputs": [],
   "source": [
    "from logging import raiseExceptions\n",
    "from tokenize import Double\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d58DYjvVhX87",
    "outputId": "af8fa1c5-a5f9-4cab-e206-db157698ef87"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/gdrive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgdrive/My Drive/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "%cd gdrive/My Drive/\n",
    "%cd intra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "c_kL7cYBhX58"
   },
   "outputs": [],
   "source": [
    "from vec3 import Vec3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqyohNmrk4WT"
   },
   "source": [
    "# **CLASE NODO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "o1JoaLMShX1s"
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    Class Node\n",
    "    \"\"\"\n",
    "    def __init__(self, value, radius, left = None, right = None, position = None, cl_prob= None):\n",
    "        self.left = left\n",
    "        self.data = value\n",
    "        self.radius = radius\n",
    "        self.position = position\n",
    "        self.right = right\n",
    "        self.prob = cl_prob\n",
    "        self.children = [self.left, self.right]\n",
    "    \n",
    "    def agregarHijo(self, children):\n",
    "\n",
    "        if self.right is None:\n",
    "            self.right = children\n",
    "        elif self.left is None:\n",
    "            self.left = children\n",
    "\n",
    "        else:\n",
    "            raise ValueError (\"solo arbol binario \")\n",
    "\n",
    "\n",
    "    def is_leaf(self):\n",
    "        if self.right is None:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def is_two_child(self):\n",
    "        if self.right is not None and self.left is not None:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def is_one_child(self):\n",
    "        if self.is_two_child():\n",
    "            return False\n",
    "        elif self.is_leaf():\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def childs(self):\n",
    "        if self.is_leaf():\n",
    "            return 0\n",
    "        if self.is_one_child():\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "    \n",
    "    \n",
    "    def traverseInorder(self, root):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            self.traverseInorder(root.left)\n",
    "            print (root.data, root.radius)\n",
    "            self.traverseInorder(root.right)\n",
    "\n",
    "    def traverseInorderLoss(self, root, loss):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            self.traverseInorderLoss(root.left, loss)\n",
    "            loss.append(root.prob)\n",
    "            self.traverseInorderLoss(root.right, loss)\n",
    "            return loss\n",
    "\n",
    "    def preorder(self, root):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            print (root.data, root.radius)\n",
    "            self.preorder(root.left)\n",
    "            self.preorder(root.right)\n",
    "\n",
    "    def cloneBinaryTree(self, root):\n",
    "     \n",
    "        # base case\n",
    "        if root is None:\n",
    "            return None\n",
    "    \n",
    "        # create a new node with the same data as the root node\n",
    "        root_copy = Node(root.data, root.radius)\n",
    "    \n",
    "        # clone the left and right subtree\n",
    "        root_copy.left = self.cloneBinaryTree(root.left)\n",
    "        root_copy.right = self.cloneBinaryTree(root.right)\n",
    "    \n",
    "        # return cloned root node\n",
    "        return root_copy\n",
    "\n",
    "    def height(self, root):\n",
    "    # Check if the binary tree is empty\n",
    "        if root is None:\n",
    "            return 0 \n",
    "        # Recursively call height of each node\n",
    "        leftAns = self.height(root.left)\n",
    "        rightAns = self.height(root.right)\n",
    "    \n",
    "        # Return max(leftHeight, rightHeight) at each iteration\n",
    "        return max(leftAns, rightAns) + 1\n",
    "\n",
    "    # Print nodes at a current level\n",
    "    def printCurrentLevel(self, root, level):\n",
    "        if root is None:\n",
    "            return\n",
    "        if level == 1:\n",
    "            print(root.data, end=\" \")\n",
    "        elif level > 1:\n",
    "            self.printCurrentLevel(root.left, level-1)\n",
    "            self.printCurrentLevel(root.right, level-1)\n",
    "\n",
    "    def printLevelOrder(self, root):\n",
    "        h = self.height(root)\n",
    "        for i in range(1, h+1):\n",
    "            self.printCurrentLevel(root, i)\n",
    "\n",
    "\n",
    "    \n",
    "    def count_nodes(self, root, counter):\n",
    "        if   root is not None:\n",
    "            self.count_nodes(root.left, counter)\n",
    "            counter.append(root.data)\n",
    "            self.count_nodes(root.right, counter)\n",
    "            return counter\n",
    "\n",
    "    \n",
    "    def serialize(self, root):\n",
    "        \n",
    "        def post_order(root):\n",
    "            if root:\n",
    "                post_order(root.left)\n",
    "                post_order(root.right)\n",
    "                ret[0] += str(root.data)+'_'+ str(root.radius) +';'\n",
    "                \n",
    "            else:\n",
    "                ret[0] += '#;'           \n",
    "\n",
    "        ret = ['']\n",
    "        post_order(root)\n",
    "        return ret[0][:-1]  # remove last ,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUsFzE1rlB94"
   },
   "source": [
    "# **Funciones extra**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Lgu0J3arlPlR"
   },
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ExpGqBASlE3M"
   },
   "outputs": [],
   "source": [
    "def traverse(root, tree):\n",
    "       \n",
    "        if root is not None:\n",
    "            traverse(root.left, tree)\n",
    "            tree.append((root.radius, root.data))\n",
    "            traverse(root.right, tree)\n",
    "            return tree\n",
    "\n",
    "def traverse_conexiones(root, tree):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            traverse_conexiones(root.left, tree)\n",
    "            if root.right is not None:\n",
    "                tree.append((root.data, root.right.data))\n",
    "            if root.left is not None:\n",
    "                tree.append((root.data, root.left.data))\n",
    "            traverse_conexiones(root.right, tree)\n",
    "            return tree\n",
    "def arbolAGrafo (nodoRaiz):\n",
    "    \n",
    "    conexiones = []\n",
    "    lineas = traverse_conexiones(nodoRaiz, conexiones)\n",
    "    tree = []\n",
    "    tree = traverse(nodoRaiz, tree)\n",
    "\n",
    "    vertices = []\n",
    "    verticesCrudos = []\n",
    "    for node in tree:\n",
    "        #breakpoint()\n",
    "        vertice = node[0][0][:3]\n",
    "        rad = node[0][0][-1]\n",
    "        num = node[1]\n",
    "        \n",
    "        #vertices.append((num, {'posicion': Vec3( vertice[0], vertice[1], vertice[2]), 'radio': rad} ))\n",
    "        vertices.append((len(verticesCrudos),{'posicion': Vec3( vertice[0], vertice[1], vertice[2]), 'radio': rad}))\n",
    "        verticesCrudos.append(vertice)\n",
    "\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from( vertices )\n",
    "    G.add_edges_from( lineas )\n",
    "    \n",
    "    a = nx.get_node_attributes(G, 'posicion')\n",
    "   \n",
    "    #for key in a.keys():\n",
    "    #    a[key] = a[key].toNumpy()[0:2]\n",
    "\n",
    "    #plt.figure(figsize=(20,10))\n",
    "    #nx.draw(G, pos = a, node_size = 150, with_labels = True)\n",
    "    #plt.show()\n",
    "    return G\n",
    "\n",
    "def createNode(data, radius, position = None, left = None, right = None, cl_prob = None):\n",
    "        \"\"\"\n",
    "        Utility function to create a node.\n",
    "        \"\"\"\n",
    "        return Node(data, radius, position, left, right, cl_prob)\n",
    " \n",
    "def deserialize(data):\n",
    "    if  not data:\n",
    "        return \n",
    "    nodes = data.split(';')  \n",
    "    #print(\"node\",nodes[3])\n",
    "    def post_order(nodes):\n",
    "                \n",
    "        if nodes[-1] == '#':\n",
    "            nodes.pop()\n",
    "            return None\n",
    "        node = nodes.pop().split('_')\n",
    "        data = int(node[0])\n",
    "        #radius = float(node[1])\n",
    "        #print(\"node\", node)\n",
    "        #breakpoint()\n",
    "        radius = node[1]\n",
    "        #print(\"radius\", radius)\n",
    "        rad = radius.split(\",\")\n",
    "        rad [0] = rad[0].replace('[','')\n",
    "        rad [3] = rad[3].replace(']','')\n",
    "        r = []\n",
    "        for value in rad:\n",
    "            r.append(float(value))\n",
    "        #r =[float(num) for num in radius if num.isdigit()]\n",
    "        r = torch.tensor(r, device=device)\n",
    "        #breakpoint()\n",
    "        root = createNode(data, r)\n",
    "        root.right = post_order(nodes)\n",
    "        root.left = post_order(nodes)\n",
    "        \n",
    "        return root    \n",
    "    return post_order(nodes)    \n",
    "\n",
    "\n",
    "def read_tree(filename):\n",
    "    with open('./trees/' +filename, \"r\") as f:\n",
    "        byte = f.read() \n",
    "        return byte\n",
    "\n",
    "def numerar_nodos(root, count):\n",
    "    if root is not None:\n",
    "        numerar_nodos(root.left, count)\n",
    "        root.data = len(count)\n",
    "        count.append(1)\n",
    "        numerar_nodos(root.right, count)\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0QHIIwzmH5d"
   },
   "source": [
    "# **Autoencoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbdjY-7VmMqx"
   },
   "source": [
    "# **Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0kZD5eV8mJwy"
   },
   "outputs": [],
   "source": [
    "class LeafEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LeafEncoder, self).__init__()\n",
    "        self.radius_feature = nn.Linear(4, 32)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, input):\n",
    "        rad = torch.tensor(input.radius)\n",
    "        rad = torch.reshape(rad, (1,4)).to(device)\n",
    "        radius = self.radius_feature(rad)\n",
    "        radius = self.tanh(radius)\n",
    "        feature = radius\n",
    "       \n",
    "        return feature\n",
    "\n",
    "class NonLeafEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NonLeafEncoder, self).__init__()\n",
    "        self.radius_feature = nn.Linear(4,32)\n",
    "        self.left = nn.Linear(32, 32)\n",
    "        self.right = nn.Linear(32, 32)\n",
    "        self.encoder = nn.Linear(64, 32)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, input, left_input, right_input):\n",
    "        \n",
    "        radius = self.radius_feature(torch.tensor(input.radius).reshape(1,4).to(device))\n",
    "        radius = self.tanh(radius)\n",
    "        context = self.right(right_input)\n",
    "        if left_input is not None:\n",
    "            context += self.left(left_input)\n",
    "        context = self.tanh(context)\n",
    "    \n",
    "        feature = torch.cat((radius,context), 1)\n",
    "        feature = self.encoder(feature)\n",
    "        feature = self.tanh(feature)\n",
    "\n",
    "\n",
    "        return feature\n",
    "\n",
    "leafenc = LeafEncoder()\n",
    "nonleafenc = NonLeafEncoder()\n",
    "leafenc = leafenc.to(device)\n",
    "nonleafenc = nonleafenc.to(device)\n",
    "def encode_structure_fold(root):\n",
    "\n",
    "    def encode_node(node):\n",
    "        \n",
    "        if node is None:\n",
    "            return\n",
    "        if node.is_leaf():\n",
    "            return leafenc(node)\n",
    "        else:\n",
    "            left = encode_node(node.left)\n",
    "            right = encode_node(node.right)\n",
    "            return nonleafenc(node, left, right)\n",
    "        \n",
    "    encoding = encode_node(root)\n",
    "    return encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPpw5YNpmXaR"
   },
   "source": [
    "# **Clasificador**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5swNmhUCmZgr"
   },
   "outputs": [],
   "source": [
    "class NodeClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NodeClassifier, self).__init__()\n",
    "        self.mlp1 = nn.Linear(32, 8)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.mlp2 = nn.Linear(8, 3)\n",
    "        \n",
    "    def forward(self, input_feature):\n",
    "        output = self.mlp1(input_feature)\n",
    "        output = self.tanh(output)\n",
    "        output = self.mlp2(output)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBUzGvKxmci4"
   },
   "source": [
    "# **Decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VbDLW63bmeIY"
   },
   "outputs": [],
   "source": [
    "class InternalDecoder(nn.Module):\n",
    "\n",
    "    \"\"\" Decode an input (parent) feature into a left-child and a right-child feature \"\"\"\n",
    "    def __init__(self):\n",
    "        super(InternalDecoder, self).__init__()\n",
    "        self.mlp = nn.Linear(32,16)\n",
    "        self.mlp_right = nn.Linear(16,32)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.mlp2 = nn.Linear(16,4)\n",
    "\n",
    "    def forward(self, parent_feature):\n",
    "        vector = self.mlp(parent_feature)\n",
    "        vector = self.tanh(vector)\n",
    "        right_feature = self.mlp_right(vector)\n",
    "        right_feature = self.tanh(right_feature)\n",
    "        rad_feature = self.mlp2(vector)\n",
    "\n",
    "        return right_feature, rad_feature\n",
    "\n",
    "class BifurcationDecoder(nn.Module):\n",
    "    \n",
    "    \"\"\" Decode an input (parent) feature into a left-child and a right-child feature \"\"\"\n",
    "    def __init__(self):\n",
    "        super(BifurcationDecoder, self).__init__()\n",
    "        self.mlp = nn.Linear(32,32)\n",
    "        self.mlp_left = nn.Linear(32,32)\n",
    "        self.mlp_right = nn.Linear(32,32)\n",
    "        self.mlp2 = nn.Linear(32,4)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, parent_feature):\n",
    "        vector = self.mlp(parent_feature)\n",
    "        vector = self.tanh(vector)\n",
    "        left_feature = self.mlp_left(vector)\n",
    "        left_feature = self.tanh(left_feature)\n",
    "        right_feature = self.mlp_right(vector)\n",
    "        right_feature = self.tanh(right_feature)\n",
    "        rad_feature = self.mlp2(vector)\n",
    "\n",
    "        return left_feature, right_feature, rad_feature\n",
    "\n",
    "class featureDecoder(nn.Module):\n",
    "    \n",
    "    \"\"\" Decode an input (parent) feature into a left-child and a right-child feature \"\"\"\n",
    "    def __init__(self):\n",
    "        super(featureDecoder, self).__init__()\n",
    "        self.mlp = nn.Linear(32,16)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.mlp2 = nn.Linear(16,4)\n",
    "\n",
    "    def forward(self, parent_feature):\n",
    "        vector = self.mlp(parent_feature)\n",
    "        vector = self.tanh(vector)\n",
    "        vector = self.mlp2(vector)\n",
    "\n",
    "        return vector\n",
    "\n",
    "featuredec = featureDecoder()\n",
    "featuredec=featuredec.to(device)\n",
    "bifdec = BifurcationDecoder()\n",
    "bifdec = bifdec.to(device)\n",
    "internaldec = InternalDecoder()\n",
    "internaldec=internaldec.to(device)\n",
    "nodeClassifier = NodeClassifier()\n",
    "nodeClassifier = nodeClassifier.to(device)\n",
    "\n",
    "def calcularLossEstructura(cl_p, original):\n",
    "    #breakpoint()\n",
    "    if original is None:\n",
    "        return 0\n",
    "    else:\n",
    "        if original.childs() == 0:\n",
    "            vector = [1, 0, 0]\n",
    "        if original.childs() == 1:\n",
    "            vector = [0, 1, 0]\n",
    "        if original.childs() == 2:\n",
    "            vector = [0, 0, 1]\n",
    "    \n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    l2 = nn.MSELoss()\n",
    "    #breakpoint()\n",
    "    return ce(cl_p, torch.tensor(vector, device=device, dtype = torch.float).reshape(1, 3))\n",
    "\n",
    "def calcularLossAtributo(nodo, radio):\n",
    "\n",
    "    if nodo is None:\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        radio = radio.reshape(4)\n",
    "        l2 = nn.MSELoss()\n",
    "        \n",
    "        return l2(nodo.radius, radio )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "pw9vFOfTmi2x"
   },
   "outputs": [],
   "source": [
    "def decode_structure_fold(v, root, weight):\n",
    "    def decode_node(v, node, weight):\n",
    "        cl = nodeClassifier(v)\n",
    "        _, label = torch.max(cl, 1)\n",
    "        label = label.data\n",
    "        #print(\"label\", label)\n",
    "        if label == 0 and createNode.count <= 1: ##output del classifier\n",
    "            lossEstructura = calcularLossEstructura(cl, node)\n",
    "            radio = featuredec(v)\n",
    "            lossAtrs = calcularLossAtributo( node, radio )\n",
    "            return createNode(1,radio, cl_prob = weight * (lossEstructura + lossAtrs))\n",
    "\n",
    "        elif label == 1 and createNode.count <= 1:\n",
    "            right, radius = internaldec(v)\n",
    "            lossEstructura = calcularLossEstructura(cl, node)\n",
    "            lossAtrs = calcularLossAtributo( node, radius )\n",
    "            d = createNode(1, radius, cl_prob = weight * (lossEstructura + lossAtrs ) )\n",
    "            count_level.append(\"1\")\n",
    "            \n",
    "            if not node is None:\n",
    "                if not node.right is None:\n",
    "                    nodoSiguiente = node.right\n",
    "                else:\n",
    "                    nodoSiguiente = None\n",
    "            else:\n",
    "                nodoSiguiente = None\n",
    "            d.right = decode_node(right, nodoSiguiente, 0.5*weight )\n",
    "            \n",
    "            return d\n",
    "        elif label == 2 and createNode.count <= 1:\n",
    "            left, right, radius = bifdec(v)\n",
    "            lossEstructura = calcularLossEstructura(cl, node)\n",
    "            lossAtrs = calcularLossAtributo( node, radius )\n",
    "            d = createNode(1, radius, cl_prob = weight * (lossEstructura + lossAtrs ))\n",
    "            count_level.append(\"1\")\n",
    "            \n",
    "\n",
    "            if not node is None:\n",
    "                if not node.right is None:\n",
    "                    nodoSiguienteRight = node.right\n",
    "                else:\n",
    "                    nodoSiguienteRight = None\n",
    "\n",
    "                if not node.left is None:\n",
    "                    nodoSiguienteLeft = node.left\n",
    "                else:\n",
    "                    nodoSiguienteLeft = None\n",
    "            else:\n",
    "                nodoSiguienteRight = None\n",
    "                nodoSiguienteLeft = None\n",
    "\n",
    "            d.right = decode_node(right, nodoSiguienteRight, 0.5*weight)\n",
    "            d.left = decode_node(left, nodoSiguienteLeft, 0.5*weight )\n",
    "           \n",
    "            return d\n",
    "        \n",
    "    count_level = []\n",
    "    createNode.count = 0\n",
    "    dec = decode_node(v,  root, weight)\n",
    "    return dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCklujwtxNQJ"
   },
   "source": [
    "# **Dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jkIduoUrxPx4"
   },
   "outputs": [],
   "source": [
    "t_list = ['test6.dat']\n",
    "class tDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.names = t_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = t_list[idx]\n",
    "        string = read_tree(file)\n",
    "        return string\n",
    "\n",
    "dataset = tDataset()\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "id": "89WSVB5KxSuA",
    "outputId": "b8ca01ea-5ac8-411f-bcd4-6c8ef66fd692"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded tensor([[-0.7696, -0.0148,  0.5258, -0.1674, -0.4627, -0.4371,  0.4245,  0.5646,\n",
      "          0.0819, -0.6760,  0.5085,  0.4686, -0.0990,  0.1922, -0.3643, -0.4461,\n",
      "         -0.5381,  0.4247,  0.1966,  0.5814,  0.3609,  0.3262,  0.5903, -0.1660,\n",
      "         -0.1747,  0.1810, -0.3856,  0.1509,  0.5983, -0.3264, -0.1340, -0.3280]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n"
     ]
    },
    {
     "ename": "RecursionError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-c4079467e17d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-c4079467e17d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_fold_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_structure_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_fold_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mloss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraverseInorderLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-b632474196a1>\u001b[0m in \u001b[0;36mdecode_structure_fold\u001b[0;34m(v, root, weight)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mcount_level\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mcreateNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mdec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-b632474196a1>\u001b[0m in \u001b[0;36mdecode_node\u001b[0;34m(v, node, weight)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mnodoSiguiente\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodoSiguiente\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-b632474196a1>\u001b[0m in \u001b[0;36mdecode_node\u001b[0;34m(v, node, weight)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mnodoSiguiente\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodoSiguiente\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "... last 2 frames repeated, from the frame below ...\n",
      "\u001b[0;32m<ipython-input-24-b632474196a1>\u001b[0m in \u001b[0;36mdecode_node\u001b[0;34m(v, node, weight)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mnodoSiguiente\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodoSiguiente\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    epochs = 1000\n",
    "\n",
    "    learning_rate = 1e-3\n",
    "\n",
    "    leaf_encoder_opt = torch.optim.Adam(leafenc.parameters(), lr=learning_rate)\n",
    "    non_leaf_encoder_opt = torch.optim.Adam(nonleafenc.parameters(), lr=learning_rate)\n",
    "    class_opt = torch.optim.Adam(nodeClassifier.parameters(), lr=learning_rate)\n",
    "\n",
    "    feature_decoder_opt = torch.optim.Adam(featuredec.parameters(), lr=learning_rate)\n",
    "    bifurcation_decoder_opt = torch.optim.Adam(bifdec.parameters(), lr=learning_rate)\n",
    "    internal_decoder_opt = torch.optim.Adam(internaldec.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_loss_avg = []\n",
    "    ce_avg = []\n",
    "    mse_avg = []\n",
    "    l1_avg = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss_avg.append(0)\n",
    "        ce_avg.append(0)\n",
    "        mse_avg.append(0)\n",
    "        l1_avg.append(0)\n",
    "        weight = 1\n",
    "        for data in data_loader:\n",
    "            \n",
    "            d_data = deserialize(data[0])\n",
    "\n",
    "\n",
    "            enc_fold_nodes = encode_structure_fold(d_data).to(device)\n",
    "            \n",
    "            print(\"encoded\", enc_fold_nodes)\n",
    "            \n",
    "            decoded = decode_structure_fold(enc_fold_nodes, d_data, weight)\n",
    "            l = []\n",
    "            loss_list = decoded.traverseInorderLoss(decoded, l)\n",
    "            #breakpoint()\n",
    "            total_loss = sum(loss_list)\n",
    "            if total_loss < 0:\n",
    "                breakpoint()\n",
    "            \n",
    "            # Do parameter optimization\n",
    "            leaf_encoder_opt.zero_grad()\n",
    "            non_leaf_encoder_opt.zero_grad()\n",
    "            feature_decoder_opt.zero_grad()\n",
    "            bifurcation_decoder_opt.zero_grad()\n",
    "            internal_decoder_opt.zero_grad()\n",
    "            class_opt.zero_grad()\n",
    "\n",
    "            total_loss.backward()\n",
    "\n",
    "            leaf_encoder_opt.step()\n",
    "            non_leaf_encoder_opt.step()\n",
    "            feature_decoder_opt.step()\n",
    "            bifurcation_decoder_opt.step()\n",
    "            class_opt.step()\n",
    "            internal_decoder_opt.step()\n",
    "\n",
    "            train_loss_avg[-1] += total_loss\n",
    "            #ce_avg [-1] += ce\n",
    "            #mse_avg [-1] +=mse\n",
    "            #l1_avg [-1] +=multiplicador\n",
    "\n",
    "        if epoch % 1 == 0:\n",
    "            print('Epoch [%d / %d] average reconstruction error: %f  ' % (epoch+1, epochs, train_loss_avg[-1]))\n",
    "\n",
    "    #print(decoded_copy2.height(decoded_copy2))\n",
    "    #decoded_copy2.traverseInorder(decoded_copy2)\n",
    "    #copy = decoded_copy2.cloneWithoutZero(decoded_copy2) ## para cuando quedan nodos vacios en el arbol decodeado, no deberia pasar si esta bien entrenado\n",
    "    #print(out_n_nodes)\n",
    "    \n",
    "    input = deserialize(iter(data_loader).next()[0])\n",
    "    print(input)\n",
    "    input.traverseInorder(input)\n",
    "    encoded = encode_structure_fold(input).to(device)\n",
    "    print(\"encoded\", enc_fold_nodes)\n",
    "    decoded = decode_structure_fold(encoded, d_data, 1)\n",
    "    count = []\n",
    "    numerar_nodos(decoded, count)\n",
    "    decoded.traverseInorder(decoded)\n",
    "    G = arbolAGrafo (decoded)\n",
    "    plt.figure()\n",
    "    nx.draw(G, node_size = 150, with_labels = True)\n",
    "    plt.show()\n",
    "\n",
    "    breakpoint()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qQ7cVszO1ofw",
    "outputId": "ec697a41-658b-4a89-972a-52d5a67bfa09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.getrecursionlimit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "m6SQ8XO11tBQ"
   },
   "outputs": [],
   "source": [
    "sys.setrecursionlimit(1500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apjhzal31txo",
    "outputId": "17a46a66-117f-429f-a376-739de18626e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    }
   ],
   "source": [
    "print(sys.getrecursionlimit())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
