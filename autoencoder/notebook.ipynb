{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import raiseExceptions\n",
    "from tokenize import Double\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "from vec3 import Vec3\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(125)\n",
    "import random\n",
    "random.seed(125)\n",
    "use_gpu = True\n",
    "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_fn(f):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        wrapper.count += 1\n",
    "        return f(*args, **kwargs)\n",
    "    wrapper.count = 0\n",
    "    return wrapper\n",
    "\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    Class Node\n",
    "    \"\"\"\n",
    "    def __init__(self, value, radius, left = None, right = None, position = None, cl_prob= None, ce = None, mse = None):\n",
    "        self.left = left\n",
    "        self.data = value\n",
    "        self.radius = radius\n",
    "        self.position = position\n",
    "        self.right = right\n",
    "        self.prob = cl_prob\n",
    "        self.mse = mse\n",
    "        self.ce = ce\n",
    "        self.children = [self.left, self.right]\n",
    "    \n",
    "    def agregarHijo(self, children):\n",
    "\n",
    "        if self.right is None:\n",
    "            self.right = children\n",
    "        elif self.left is None:\n",
    "            self.left = children\n",
    "\n",
    "        else:\n",
    "            raise ValueError (\"solo arbol binario \")\n",
    "\n",
    "\n",
    "    def is_leaf(self):\n",
    "        if self.right is None:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def is_two_child(self):\n",
    "        if self.right is not None and self.left is not None:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def is_one_child(self):\n",
    "        if self.is_two_child():\n",
    "            return False\n",
    "        elif self.is_leaf():\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def childs(self):\n",
    "        if self.is_leaf():\n",
    "            return 0\n",
    "        if self.is_one_child():\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "    \n",
    "    \n",
    "    def traverseInorder(self, root):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            self.traverseInorder(root.left)\n",
    "            print (root.data, root.radius)\n",
    "            self.traverseInorder(root.right)\n",
    "\n",
    "    def traverseInorderLoss(self, root, loss):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            self.traverseInorderLoss(root.left, loss)\n",
    "            loss.append(root.prob)\n",
    "            self.traverseInorderLoss(root.right, loss)\n",
    "            return loss\n",
    "\n",
    "    def traverseInorderMSE(self, root, loss):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            self.traverseInorderMSE(root.left, loss)\n",
    "            loss.append(root.mse)\n",
    "            self.traverseInorderMSE(root.right, loss)\n",
    "            return loss\n",
    "\n",
    "    def traverseInorderCE(self, root, loss):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            self.traverseInorderCE(root.left, loss)\n",
    "            loss.append(root.ce)\n",
    "            self.traverseInorderCE(root.right, loss)\n",
    "            return loss\n",
    "\n",
    "    def traverseInorderChilds(self, root, l):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            self.traverseInorderChilds(root.left, l)\n",
    "            l.append(root.childs())\n",
    "            self.traverseInorderChilds(root.right, l)\n",
    "            return l\n",
    "\n",
    "    def preorder(self, root):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            print (root.data, root.radius)\n",
    "            self.preorder(root.left)\n",
    "            self.preorder(root.right)\n",
    "\n",
    "    def cloneBinaryTree(self, root):\n",
    "     \n",
    "        # base case\n",
    "        if root is None:\n",
    "            return None\n",
    "    \n",
    "        # create a new node with the same data as the root node\n",
    "        root_copy = Node(root.data, root.radius)\n",
    "    \n",
    "        # clone the left and right subtree\n",
    "        root_copy.left = self.cloneBinaryTree(root.left)\n",
    "        root_copy.right = self.cloneBinaryTree(root.right)\n",
    "    \n",
    "        # return cloned root node\n",
    "        return root_copy\n",
    "\n",
    "    def height(self, root):\n",
    "    # Check if the binary tree is empty\n",
    "        if root is None:\n",
    "            return 0 \n",
    "        # Recursively call height of each node\n",
    "        leftAns = self.height(root.left)\n",
    "        rightAns = self.height(root.right)\n",
    "    \n",
    "        # Return max(leftHeight, rightHeight) at each iteration\n",
    "        return max(leftAns, rightAns) + 1\n",
    "\n",
    "    # Print nodes at a current level\n",
    "    def printCurrentLevel(self, root, level):\n",
    "        if root is None:\n",
    "            return\n",
    "        if level == 1:\n",
    "            print(root.data, end=\" \")\n",
    "        elif level > 1:\n",
    "            self.printCurrentLevel(root.left, level-1)\n",
    "            self.printCurrentLevel(root.right, level-1)\n",
    "\n",
    "    def printLevelOrder(self, root):\n",
    "        h = self.height(root)\n",
    "        for i in range(1, h+1):\n",
    "            self.printCurrentLevel(root, i)\n",
    "\n",
    "\n",
    "    \n",
    "    def count_nodes(self, root, counter):\n",
    "        if   root is not None:\n",
    "            self.count_nodes(root.left, counter)\n",
    "            counter.append(root.data)\n",
    "            self.count_nodes(root.right, counter)\n",
    "            return counter\n",
    "\n",
    "    \n",
    "    def serialize(self, root):\n",
    "        def post_order(root):\n",
    "            if root:\n",
    "                post_order(root.left)\n",
    "                post_order(root.right)\n",
    "                ret[0] += str(root.data)+'_'+ str(root.radius) +';'\n",
    "                \n",
    "            else:\n",
    "                ret[0] += '#;'           \n",
    "\n",
    "        ret = ['']\n",
    "        post_order(root)\n",
    "        return ret[0][:-1]  # remove last ,\n",
    "\n",
    "    def search(self, node, data):\n",
    "        \"\"\"\n",
    "        Search function will search a node into tree.\n",
    "        \"\"\"\n",
    "        # if root is None or root is the search data.\n",
    "        if node is None or node.data == data:\n",
    "            return node\n",
    "        if node.data < data:\n",
    "            return self.search(node.right, data)\n",
    "        else:\n",
    "            return self.search(node.left, data)\n",
    "\n",
    "    def toGraph( self, graph, index, dec, proc=True):\n",
    "        \n",
    "        radius = self.radius.cpu().detach().numpy()\n",
    "        if dec:\n",
    "            radius= radius[0]\n",
    "        print(\"radius\", radius)\n",
    "        graph.add_nodes_from( [ (index, {'posicion': radius[0:3], 'radio': radius[3] } ) ])\n",
    "\n",
    "        if self.right is not None:\n",
    "            leftIndex = self.right.toGraph( graph, index + 1, dec)\n",
    "\n",
    "            graph.add_edge( index, index + 1 )\n",
    "            if proc:\n",
    "                nx.set_edge_attributes( graph, {(index, index+1) : {'procesada':False}})\n",
    "        \n",
    "            if self.left is not None:\n",
    "                retIndex = self.left.toGraph( graph, leftIndex, dec )\n",
    "\n",
    "                graph.add_edge( index, leftIndex)\n",
    "                if proc:\n",
    "                    nx.set_edge_attributes( graph, {(index, leftIndex) : {'procesada':False}})\n",
    "            \n",
    "            else:\n",
    "               return leftIndex\n",
    "\n",
    "        else:\n",
    "            return index + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse(root, tree):\n",
    "       \n",
    "        if root is not None:\n",
    "            traverse(root.left, tree)\n",
    "            tree.append((root.radius, root.data))\n",
    "            traverse(root.right, tree)\n",
    "            return tree\n",
    "\n",
    "def traverse_2(tree1, tree2, t_l):\n",
    "       \n",
    "        if tree1 is not None:\n",
    "            traverse_2(tree1.left, tree2.left, t_l)\n",
    "            if tree2:\n",
    "                t_l.append((tree1.radius, tree2.radius))\n",
    "                print((tree1.radius, tree2.radius))\n",
    "            else:\n",
    "                t_l.append(tree1.radius)\n",
    "                print((tree1.radius))\n",
    "            traverse_2(tree1.right, tree2, t_l)\n",
    "            return t_l\n",
    "            \n",
    "\n",
    "def traverse_conexiones(root, tree):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            traverse_conexiones(root.left, tree)\n",
    "            if root.right is not None:\n",
    "                tree.append((root.data, root.right.data))\n",
    "            if root.left is not None:\n",
    "                tree.append((root.data, root.left.data))\n",
    "            traverse_conexiones(root.right, tree)\n",
    "            return tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "@count_fn\n",
    "def createNode(data, radius, position = None, left = None, right = None, cl_prob = None, ce = None, mse=None):\n",
    "        \"\"\"\n",
    "        Utility function to create a node.\n",
    "        \"\"\"\n",
    "        return Node(data, radius, position, left, right, cl_prob, ce, mse)\n",
    " \n",
    "def deserialize(data):\n",
    "    if  not data:\n",
    "        return \n",
    "    nodes = data.split(';')  \n",
    "    #print(\"node\",nodes[3])\n",
    "    def post_order(nodes):\n",
    "                \n",
    "        if nodes[-1] == '#':\n",
    "            nodes.pop()\n",
    "            return None\n",
    "        node = nodes.pop().split('_')\n",
    "        data = int(node[0])\n",
    "        #radius = float(node[1])\n",
    "        #print(\"node\", node)\n",
    "        #breakpoint()\n",
    "        radius = node[1]\n",
    "        #print(\"radius\", radius)\n",
    "        rad = radius.split(\",\")\n",
    "        rad [0] = rad[0].replace('[','')\n",
    "        rad [3] = rad[3].replace(']','')\n",
    "        r = []\n",
    "        for value in rad:\n",
    "            r.append(float(value))\n",
    "        #r =[float(num) for num in radius if num.isdigit()]\n",
    "        r = torch.tensor(r, device=device)\n",
    "        #breakpoint()\n",
    "        root = createNode(data, r)\n",
    "        root.right = post_order(nodes)\n",
    "        root.left = post_order(nodes)\n",
    "        \n",
    "        return root    \n",
    "    return post_order(nodes)    \n",
    "\n",
    "\n",
    "def read_tree(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        byte = f.read() \n",
    "        return byte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ENCODER\n",
    "class LeafEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LeafEncoder, self).__init__()\n",
    "        self.l1 = nn.Linear(4, 32)\n",
    "        self.l2 = nn.Linear(32, 32)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, input):\n",
    "        rad = torch.tensor(input.radius)\n",
    "        rad = torch.reshape(rad, (1,4)).to(device)\n",
    "        radius = self.l1(rad)\n",
    "        radius = self.tanh(radius)\n",
    "        radius = self.l2(radius)\n",
    "        radius = self.tanh(radius)\n",
    "        \n",
    "        return radius\n",
    "\n",
    "class NonLeafEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NonLeafEncoder, self).__init__()\n",
    "        self.l1 = nn.Linear(4,16)\n",
    "        self.l2 = nn.Linear(16,32)\n",
    "\n",
    "        self.left = nn.Linear(32,32)\n",
    "        self.right = nn.Linear(32,32)\n",
    "        \n",
    "        self.encoder = nn.Linear(64, 32)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, input, left_input, right_input):\n",
    "        \n",
    "        radius = self.l1(torch.tensor(input.radius).reshape(1,4).to(device))\n",
    "        radius = self.tanh(radius)\n",
    "        radius = self.l2(radius)\n",
    "        radius = self.tanh(radius)\n",
    "        context = self.right(right_input)\n",
    "        if left_input is not None:\n",
    "            context += self.left(left_input)\n",
    "        context = self.tanh(context)\n",
    "    \n",
    "        feature = torch.cat((radius,context), 1)\n",
    "        feature = self.encoder(feature)\n",
    "        feature = self.tanh(feature)\n",
    "\n",
    "\n",
    "        return feature\n",
    "\n",
    "leafenc = LeafEncoder()\n",
    "nonleafenc = NonLeafEncoder()\n",
    "leafenc = leafenc.to(device)\n",
    "nonleafenc = nonleafenc.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_structure_fold(root):\n",
    "    \n",
    "    def encode_node(node):\n",
    "        \n",
    "        if node is None:\n",
    "            return\n",
    "        if node.is_leaf():\n",
    "            return leafenc(node)\n",
    "        else:\n",
    "            left = encode_node(node.left)\n",
    "            right = encode_node(node.right)\n",
    "            return nonleafenc(node, left, right)\n",
    "        \n",
    "    encoding = encode_node(root)\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NodeClassifier, self).__init__()\n",
    "        self.mlp1 = nn.Linear(32, 16)\n",
    "        self.tanh = nn.LeakyReLU()\n",
    "        self.mlp2 = nn.Linear(16, 8)\n",
    "\n",
    "        self.tanh2 = nn.LeakyReLU()\n",
    "        self.mlp3 = nn.Linear(8, 3)\n",
    "\n",
    "    def forward(self, input_feature):\n",
    "        output = self.mlp1(input_feature)\n",
    "        output = self.tanh(output)\n",
    "        output = self.mlp2(output)\n",
    "\n",
    "        output = self.tanh2(output)\n",
    "        output = self.mlp3(output)\n",
    "        \n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InternalDecoder(nn.Module):\n",
    "\n",
    "    \"\"\" Decode an input (parent) feature into a left-child and a right-child feature \"\"\"\n",
    "    def __init__(self):\n",
    "        super(InternalDecoder, self).__init__()\n",
    "        self.mlp = nn.Linear(32, 32)\n",
    "        self.lp2 = nn.Linear(32, 32)\n",
    "        self.mlp_right = nn.Linear(32, 32)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.mlp2 = nn.Linear(32,4)\n",
    "\n",
    "    def forward(self, parent_feature):\n",
    "        \n",
    "        vector = self.mlp(parent_feature)\n",
    "        vector = self.tanh(vector)\n",
    "        vector = self.lp2(vector)\n",
    "        vector = self.tanh(vector)\n",
    "        right_feature = self.mlp_right(vector)\n",
    "        right_feature = self.tanh(right_feature)\n",
    "        rad_feature = self.mlp2(vector)\n",
    "\n",
    "        return right_feature, rad_feature\n",
    "\n",
    "class BifurcationDecoder(nn.Module):\n",
    "    \n",
    "    \"\"\" Decode an input (parent) feature into a left-child and a right-child feature \"\"\"\n",
    "    def __init__(self):\n",
    "        super(BifurcationDecoder, self).__init__()\n",
    "        self.mlp = nn.Linear(32,32)\n",
    "        self.lp2 = nn.Linear(32,32)\n",
    "        self.mlp_left = nn.Linear(32,32)\n",
    "        self.mlp_right = nn.Linear(32,32)\n",
    "        self.mlp2 = nn.Linear(32,4)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, parent_feature):\n",
    "        vector = self.mlp(parent_feature)\n",
    "        vector = self.tanh(vector)\n",
    "        vector = self.lp2(vector)\n",
    "        vector = self.tanh(vector)\n",
    "        left_feature = self.mlp_left(vector)\n",
    "        left_feature = self.tanh(left_feature)\n",
    "        right_feature = self.mlp_right(vector)\n",
    "        right_feature = self.tanh(right_feature)\n",
    "        rad_feature = self.mlp2(vector)\n",
    "\n",
    "        return left_feature, right_feature, rad_feature\n",
    "\n",
    "\n",
    "\n",
    "class featureDecoder(nn.Module):\n",
    "    \n",
    "    \"\"\" Decode an input (parent) feature into a left-child and a right-child feature \"\"\"\n",
    "    def __init__(self):\n",
    "        super(featureDecoder, self).__init__()\n",
    "        self.mlp = nn.Linear(32,32)\n",
    "        self.mlp2 = nn.Linear(32,32)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.mlp3 = nn.Linear(32,4)\n",
    "\n",
    "    def forward(self, parent_feature):\n",
    "        vector = self.mlp(parent_feature)\n",
    "        vector = self.tanh(vector)\n",
    "        vector = self.mlp2(vector)\n",
    "        vector = self.tanh(vector)\n",
    "        vector = self.mlp3(vector)\n",
    "       \n",
    "        return vector\n",
    "\n",
    "featuredec = featureDecoder()\n",
    "featuredec=featuredec.to(device)\n",
    "bifdec = BifurcationDecoder()\n",
    "bifdec = bifdec.to(device)\n",
    "internaldec = InternalDecoder()\n",
    "internaldec=internaldec.to(device)\n",
    "nodeClassifier = NodeClassifier()\n",
    "nodeClassifier = nodeClassifier.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcularLossEstructura(cl_p, original):\n",
    "    mult = torch.tensor([1/3.,1/56,1/2.], device = device)#1-7\n",
    "    #mult = torch.tensor([1/3.,1/16,1/2.], device = device)#1-2\n",
    "    ce = nn.CrossEntropyLoss(weight=mult)\n",
    "\n",
    "    \n",
    "    if original.childs() == 0:\n",
    "        vector = [1, 0, 0] \n",
    "    if original.childs() == 1:\n",
    "        vector = [0, 1, 0]\n",
    "    if original.childs() == 2:\n",
    "        vector = [0, 0, 1] \n",
    "\n",
    "    #mult = torch.tensor([1/3.,1/58,1/2.], device = device)#1-0\n",
    "    #mult = torch.tensor([1/4.,1/72,1/3.], device = device)#19-2\n",
    "    #mult = torch.tensor([1/2.,1/60,1/1.], device = device)#b1-0\n",
    "\n",
    "    c = ce(cl_p, torch.tensor(vector, device=device, dtype = torch.float).reshape(1, 3))\n",
    "    return c\n",
    "\n",
    "\n",
    "def calcularLossAtributo(nodo, radio):\n",
    "    \n",
    "    radio = radio.reshape(4)\n",
    "    l2    = nn.MSELoss(reduction = 'mean')\n",
    "   \n",
    "    mse = l2(radio, nodo.radius)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_structure_fold(v, root, max_nodes = 200, max_depth = 100):\n",
    "\n",
    "    def decode_node(v, node, max_nodes, max_depth, level = 0):\n",
    "        cl = nodeClassifier(v)\n",
    "        _, label = torch.max(cl, 1)\n",
    "        label = label.data\n",
    "\n",
    "        \n",
    "        if node.childs() == 0 and createNode.count <= max_nodes: ##output del classifier\n",
    "            lossEstructura = calcularLossEstructura(cl, node)\n",
    "            radio = featuredec(v)\n",
    "            lossAtrs = calcularLossAtributo( node, radio )\n",
    "            nd = createNode(1,radio, ce = lossEstructura,  mse = lossAtrs)\n",
    "            return nd\n",
    "\n",
    "        elif node.childs() == 1 and createNode.count <= max_nodes:\n",
    "            right, radius = internaldec(v)\n",
    "            lossEstructura = calcularLossEstructura(cl, node)\n",
    "            lossAtrs = calcularLossAtributo( node, radius )\n",
    "            nd = createNode(1, radius, cl_prob = lossAtrs , ce = lossEstructura, mse = lossAtrs) \n",
    "            \n",
    "            nodoSiguiente = node.right\n",
    "            #if not node is None:\n",
    "            #    if not node.right is None:\n",
    "            #        nodoSiguiente = node.right\n",
    "            #    else:\n",
    "            #        print(\"aca\")\n",
    "            #        nodoSiguiente = None\n",
    "            #else:\n",
    "            #    nodoSiguiente = None\n",
    "            \n",
    "            if nodoSiguiente is not None:\n",
    "                nd.right = decode_node(right, nodoSiguiente, max_nodes, max_depth, level=level+1)\n",
    "                level=level-1\n",
    "            return nd\n",
    "\n",
    "        elif node.childs() == 2 and createNode.count <= max_nodes:\n",
    "            left, right, radius = bifdec(v)\n",
    "            lossEstructura = calcularLossEstructura(cl, node)\n",
    "            lossAtrs = calcularLossAtributo( node, radius )\n",
    "            nd = createNode(1, radius, cl_prob = lossAtrs, ce = lossEstructura, mse = lossAtrs)\n",
    "            \n",
    "            nodoSiguienteRight = node.right\n",
    "            nodoSiguienteLeft = node.left\n",
    "            if nodoSiguienteRight is not None:\n",
    "                nd.right = decode_node(right, nodoSiguienteRight, max_nodes, max_depth, level=level+1)\n",
    "                level=level-1\n",
    "            if nodoSiguienteLeft is not None:\n",
    "                nd.left  = decode_node(left, nodoSiguienteLeft, max_nodes, max_depth, level=level+1)\n",
    "                level=level-1\n",
    "            return nd\n",
    "            \n",
    "    createNode.count = 0\n",
    "    dec = decode_node (v, root, max_nodes, max_depth, level=0)\n",
    "    return dec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traversefeatures(root, features):\n",
    "       \n",
    "    if root is not None:\n",
    "        traversefeatures(root.left, features)\n",
    "        features.append(root.radius)\n",
    "        traversefeatures(root.right, features)\n",
    "        return features\n",
    "\n",
    "def numerar_nodos(root, count):\n",
    "    if root is not None:\n",
    "        numerar_nodos(root.left, count)\n",
    "        root.data = len(count)\n",
    "        count.append(1)\n",
    "        numerar_nodos(root.right, count)\n",
    "        return \n",
    "\n",
    "\n",
    "def norm(root, minx, miny, minz, minr, maxx, maxy, maxz, maxr):\n",
    "    \n",
    "    if root is not None:\n",
    "        mx = minx.clone().detach()\n",
    "        my = miny.clone().detach()\n",
    "        mz = minz.clone().detach()\n",
    "        mr = minr.clone().detach()\n",
    "        Mx = maxx.clone().detach()\n",
    "        My = maxy.clone().detach()\n",
    "        Mz = maxz.clone().detach()\n",
    "        Mr = maxr.clone().detach()\n",
    "\n",
    "        root.radius[0] = (root.radius[0] - minx)/(maxx - minx)\n",
    "        root.radius[1] = (root.radius[1] - miny)/(maxy - miny)\n",
    "        root.radius[2] = (root.radius[2] - minz)/(maxz - minz)\n",
    "        root.radius[3] = (root.radius[3] - minr)/(maxr - minr)\n",
    "        \n",
    "        norm(root.left, mx, my, mz, mr, Mx, My, Mz, Mr)\n",
    "        norm(root.right, mx, my, mz, mr, Mx, My, Mz, Mr)\n",
    "        return \n",
    "\n",
    "def normalize_features(root):\n",
    "    features = []\n",
    "    features = traversefeatures(root, features)\n",
    "    \n",
    "    x = [tensor[0] for tensor in features]\n",
    "    y = [tensor[1] for tensor in features]\n",
    "    z = [tensor[2] for tensor in features]\n",
    "    r = [tensor[3] for tensor in features]\n",
    " \n",
    "    norm(root, min(x), min(y), min(z), min(r), max(x), max(y), max(z), max(r))\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_list = ['ArteryObjAN1-2.dat']\n",
    "class tDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.names = t_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = t_list[idx]\n",
    "        string = read_tree(\"./trees/\"+file)\n",
    "        return string\n",
    "\n",
    "dataset = tDataset()\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_4160\\2448251074.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rad = torch.tensor(input.radius)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_4160\\2448251074.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  radius = self.l1(torch.tensor(input.radius).reshape(1,4).to(device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 1200] average reconstruction error: 0.012574 mse: 0.022759, ce: 0.010298, lr: 0.000000\n",
      "Epoch [11 / 1200] average reconstruction error: 0.015657 mse: 0.023906, ce: 0.013266, lr: 0.000000\n",
      "Epoch [21 / 1200] average reconstruction error: 0.012953 mse: 0.022738, ce: 0.010679, lr: 0.000000\n",
      "Epoch [31 / 1200] average reconstruction error: 0.012020 mse: 0.022664, ce: 0.009754, lr: 0.000000\n",
      "Epoch [41 / 1200] average reconstruction error: 0.011840 mse: 0.022612, ce: 0.009578, lr: 0.000000\n",
      "Epoch [51 / 1200] average reconstruction error: 0.011576 mse: 0.022460, ce: 0.009330, lr: 0.000000\n",
      "Epoch [61 / 1200] average reconstruction error: 0.011292 mse: 0.022258, ce: 0.009066, lr: 0.000000\n",
      "Epoch [71 / 1200] average reconstruction error: 0.011097 mse: 0.022146, ce: 0.008882, lr: 0.000000\n",
      "Epoch [81 / 1200] average reconstruction error: 0.010946 mse: 0.022125, ce: 0.008733, lr: 0.000000\n",
      "Epoch [91 / 1200] average reconstruction error: 0.010743 mse: 0.021887, ce: 0.008554, lr: 0.000000\n",
      "Epoch [101 / 1200] average reconstruction error: 0.010582 mse: 0.021903, ce: 0.008392, lr: 0.000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Documents\\repo\\Intra\\autoencoder\\notebook.ipynb Celda 14\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/notebook.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m li \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/notebook.ipynb#X16sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m d_data\u001b[39m.\u001b[39mtraverseInorderChilds(d_data, li)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/notebook.ipynb#X16sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m normalize_features(d_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/notebook.ipynb#X16sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m enc_fold_nodes \u001b[39m=\u001b[39m encode_structure_fold(d_data)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/notebook.ipynb#X16sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m max_depth \u001b[39m=\u001b[39m \u001b[39m30\u001b[39m\n",
      "\u001b[1;32mc:\\Users\\User\\Documents\\repo\\Intra\\autoencoder\\notebook.ipynb Celda 14\u001b[0m in \u001b[0;36mnormalize_features\u001b[1;34m(root)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/notebook.ipynb#X16sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m z \u001b[39m=\u001b[39m [tensor[\u001b[39m2\u001b[39m] \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m features]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/notebook.ipynb#X16sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m r \u001b[39m=\u001b[39m [tensor[\u001b[39m3\u001b[39m] \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m features]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/notebook.ipynb#X16sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m norm(root, \u001b[39mmin\u001b[39m(x), \u001b[39mmin\u001b[39m(y), \u001b[39mmin\u001b[39m(z), \u001b[39mmin\u001b[39m(r), \u001b[39mmax\u001b[39m(x), \u001b[39mmax\u001b[39m(y), \u001b[39mmax\u001b[39m(z), \u001b[39mmax\u001b[39;49m(r))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/repo/Intra/autoencoder/notebook.ipynb#X16sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1200\n",
    "learning_rate = 1e-4\n",
    "\n",
    "params = list(leafenc.parameters()) + list(nonleafenc.parameters()) + list(nodeClassifier.parameters()) + list(featuredec.parameters()) + list(bifdec.parameters())+ list(internaldec.parameters())\n",
    "opt = torch.optim.Adam(params, lr=learning_rate)\n",
    "\n",
    "train_loss_avg = []\n",
    "ce_avg = []\n",
    "mse_avg = []\n",
    "lr_list = []\n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    train_loss_avg.append(0)\n",
    "    ce_avg.append(0)\n",
    "    mse_avg.append(0)\n",
    "    lr_list.append(0)\n",
    "    batches = 0\n",
    "    for data in data_loader:\n",
    "            \n",
    "        d_data = deserialize(data[0])\n",
    "        li = []\n",
    "        d_data.traverseInorderChilds(d_data, li)\n",
    "        normalize_features(d_data)\n",
    "        enc_fold_nodes = encode_structure_fold(d_data).to(device)\n",
    "        max_depth = 30\n",
    "        max_nodes = 200\n",
    "        decoded = decode_structure_fold(enc_fold_nodes, d_data, max_nodes, max_depth)\n",
    "           \n",
    "        l = []\n",
    "        mse_loss_list = decoded.traverseInorderMSE(decoded, l)\n",
    "        l = []\n",
    "        ce_loss_list = decoded.traverseInorderCE(decoded, l)\n",
    "            \n",
    "        mse_loss = sum(mse_loss_list) / len(mse_loss_list)\n",
    "        ce_loss  = sum(ce_loss_list)  / len(ce_loss_list)\n",
    "        total_loss = (ce_loss + 0.1*mse_loss)\n",
    "\n",
    "        count = []\n",
    "        in_n_nodes = len(d_data.count_nodes(d_data, count))\n",
    "          \n",
    "        opt.zero_grad()\n",
    "        total_loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        train_loss_avg[-1] += (total_loss.item())\n",
    "        ce_avg[-1] += (ce_loss.item())\n",
    "        mse_avg[-1] += (mse_loss.item())\n",
    "        batches += 1\n",
    "\n",
    "    train_loss_avg[-1] /= batches\n",
    "    ce_avg[-1] /= batches\n",
    "    mse_avg[-1] /= batches\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch [%d / %d] average reconstruction error: %f mse: %f, ce: %f, lr: %f' % (epoch+1, epochs, train_loss_avg[-1], mse_avg[-1], ce_avg[-1], lr_list[-1]))\n",
    "            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_testing(v, max):\n",
    "    \n",
    "    def decode_node(v):\n",
    "        cl = nodeClassifier(v)\n",
    "        _, label = torch.max(cl, 1)\n",
    "        label = label.data\n",
    "        \n",
    "        if label == 0 and createNode.count < max: ##output del classifier\n",
    "            radio = featuredec(v)\n",
    "            nd = createNode(1,radio)\n",
    "            return nd\n",
    "\n",
    "        elif label == 1 and createNode.count < max:\n",
    "            right, radius = internaldec(v)\n",
    "            nd = createNode(1, radius) \n",
    "            nd.right = decode_node(right)\n",
    "            return nd\n",
    "\n",
    "        elif label == 2 and createNode.count < max:\n",
    "            left, right, radius = bifdec(v)\n",
    "            nd = createNode(1, radius)\n",
    "            nd.right = decode_node(right)\n",
    "            nd.left  = decode_node(left)\n",
    "            return nd\n",
    "    \n",
    "    createNode.count = 0\n",
    "    dec = decode_node (v)\n",
    "    return dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 tensor([0.4490, 0.3835, 0.2926, 0.7922], device='cuda:0')\n",
      "11 tensor([0.5112, 0.4319, 0.3092, 0.7855], device='cuda:0')\n",
      "12 tensor([0.5662, 0.4702, 0.3241, 0.7940], device='cuda:0')\n",
      "13 tensor([0.6067, 0.5095, 0.3300, 0.8085], device='cuda:0')\n",
      "14 tensor([0.6504, 0.5486, 0.3556, 0.8109], device='cuda:0')\n",
      "15 tensor([0.7006, 0.5836, 0.3625, 0.8291], device='cuda:0')\n",
      "21 tensor([0.7533, 0.9166, 0.4106, 0.4275], device='cuda:0')\n",
      "22 tensor([0.7374, 0.9443, 0.4777, 0.0000], device='cuda:0')\n",
      "16 tensor([0.7755, 0.6896, 0.3731, 0.8923], device='cuda:0')\n",
      "18 tensor([0.8530, 0.7216, 0.3719, 0.8838], device='cuda:0')\n",
      "17 tensor([1., 1., 0., 1.], device='cuda:0')\n",
      "9 tensor([0.3951, 0.3444, 0.2843, 0.7940], device='cuda:0')\n",
      "8 tensor([0.3201, 0.2997, 0.2775, 0.8339], device='cuda:0')\n",
      "7 tensor([0.2511, 0.2547, 0.2967, 0.8125], device='cuda:0')\n",
      "6 tensor([0.1999, 0.2023, 0.3313, 0.7864], device='cuda:0')\n",
      "5 tensor([0.1627, 0.1575, 0.3763, 0.7699], device='cuda:0')\n",
      "4 tensor([0.1228, 0.1181, 0.4348, 0.7539], device='cuda:0')\n",
      "3 tensor([0.0835, 0.0727, 0.5076, 0.7414], device='cuda:0')\n",
      "2 tensor([0.0342, 0.0449, 0.6224, 0.7506], device='cuda:0')\n",
      "1 tensor([0.0112, 0.0279, 0.7460, 0.7558], device='cuda:0')\n",
      "0 tensor([0.0000, 0.0000, 1.0000, 0.7791], device='cuda:0')\n",
      "encoded tensor([[ 0.9925, -0.9940, -0.9786, -0.9967, -0.9839, -0.9911,  0.9861,  0.9940,\n",
      "          0.9936,  0.9930,  0.9977,  0.9914, -0.9936,  0.9925,  0.9940, -0.9932,\n",
      "         -0.9952,  0.9912, -0.9907, -0.9965, -0.9940, -0.9908,  0.9897, -0.9961,\n",
      "          0.9951,  0.9897,  0.9940, -0.9919, -0.9928,  0.9891,  0.9931, -0.9736]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_4160\\2448251074.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rad = torch.tensor(input.radius)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_4160\\2448251074.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  radius = self.l1(torch.tensor(input.radius).reshape(1,4).to(device))\n"
     ]
    }
   ],
   "source": [
    "input = deserialize(iter(data_loader).next()[0])\n",
    "normalize_features(input)\n",
    "input.traverseInorder(input)\n",
    "encoded = encode_structure_fold(input).to(device)\n",
    "print(\"encoded\", enc_fold_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = decode_testing(encoded, 150)\n",
    "count = []\n",
    "numerar_nodos(decoded, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meshplot as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTree( root, dec ):\n",
    "    graph = nx.Graph()\n",
    "    root.toGraph( graph, 0, dec)\n",
    "    print(\"plot tree\", dec)\n",
    "    p = mp.plot( np.array([ graph.nodes[v]['posicion'] for v in graph.nodes]), shading={'point_size':0.5}, return_plot=True)\n",
    "\n",
    "    for arista in graph.edges:\n",
    "        p.add_lines( graph.nodes[arista[0]]['posicion'], graph.nodes[arista[1]]['posicion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([[0.3475, 0.2912, 0.3523, 0.7640]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "1 tensor([[0.2730, 0.2591, 0.3898, 0.7713]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "2 tensor([[0.2996, 0.3010, 0.4240, 0.8280]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "3 tensor([[0.3527, 0.3620, 0.4642, 0.8708]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "4 tensor([[0.4776, 0.4385, 0.4942, 0.8516]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "5 tensor([[-0.1220, -0.1930,  1.1707,  0.9564]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "6 tensor([[0.3957, 0.3447, 0.2846, 0.7939]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "7 tensor([[0.2639, 0.1229, 0.2667, 0.7591]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "8 tensor([[0.2084, 0.1554, 0.3020, 0.6135]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "9 tensor([[0.2381, 0.1957, 0.3387, 0.7027]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "10 tensor([[0.2503, 0.2231, 0.3629, 0.7394]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "11 tensor([[0.2670, 0.2527, 0.3872, 0.7756]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "12 tensor([[0.2921, 0.2908, 0.4166, 0.8171]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "13 tensor([[0.3376, 0.3468, 0.4551, 0.8629]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "14 tensor([[0.4421, 0.4249, 0.4930, 0.8700]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "15 tensor([[0.0059, 0.0067, 0.9899, 0.8224]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "radius [0.39568886 0.34471434 0.28464556 0.79388845]\n",
      "radius [0.263932   0.12285309 0.26665503 0.75914955]\n",
      "radius [0.2083966  0.1554492  0.30201298 0.613516  ]\n",
      "radius [0.23812264 0.19572636 0.3387027  0.70274574]\n",
      "radius [0.2502995  0.22310887 0.3628837  0.7394409 ]\n",
      "radius [0.26700088 0.25269917 0.38718653 0.7756292 ]\n",
      "radius [0.29210865 0.29084095 0.41664314 0.8170501 ]\n",
      "radius [0.3375892  0.34682357 0.45509705 0.8628758 ]\n",
      "radius [0.4420775 0.4249088 0.4930455 0.870005 ]\n",
      "radius [0.00591662 0.00672885 0.98992586 0.8223687 ]\n",
      "radius [0.34746307 0.29117733 0.35229734 0.76395786]\n",
      "radius [0.27298048 0.25914598 0.38979745 0.7712645 ]\n",
      "radius [0.2996162  0.30098397 0.423978   0.82803094]\n",
      "radius [0.35267526 0.36202258 0.46424147 0.8708421 ]\n",
      "radius [0.47764874 0.43850943 0.4941674  0.8516465 ]\n",
      "radius [-0.12201244 -0.19303833  1.1707041   0.9563577 ]\n",
      "plot tree True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f57ad7bdc27432e86720196e6b980b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(0.1778181…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoded.traverseInorder(decoded)\n",
    "plotTree (decoded, dec = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "nx.draw(G, node_size = 150, with_labels = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "fig = plt.plot(train_loss_avg) \n",
    "#plt.savefig(\"loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20,10))\n",
    "ax.plot(mse_avg, label=\"MSE\")\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(ce_avg, color=\"red\", label=\"Cross Entropy\")\n",
    "ax.legend(loc=1)\n",
    "ax.set_ylim(0, max(mse_avg))\n",
    "\n",
    "ax2.legend(loc=3)\n",
    "ax2.set_ylim(0, max(ce_avg))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "from turtle import pos\n",
    "\n",
    "import meshplot as mp\n",
    "from vec3 import Vec3\n",
    "    \n",
    "grafo = G\n",
    "\n",
    "posiciones = nx.get_node_attributes( grafo, 'posicion')\n",
    "\n",
    "li = posiciones[0].toList()\n",
    "v3 = posiciones[0]\n",
    "print(\"vec3\", v3)\n",
    "v3.tocpu()\n",
    "print(\"vec3\", v3)\n",
    "'''\n",
    "li = [x.cpu().detach() for x in li]\n",
    "print(li)\n",
    "posiciones.update((x, y.toList()) for x, y in posiciones.items())\n",
    "print(posiciones[0])\n",
    "\n",
    "posiciones.update((x, [a.cpu().detach() for a in y]) for x, y in posiciones.items())\n",
    "print(posiciones)\n",
    "p = mp.plot( np.array([ np.array(posiciones[node]) for node in grafo.nodes]), return_plot=True, shading={'point_size':4})\n",
    "\n",
    "\n",
    "\n",
    "for arista in grafo.edges:\n",
    "    #print(\"ariste\", grafo.nodes[arista[0]]['posicion'].toList())\n",
    "    arista0 = grafo.nodes[arista[0]]['posicion'].toList()\n",
    "    arista1 = grafo.nodes[arista[1]]['posicion'].toList()\n",
    "    print(\"ariste\", arista0)\n",
    "    arista_0 = [x.cpu().detach() for x in arista0]\n",
    "    print(\"ariste\", arista_0)\n",
    "    arista_1 = [x.cpu().detach() for x in arista1]\n",
    "    p.add_lines( arista_0, arista_1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py_torc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f3e717cd274da89498094fde320e6eab1bf0f52911d27cf47473187acb3fe8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
