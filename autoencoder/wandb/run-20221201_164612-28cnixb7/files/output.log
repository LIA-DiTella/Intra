
Epoch [1 / 8000] average reconstruction error: 0.3084212244
Epoch [11 / 8000] average reconstruction error: 0.2921299934
Epoch [21 / 8000] average reconstruction error: 0.2755670249
Epoch [31 / 8000] average reconstruction error: 0.2567910850
Epoch [41 / 8000] average reconstruction error: 0.2327285111
Epoch [51 / 8000] average reconstruction error: 0.1981104761
Epoch [61 / 8000] average reconstruction error: 0.1456891000
Epoch [71 / 8000] average reconstruction error: 0.0843881294
Epoch [81 / 8000] average reconstruction error: 0.0553002730
Epoch [91 / 8000] average reconstruction error: 0.0419650935
Epoch [101 / 8000] average reconstruction error: 0.0343420096
Epoch [111 / 8000] average reconstruction error: 0.0305114686
Epoch [121 / 8000] average reconstruction error: 0.0277579669
Epoch [131 / 8000] average reconstruction error: 0.0258207619
Epoch [141 / 8000] average reconstruction error: 0.0242885109
Epoch [151 / 8000] average reconstruction error: 0.0230882224
Epoch [161 / 8000] average reconstruction error: 0.0221286044
Epoch [171 / 8000] average reconstruction error: 0.0213534366
Epoch [181 / 8000] average reconstruction error: 0.0206987057
Epoch [191 / 8000] average reconstruction error: 0.0201081522
Epoch [201 / 8000] average reconstruction error: 0.0195354037
Epoch [211 / 8000] average reconstruction error: 0.0189390481
Epoch [221 / 8000] average reconstruction error: 0.0182820726
Epoch [231 / 8000] average reconstruction error: 0.0175274108
Epoch [241 / 8000] average reconstruction error: 0.0166457053
Epoch [251 / 8000] average reconstruction error: 0.0156318080
Epoch [261 / 8000] average reconstruction error: 0.0145265758
Epoch [271 / 8000] average reconstruction error: 0.0134241646
Epoch [281 / 8000] average reconstruction error: 0.0124114072
Epoch [291 / 8000] average reconstruction error: 0.0115157105
Epoch [301 / 8000] average reconstruction error: 0.0107516320
Epoch [311 / 8000] average reconstruction error: 0.0101574929
Epoch [321 / 8000] average reconstruction error: 0.0097305868
Epoch [331 / 8000] average reconstruction error: 0.0094323708
Epoch [341 / 8000] average reconstruction error: 0.0092176413
Epoch [351 / 8000] average reconstruction error: 0.0090621812
Epoch [361 / 8000] average reconstruction error: 0.0089449575
Epoch [371 / 8000] average reconstruction error: 0.0088547580
Epoch [381 / 8000] average reconstruction error: 0.0087841554
Epoch [391 / 8000] average reconstruction error: 0.0087270951
Epoch [401 / 8000] average reconstruction error: 0.0086793369
Epoch [411 / 8000] average reconstruction error: 0.0086397221
Epoch [421 / 8000] average reconstruction error: 0.0086048609
Epoch [431 / 8000] average reconstruction error: 0.0085748956
Epoch [441 / 8000] average reconstruction error: 0.0085479040
Epoch [451 / 8000] average reconstruction error: 0.0085241748
Epoch [461 / 8000] average reconstruction error: 0.0085028484
Epoch [471 / 8000] average reconstruction error: 0.0084831407
Epoch [481 / 8000] average reconstruction error: 0.0084653329
Epoch [491 / 8000] average reconstruction error: 0.0084492592
Epoch [501 / 8000] average reconstruction error: 0.0084335655
Epoch [511 / 8000] average reconstruction error: 0.0084199430
Epoch [521 / 8000] average reconstruction error: 0.0084071858
Epoch [531 / 8000] average reconstruction error: 0.0083948625
Epoch [541 / 8000] average reconstruction error: 0.0083839316
Epoch [551 / 8000] average reconstruction error: 0.0083735017
Epoch [561 / 8000] average reconstruction error: 0.0083632311
Epoch [571 / 8000] average reconstruction error: 0.0083533684
Epoch [581 / 8000] average reconstruction error: 0.0083445543
Epoch [591 / 8000] average reconstruction error: 0.0083354050
Epoch [601 / 8000] average reconstruction error: 0.0083265202
Epoch [611 / 8000] average reconstruction error: 0.0083185602
Epoch [621 / 8000] average reconstruction error: 0.0083104139
Epoch [631 / 8000] average reconstruction error: 0.0083026886
Epoch [641 / 8000] average reconstruction error: 0.0082950080
Epoch [651 / 8000] average reconstruction error: 0.0082871923
Epoch [661 / 8000] average reconstruction error: 0.0082792183
Epoch [671 / 8000] average reconstruction error: 0.0082719428
Epoch [681 / 8000] average reconstruction error: 0.0082645528
Epoch [691 / 8000] average reconstruction error: 0.0082566431
Epoch [701 / 8000] average reconstruction error: 0.0082491031
Epoch [711 / 8000] average reconstruction error: 0.0082413629
Epoch [721 / 8000] average reconstruction error: 0.0082338331
Epoch [731 / 8000] average reconstruction error: 0.0082259914
Epoch [741 / 8000] average reconstruction error: 0.0082179355
Epoch [751 / 8000] average reconstruction error: 0.0082097193
Epoch [761 / 8000] average reconstruction error: 0.0082020108
Epoch [771 / 8000] average reconstruction error: 0.0081944559
Epoch [781 / 8000] average reconstruction error: 0.0081858113
Epoch [791 / 8000] average reconstruction error: 0.0081778895
Epoch [801 / 8000] average reconstruction error: 0.0081697619
Epoch [811 / 8000] average reconstruction error: 0.0081616025
Epoch [821 / 8000] average reconstruction error: 0.0081538623
Epoch [831 / 8000] average reconstruction error: 0.0081459871
Epoch [841 / 8000] average reconstruction error: 0.0081382422
Epoch [851 / 8000] average reconstruction error: 0.0081304982
Epoch [861 / 8000] average reconstruction error: 0.0081232050
Epoch [871 / 8000] average reconstruction error: 0.0081159761
Epoch [881 / 8000] average reconstruction error: 0.0081083570
Epoch [891 / 8000] average reconstruction error: 0.0081009893
Epoch [901 / 8000] average reconstruction error: 0.0080939075
Epoch [911 / 8000] average reconstruction error: 0.0080868052
Epoch [921 / 8000] average reconstruction error: 0.0080792708
Epoch [931 / 8000] average reconstruction error: 0.0080717057
Epoch [941 / 8000] average reconstruction error: 0.0080642970
Epoch [951 / 8000] average reconstruction error: 0.0080569573
Epoch [961 / 8000] average reconstruction error: 0.0080490997
Epoch [971 / 8000] average reconstruction error: 0.0080409031
Epoch [981 / 8000] average reconstruction error: 0.0080326954
Epoch [991 / 8000] average reconstruction error: 0.0080245631
Epoch [1001 / 8000] average reconstruction error: 0.0080156205
Epoch [1011 / 8000] average reconstruction error: 0.0080066854
Epoch [1021 / 8000] average reconstruction error: 0.0079974597
Epoch [1031 / 8000] average reconstruction error: 0.0079882061
Epoch [1041 / 8000] average reconstruction error: 0.0079778824
Epoch [1051 / 8000] average reconstruction error: 0.0079682069
Epoch [1061 / 8000] average reconstruction error: 0.0079574697
Epoch [1071 / 8000] average reconstruction error: 0.0079470295
Epoch [1081 / 8000] average reconstruction error: 0.0079357279
Epoch [1091 / 8000] average reconstruction error: 0.0079241423
Epoch [1101 / 8000] average reconstruction error: 0.0079123769
Epoch [1111 / 8000] average reconstruction error: 0.0078999856
Epoch [1121 / 8000] average reconstruction error: 0.0078874370
Epoch [1131 / 8000] average reconstruction error: 0.0078744302
Epoch [1141 / 8000] average reconstruction error: 0.0078605535
Epoch [1151 / 8000] average reconstruction error: 0.0078462213
Epoch [1161 / 8000] average reconstruction error: 0.0078317272
Epoch [1171 / 8000] average reconstruction error: 0.0078165745
Epoch [1181 / 8000] average reconstruction error: 0.0078001767
Epoch [1191 / 8000] average reconstruction error: 0.0077834963
Epoch [1201 / 8000] average reconstruction error: 0.0077657932
Epoch [1211 / 8000] average reconstruction error: 0.0077467375
Epoch [1221 / 8000] average reconstruction error: 0.0077271760
Epoch [1231 / 8000] average reconstruction error: 0.0077056396
Epoch [1241 / 8000] average reconstruction error: 0.0076829004
Epoch [1251 / 8000] average reconstruction error: 0.0076587410
Epoch [1261 / 8000] average reconstruction error: 0.0076322416
Epoch [1271 / 8000] average reconstruction error: 0.0076032067
Epoch [1281 / 8000] average reconstruction error: 0.0075720893
Epoch [1291 / 8000] average reconstruction error: 0.0075384690
Epoch [1301 / 8000] average reconstruction error: 0.0075023146
Epoch [1311 / 8000] average reconstruction error: 0.0074635455
Epoch [1321 / 8000] average reconstruction error: 0.0074231075
Epoch [1331 / 8000] average reconstruction error: 0.0073810979
0 tensor([[0.4443, 0.1999, 0.2222, 0.4998]], device='cuda:0',
       grad_fn=<AddmmBackward0>)
1 tensor([[0.8888, 0.3999, 0.4444, 0.9998]], device='cuda:0',
       grad_fn=<AddmmBackward0>)
2 tensor([[-4.2706e-05, -1.6338e-04, -1.3579e-04, -1.3236e-04]], device='cuda:0',
       grad_fn=<AddmmBackward0>)
3 tensor([[0.5555, 0.7999, 0.7777, 0.4999]], device='cuda:0',
       grad_fn=<AddmmBackward0>)
4 tensor([[1.0000, 0.9999, 1.0000, 0.9998]], device='cuda:0',
       grad_fn=<AddmmBackward0>)
0 tensor([[5.4140e-05, 6.4339e-05, 4.4752e-05, 1.2178e-04]], device='cuda:0',
       grad_fn=<AddmmBackward0>)
0 tensor([[5.4140e-05, 6.4339e-05, 4.4752e-05, 1.2178e-04]], device='cuda:0',
       grad_fn=<AddmmBackward0>)
0 tensor([[0.4443, 0.1999, 0.2222, 0.4998]], device='cuda:0',
       grad_fn=<AddmmBackward0>)
1 tensor([[0.8888, 0.3999, 0.4444, 0.9998]], device='cuda:0',
       grad_fn=<AddmmBackward0>)
2 tensor([[-4.2706e-05, -1.6338e-04, -1.3579e-04, -1.3236e-04]], device='cuda:0',
       grad_fn=<AddmmBackward0>)
3 tensor([[0.5555, 0.7999, 0.7777, 0.4999]], device='cuda:0',
       grad_fn=<AddmmBackward0>)
4 tensor([[1.0000, 0.9999, 1.0000, 0.9998]], device='cuda:0',
       grad_fn=<AddmmBackward0>)
0 tensor([[0.0002, 0.0003, 0.0003, 0.0004]], device='cuda:0',
       grad_fn=<AddmmBackward0>)
1 tensor([[0.5003, 0.5002, 0.5003, 0.5003]], device='cuda:0',
       grad_fn=<AddmmBackward0>)
['tree0.dat', 'tree1.dat', 'tree10.dat', 'tree11.dat', 'tree12.dat', 'tree13.dat', 'tree14.dat', 'tree15.dat', 'tree16.dat', 'tree17.dat']
0 tensor([0., 0., 0., 0.], device='cuda:0')
2 tensor([1., 1., 1., 1.], device='cuda:0')
1 tensor([0.5000, 0.5000, 0.5000, 0.5000], device='cuda:0')
['tree0.dat', 'tree1.dat', 'tree10.dat', 'tree11.dat', 'tree12.dat', 'tree13.dat', 'tree14.dat', 'tree15.dat', 'tree16.dat', 'tree17.dat']
0 tensor([0., 0., 0., 0.], device='cuda:0')
2 tensor([1., 1., 1., 1.], device='cuda:0')
1 tensor([0.5000, 0.5000, 0.5000, 0.5000], device='cuda:0')
ENCODED con batch [tensor([[-0.0554, -0.0035,  0.0399,  0.0745,  0.1057,  0.0828,  0.0751, -0.0148,
         -0.0286, -0.0111, -0.0284,  0.0852, -0.0192, -0.0870, -0.0061,  0.0030,
          0.0399, -0.0041,  0.1329,  0.0011,  0.0156,  0.0300,  0.0506,  0.0202,
         -0.0008, -0.0289,  0.0886,  0.0455, -0.0389,  0.0456,  0.0651,  0.0290,
         -0.0204,  0.0108, -0.0928,  0.0160,  0.0005,  0.0795,  0.0231, -0.0293,
          0.0142, -0.0217, -0.0321, -0.1034,  0.0899,  0.0002,  0.0769,  0.0412,
          0.0021, -0.0853,  0.0359,  0.0389,  0.0193, -0.0079, -0.0749,  0.0312,
          0.0754, -0.0060,  0.0184, -0.0793, -0.0408, -0.0492, -0.0027,  0.0674,
          0.0574, -0.0246,  0.0077,  0.0277, -0.0371, -0.0067, -0.0114,  0.0139,
         -0.1223, -0.0191,  0.0018, -0.1168,  0.0436,  0.0434, -0.0255,  0.0296,
          0.0667,  0.0539,  0.0184, -0.0490,  0.0652,  0.0490, -0.0498,  0.0167,
          0.0364, -0.0437,  0.0302, -0.0335,  0.0002, -0.0314, -0.0683,  0.0028,
         -0.0156,  0.0457, -0.0329, -0.0277,  0.0094,  0.0663, -0.0020,  0.0713,
          0.0170,  0.0135, -0.0396, -0.0478,  0.1199,  0.0337, -0.0279, -0.0375,
         -0.0214,  0.0313, -0.0469, -0.0340, -0.0473, -0.0241, -0.0619,  0.0058,
         -0.0226,  0.0036, -0.0285,  0.0217,  0.0817, -0.0362, -0.0589,  0.0939,
         -0.0391, -0.0928, -0.0153,  0.0041,  0.0148, -0.0755,  0.0092,  0.0278,
          0.0416, -0.0212, -0.0970, -0.0056,  0.0838,  0.0414,  0.0232, -0.0180,
          0.0280, -0.0638, -0.0972, -0.0275,  0.0050,  0.0857, -0.0383,  0.0166,
         -0.0344, -0.0048,  0.0486,  0.0720,  0.0160,  0.0026,  0.0198,  0.0275,
         -0.0429,  0.0153, -0.0902,  0.0846,  0.0225, -0.0145, -0.0285, -0.0302,
          0.0296,  0.0327, -0.0887,  0.0372, -0.0152,  0.0028, -0.0298,  0.0275,
         -0.0026, -0.0400, -0.0028, -0.0483, -0.0400,  0.0327,  0.0326,  0.0408,
          0.0003,  0.0131,  0.0007, -0.0303,  0.0713, -0.0946, -0.0221,  0.0839,
         -0.0562,  0.0417, -0.0066,  0.0957,  0.0049, -0.0263,  0.0688,  0.0912,
          0.0121,  0.0406, -0.0151, -0.0099, -0.0115, -0.1263,  0.0110, -0.1372,
         -0.0330, -0.0226,  0.0492, -0.0319, -0.0009,  0.0785,  0.0333,  0.0140,
          0.0039, -0.0208, -0.0234,  0.0731, -0.0657,  0.0367, -0.0763,  0.0139,
         -0.0292,  0.0345,  0.0200,  0.0177, -0.0192,  0.0194, -0.0102, -0.0812,
         -0.0363,  0.0110,  0.0002, -0.0236, -0.0352,  0.0391, -0.0070,  0.0448,
         -0.0469, -0.0701, -0.0425,  0.0192,  0.0125, -0.0787,  0.1129,  0.0326,
          0.0146, -0.0294,  0.0362,  0.0664, -0.0052, -0.0031, -0.0164, -0.0158,
          0.0131,  0.0214, -0.0053, -0.0050, -0.0403, -0.0457, -0.0220,  0.0466,
         -0.0094, -0.0373,  0.0315,  0.0826,  0.0015, -0.0080,  0.0538,  0.0594,
         -0.0287,  0.0735,  0.0114, -0.0437, -0.0491,  0.0914, -0.0014, -0.0550,
         -0.0412,  0.0385,  0.0184, -0.0347,  0.0005, -0.1566,  0.0064, -0.0041,
         -0.0160,  0.0676, -0.0356, -0.0308, -0.0040, -0.1198,  0.0314,  0.0251,
          0.0313,  0.0524,  0.0279, -0.0051, -0.0161, -0.0228, -0.0354, -0.0072,
          0.0491,  0.0395, -0.0812,  0.0586,  0.0278, -0.0414,  0.0264,  0.0305,
         -0.0578,  0.0133,  0.0359,  0.0857,  0.0238, -0.0025,  0.0300,  0.0486,
          0.0556,  0.0658, -0.0177, -0.0287, -0.0402, -0.0110,  0.0286,  0.0480,
         -0.0773, -0.0260,  0.0284,  0.0023,  0.0336,  0.0065,  0.0589, -0.0199,
          0.0231, -0.0465, -0.0073,  0.0394, -0.0211,  0.0395,  0.0050, -0.0527,
         -0.0095, -0.0003,  0.0179,  0.0859,  0.0261,  0.0780,  0.0294, -0.0204,
          0.0501, -0.0149,  0.0201, -0.0703,  0.0205, -0.0055, -0.0412,  0.1058,
         -0.0451, -0.0212,  0.0013,  0.0323, -0.0003, -0.0524, -0.0045, -0.0250,
         -0.0304, -0.0243, -0.0970,  0.0187,  0.0577,  0.0617,  0.0294, -0.0225,
         -0.0378,  0.0295,  0.0258, -0.0011, -0.0206, -0.0005, -0.0390,  0.0592,
          0.0029,  0.0401,  0.0129, -0.1026,  0.0038, -0.0267,  0.0327,  0.0205,
         -0.0473, -0.0094,  0.0408,  0.0254, -0.0655,  0.0067,  0.0143, -0.0645,
         -0.0038, -0.0011, -0.0726, -0.0660,  0.0020, -0.0039,  0.0648, -0.0300,
         -0.0574,  0.0059, -0.0917,  0.0830,  0.0379,  0.0871,  0.0409, -0.0675,
          0.0383, -0.0446,  0.0156, -0.0646, -0.0245,  0.0341, -0.0868, -0.0152,
         -0.0197, -0.0078, -0.0134,  0.0634, -0.0685, -0.0665, -0.0054,  0.0060,
         -0.0014,  0.0074,  0.0278, -0.0779, -0.0254, -0.0280, -0.0053, -0.0252,
         -0.0469, -0.0299, -0.0481, -0.0177, -0.0349,  0.0223,  0.0567, -0.0698,
          0.0253, -0.0253, -0.0283, -0.0302,  0.0828,  0.0074, -0.0542, -0.0234,
         -0.0017, -0.0083, -0.0073, -0.0816,  0.0129,  0.0026, -0.0656,  0.0343,
         -0.0383,  0.0846,  0.0322, -0.0452,  0.0115,  0.0069,  0.0151, -0.0577,
          0.0020, -0.0308, -0.0870, -0.0192, -0.0546, -0.0558,  0.0459,  0.0537,
         -0.0552,  0.0314,  0.0652, -0.0771,  0.0309, -0.0561,  0.0020, -0.0059,
         -0.0436,  0.0545,  0.0709,  0.0950,  0.0103, -0.0421, -0.0189, -0.0432,
         -0.0320, -0.0703,  0.0178,  0.1129, -0.0038, -0.0205,  0.0694, -0.0392,
          0.0191,  0.0379,  0.0142, -0.0458, -0.0204,  0.0189, -0.0203, -0.0140]],
       device='cuda:0', grad_fn=<StackBackward0>)]
encodeado sin batch tensor([[-0.0554, -0.0035,  0.0399,  0.0745,  0.1057,  0.0828,  0.0751, -0.0148,
         -0.0286, -0.0111, -0.0284,  0.0852, -0.0192, -0.0870, -0.0061,  0.0030,
          0.0399, -0.0041,  0.1329,  0.0011,  0.0156,  0.0300,  0.0506,  0.0202,
         -0.0008, -0.0289,  0.0886,  0.0455, -0.0389,  0.0456,  0.0651,  0.0290,
         -0.0204,  0.0108, -0.0928,  0.0160,  0.0005,  0.0795,  0.0231, -0.0293,
          0.0142, -0.0217, -0.0321, -0.1034,  0.0899,  0.0002,  0.0769,  0.0412,
          0.0021, -0.0853,  0.0359,  0.0389,  0.0193, -0.0079, -0.0749,  0.0312,
          0.0754, -0.0060,  0.0184, -0.0793, -0.0408, -0.0492, -0.0027,  0.0674,
          0.0574, -0.0246,  0.0077,  0.0277, -0.0371, -0.0067, -0.0114,  0.0139,
         -0.1223, -0.0191,  0.0018, -0.1168,  0.0436,  0.0434, -0.0255,  0.0296,
          0.0667,  0.0539,  0.0184, -0.0490,  0.0652,  0.0490, -0.0498,  0.0167,
          0.0364, -0.0437,  0.0302, -0.0335,  0.0002, -0.0314, -0.0683,  0.0028,
         -0.0156,  0.0457, -0.0329, -0.0277,  0.0094,  0.0663, -0.0020,  0.0713,
          0.0170,  0.0135, -0.0396, -0.0478,  0.1199,  0.0337, -0.0279, -0.0375,
         -0.0214,  0.0313, -0.0469, -0.0340, -0.0473, -0.0241, -0.0619,  0.0058,
         -0.0226,  0.0036, -0.0285,  0.0217,  0.0817, -0.0362, -0.0589,  0.0939,
         -0.0391, -0.0928, -0.0153,  0.0041,  0.0148, -0.0755,  0.0092,  0.0278,
          0.0416, -0.0212, -0.0970, -0.0056,  0.0838,  0.0414,  0.0232, -0.0180,
          0.0280, -0.0638, -0.0972, -0.0275,  0.0050,  0.0857, -0.0383,  0.0166,
         -0.0344, -0.0048,  0.0486,  0.0720,  0.0160,  0.0026,  0.0198,  0.0275,
         -0.0429,  0.0153, -0.0902,  0.0846,  0.0225, -0.0145, -0.0285, -0.0302,
          0.0296,  0.0327, -0.0887,  0.0372, -0.0152,  0.0028, -0.0298,  0.0275,
         -0.0026, -0.0400, -0.0028, -0.0483, -0.0400,  0.0327,  0.0326,  0.0408,
          0.0003,  0.0131,  0.0007, -0.0303,  0.0713, -0.0946, -0.0221,  0.0839,
         -0.0562,  0.0417, -0.0066,  0.0957,  0.0049, -0.0263,  0.0688,  0.0912,
          0.0121,  0.0406, -0.0151, -0.0099, -0.0115, -0.1263,  0.0110, -0.1372,
         -0.0330, -0.0226,  0.0492, -0.0319, -0.0009,  0.0785,  0.0333,  0.0140,
          0.0039, -0.0208, -0.0234,  0.0731, -0.0657,  0.0367, -0.0763,  0.0139,
         -0.0292,  0.0345,  0.0200,  0.0177, -0.0192,  0.0194, -0.0102, -0.0812,
         -0.0363,  0.0110,  0.0002, -0.0236, -0.0352,  0.0391, -0.0070,  0.0448,
         -0.0469, -0.0701, -0.0425,  0.0192,  0.0125, -0.0787,  0.1129,  0.0326,
          0.0146, -0.0294,  0.0362,  0.0664, -0.0052, -0.0031, -0.0164, -0.0158,
          0.0131,  0.0214, -0.0053, -0.0050, -0.0403, -0.0457, -0.0220,  0.0466,
         -0.0094, -0.0373,  0.0315,  0.0826,  0.0015, -0.0080,  0.0538,  0.0594,
         -0.0287,  0.0735,  0.0114, -0.0437, -0.0491,  0.0914, -0.0014, -0.0550,
         -0.0412,  0.0385,  0.0184, -0.0347,  0.0005, -0.1566,  0.0064, -0.0041,
         -0.0160,  0.0676, -0.0356, -0.0308, -0.0040, -0.1198,  0.0314,  0.0251,
          0.0313,  0.0524,  0.0279, -0.0051, -0.0161, -0.0228, -0.0354, -0.0072,
          0.0491,  0.0395, -0.0812,  0.0586,  0.0278, -0.0414,  0.0264,  0.0305,
         -0.0578,  0.0133,  0.0359,  0.0857,  0.0238, -0.0025,  0.0300,  0.0486,
          0.0556,  0.0658, -0.0177, -0.0287, -0.0402, -0.0110,  0.0286,  0.0480,
         -0.0773, -0.0260,  0.0284,  0.0023,  0.0336,  0.0065,  0.0589, -0.0199,
          0.0231, -0.0465, -0.0073,  0.0394, -0.0211,  0.0395,  0.0050, -0.0527,
         -0.0095, -0.0003,  0.0179,  0.0859,  0.0261,  0.0780,  0.0294, -0.0204,
          0.0501, -0.0149,  0.0201, -0.0703,  0.0205, -0.0055, -0.0412,  0.1058,
         -0.0451, -0.0212,  0.0013,  0.0323, -0.0003, -0.0524, -0.0045, -0.0250,
         -0.0304, -0.0243, -0.0970,  0.0187,  0.0577,  0.0617,  0.0294, -0.0225,
         -0.0378,  0.0295,  0.0258, -0.0011, -0.0206, -0.0005, -0.0390,  0.0592,
          0.0029,  0.0401,  0.0129, -0.1026,  0.0038, -0.0267,  0.0327,  0.0205,
         -0.0473, -0.0094,  0.0408,  0.0254, -0.0655,  0.0067,  0.0143, -0.0645,
         -0.0038, -0.0011, -0.0726, -0.0660,  0.0020, -0.0039,  0.0648, -0.0300,
         -0.0574,  0.0059, -0.0917,  0.0830,  0.0379,  0.0871,  0.0409, -0.0675,
          0.0383, -0.0446,  0.0156, -0.0646, -0.0245,  0.0341, -0.0868, -0.0152,
         -0.0197, -0.0078, -0.0134,  0.0634, -0.0685, -0.0665, -0.0054,  0.0060,
         -0.0014,  0.0074,  0.0278, -0.0779, -0.0254, -0.0280, -0.0053, -0.0252,
         -0.0469, -0.0299, -0.0481, -0.0177, -0.0349,  0.0223,  0.0567, -0.0698,
          0.0253, -0.0253, -0.0283, -0.0302,  0.0828,  0.0074, -0.0542, -0.0234,
         -0.0017, -0.0083, -0.0073, -0.0816,  0.0129,  0.0026, -0.0656,  0.0343,
         -0.0383,  0.0846,  0.0322, -0.0452,  0.0115,  0.0069,  0.0151, -0.0577,
          0.0020, -0.0308, -0.0870, -0.0192, -0.0546, -0.0558,  0.0459,  0.0537,
         -0.0552,  0.0314,  0.0652, -0.0771,  0.0309, -0.0561,  0.0020, -0.0059,
         -0.0436,  0.0545,  0.0709,  0.0950,  0.0103, -0.0421, -0.0189, -0.0432,
         -0.0320, -0.0703,  0.0178,  0.1129, -0.0038, -0.0205,  0.0694, -0.0392,
          0.0191,  0.0379,  0.0142, -0.0458, -0.0204,  0.0189, -0.0203, -0.0140]],
       device='cuda:0', grad_fn=<TanhBackward0>)
10
[5, 5, 3, 6, 6, 5, 5, 5, 3, 5]
4.8
3.0
0.6
1.2
3.0
0.6
1.2
tensor([0.3333, 1.0000, 1.0000], device='cuda:0')
n_nodes 3
<__main__.Node object at 0x0000024905798A00>
tree level 11
<__main__.Node object at 0x0000024905798640>
tree level 11
<__main__.Node object at 0x000002490579A710>
tree level 14
<__main__.Node object at 0x0000024905348D30>
tree level 6
<__main__.Node object at 0x000002490579A860>
tree level 11
<__main__.Node object at 0x000002490534B2B0>
tree level 11
<__main__.Node object at 0x000002490579A140>
tree level 11
<__main__.Node object at 0x000002490579D900>
tree level 6
<__main__.Node object at 0x000002490579A890>
tree level 11
<__main__.Node object at 0x000002490579A470>
tree level 14